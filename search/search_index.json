{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"Cursor/","text":"Database Cursor","title":"Cursor"},{"location":"Implementation/SQL-compiler/","text":"SQL compiler # \u901a\u8fc7 Architecture of SQLite \u53ef\u77e5\uff0c\u5b9e\u73b0\u4e00\u4e2aSQL engine\u7684\u7b2c\u4e00\u6b65\u662f\u5b9e\u73b0\u4e00\u4e2aSQL compiler\uff0c\u5373\u7f16\u8bd1SQL\u8bed\u53e5\u3002 \u4e0b\u9762\u662f\u4e00\u4e9b\u4f8b\u5b50: TrivialDB thinkpad20 / sql SQL Parser mozilla / moz-sql-parser cybergarage / usql madanjhawar / Mini-SQL-Engine","title":"Introduction"},{"location":"Implementation/SQL-compiler/#sql-compiler","text":"\u901a\u8fc7 Architecture of SQLite \u53ef\u77e5\uff0c\u5b9e\u73b0\u4e00\u4e2aSQL engine\u7684\u7b2c\u4e00\u6b65\u662f\u5b9e\u73b0\u4e00\u4e2aSQL compiler\uff0c\u5373\u7f16\u8bd1SQL\u8bed\u53e5\u3002 \u4e0b\u9762\u662f\u4e00\u4e9b\u4f8b\u5b50: TrivialDB thinkpad20 / sql SQL Parser mozilla / moz-sql-parser cybergarage / usql madanjhawar / Mini-SQL-Engine","title":"SQL compiler"},{"location":"Implementation/SQLite/doc/","text":"SQLite # About SQLite # SQLite is an in-process library that implements a self-contained , serverless , zero-configuration , transactional SQL database engine. NOTE: SQLite \u7f16\u8bd1\u751f\u6210\u7684\u662f\u4e00\u4e2aso\uff0cLinux\u4e0b\u7684 sqlite3 dynamic link\u5bf9\u5e94\u7684so: C++ [root@localhost ~]# ldd -r /usr/bin/sqlite3 linux-vdso.so.1 => (0x00007ffe52bb9000) libsqlite3.so.0 => /lib64/libsqlite3.so.0 (0x00007f6640589000) libreadline.so.6 => /lib64/libreadline.so.6 (0x00007f6640342000) libncurses.so.5 => /lib64/libncurses.so.5 (0x00007f664011b000) libtinfo.so.5 => /lib64/libtinfo.so.5 (0x00007f663fef1000) libdl.so.2 => /lib64/libdl.so.2 (0x00007f663fcec000) libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f663fad0000) libc.so.6 => /lib64/libc.so.6 (0x00007f663f703000) /lib64/ld-linux-x86-64.so.2 (0x00007f6640856000)","title":"Introduction"},{"location":"Implementation/SQLite/doc/#sqlite","text":"","title":"SQLite"},{"location":"Implementation/SQLite/doc/#about-sqlite","text":"SQLite is an in-process library that implements a self-contained , serverless , zero-configuration , transactional SQL database engine. NOTE: SQLite \u7f16\u8bd1\u751f\u6210\u7684\u662f\u4e00\u4e2aso\uff0cLinux\u4e0b\u7684 sqlite3 dynamic link\u5bf9\u5e94\u7684so: C++ [root@localhost ~]# ldd -r /usr/bin/sqlite3 linux-vdso.so.1 => (0x00007ffe52bb9000) libsqlite3.so.0 => /lib64/libsqlite3.so.0 (0x00007f6640589000) libreadline.so.6 => /lib64/libreadline.so.6 (0x00007f6640342000) libncurses.so.5 => /lib64/libncurses.so.5 (0x00007f664011b000) libtinfo.so.5 => /lib64/libtinfo.so.5 (0x00007f663fef1000) libdl.so.2 => /lib64/libdl.so.2 (0x00007f663fcec000) libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f663fad0000) libc.so.6 => /lib64/libc.so.6 (0x00007f663f703000) /lib64/ld-linux-x86-64.so.2 (0x00007f6640856000)","title":"About SQLite"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/","text":"Run-Time Loadable Extensions # 1. Overview # Extensions can also be statically linked with the application. The code template shown below will work just as well as a statically linked extension as it does as a run-time loadable extension except that you should give the entry point function (\" sqlite3_extension_init \") a different name to avoid name collisions if your application contains two or more extensions. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u4ec0\u4e48\u610f\u601d\uff1f\u7ed3\u5408\u4e0b\u9762\u7684\u5185\u5bb9\u6765\u8fdb\u884c\u7406\u89e3: sqlite\u662f\u5141\u8bb8load\u591a\u4e2aextension\u7684\uff0c\u6bcf\u4e2aextension\u90fd\u9700\u8981\u6709\u4e00\u4e2aentry point function\uff0c\u5982\u679c\u90fd\u6307\u5b9a\u4e3a sqlite3_extension_init \u7684\u8bdd\uff0c\u5219\u5c31\u5bfc\u81f4name collision\u4e86\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0csqlite\u91c7\u7528\u4e86\u4e00\u5b9a\u7684\u547d\u540d\u65b9\u6848: sqlite3_X_init \uff0c\u53c2\u89c1\u539f\u6587\u7684\"2. Loading An Extension\"\u7ae0\u8282\u3002 NOTE: Extensions\u7684\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f: 1) statically linked 2) run-time load 2. Loading An Extension # NOTE: \u672c\u8282\u4ecb\u7ecdrun-time load\u65b9\u6cd5\u3002\u4e0b\u9762\u662fsqlite\u63d0\u4f9b\u7684\u65b9\u6cd5: 1) C: sqlite3_load_extension() 2) SQL function: Load_extension(X,Y) 3) command-line shell , extensions can be loaded using the \" .load \" dot-command \u65e0\u8bba\u54ea\u79cd\u65b9\u5f0f\uff0c\u975e\u5e38\u91cd\u8981\u7684\u662f\u5bf9 entry point function \u7684\u6307\u5b9a\u3002\u5176\u5b9e\u4e5f\u53ef\u4ee5\u4e0d\u6307\u5b9a\uff0csqlite\u7684\u9ed8\u8ba4\u5bfb\u627e\u89c4\u5219\u80fd\u591f\u81ea\u52a8\u627e\u5230 entry point function \u3002 For security reasons, extension loading is turned off by default. In order to use either the C-language or SQL extension loading functions, one must first enable extension loading using the sqlite3_db_config (db, SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION ,1,NULL) C-language API in your application. NOTE: \u5fc5\u987b\u8981\u9996\u5148\u5f00\u542f\u624d\u80fd\u591f\u4f7f\u7528 3. Compiling A Loadable Extension # gcc -g -fPIC -shared YourCode.c -o YourCode.so NOTE: \u5176\u5b9e\u5c31\u662f\u666e\u901a\u7684\u7f16\u8bd1so\u7684\u65b9\u5f0f 4. Programming Loadable Extensions # NOTE: \u4e0d\u540c\u7684\u7c7b\u578b\u7684extension\u4f7f\u7528\u4e0d\u540c\u7684\u5b9e\u73b0 5. Persistent Loadable Extensions # The default behavior for a loadable extension is that it is unloaded from process memory when the database connection that originally invoked sqlite3_load_extension() closes. However, if the initialization procedure returns SQLITE_OK_LOAD_PERMANENTLY instead of SQLITE_OK , then the extension will not be unloaded ( xDlClose will not be invoked) and the extension will remain in process memory indefinitely. The SQLITE_OK_LOAD_PERMANENTLY return value is useful for extensions that want to register new VFSes . To clarify: an extension for which the initialization function returns SQLITE_OK_LOAD_PERMANENTLY continues to exist in memory after the database connection closes. However, the extension is not automatically registered with subsequent database connections. This makes it possible to load extensions that implement new VFSes . To persistently load and register an extension that implements new SQL functions , collating sequences, and/or virtual tables, such that those added capabilities are available to all subsequent database connections, then the initialization routine should also invoke sqlite3_auto_extension() on a subfunction that will register those services. NOTE:\u81ea\u52a8load\u3001register\u7279\u6027\u975e\u5e38\u91cd\u8981\u3002 \u5bf9\u4e8e SQL functions \uff0c\u8c8c\u4f3c\u5b83\u4eec\u5fc5\u987b\u8981persistently load and register \u3002 The vfsstat.c extension show an example of a loadable extension that persistently registers both a new VFS and a new virtual table. The sqlite3_vfsstat_init() initialization routine in that extension is called only once, when the extension is first loaded. It registers the new \"vfslog\" VFS just that one time, and it returns SQLITE_OK_LOAD_PERMANENTLY so that the code used to implement the \"vfslog\" VFS will remain in memory. The initialization routine also invokes sqlite3_auto_extension() on a pointer to the \" vstatRegister() \" function so that all subsequent database connections will invoke the \" vstatRegister() \" function as they start up, and hence register the \"vfsstat\" virtual table. 6. Statically Linking A Run-Time Loadable Extension # 7. Implementation Details # SQLite implements run-time extension loading using the xDlOpen() , xDlError() , xDlSym() , and xDlClose() methods of the sqlite3_vfs object. These methods are implemented using the dlopen() library on unix (which explains why SQLite commonly need to be linked against the \" -ldl \" library on unix systems) and using LoadLibrary() API on Windows. In a custom VFS for unusual systems, these methods can all be omitted, in which case the run-time extension loading mechanism will not work (though you will still be able to statically link the extension code, assuming the entry pointers are uniquely named). SQLite can be compiled with SQLITE_OMIT_LOAD_EXTENSION to omit the extension loading code from the build. NOTE: \u5173\u4e8e dlopen \uff0c\u53c2\u89c1\u5de5\u7a0bLinux-OS\u7684 Programming\\Object-file\\Shared-library","title":"Run-Time-Loadable-Extensions"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#run-time-loadable-extensions","text":"","title":"Run-Time Loadable Extensions"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#1-overview","text":"Extensions can also be statically linked with the application. The code template shown below will work just as well as a statically linked extension as it does as a run-time loadable extension except that you should give the entry point function (\" sqlite3_extension_init \") a different name to avoid name collisions if your application contains two or more extensions. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u662f\u4ec0\u4e48\u610f\u601d\uff1f\u7ed3\u5408\u4e0b\u9762\u7684\u5185\u5bb9\u6765\u8fdb\u884c\u7406\u89e3: sqlite\u662f\u5141\u8bb8load\u591a\u4e2aextension\u7684\uff0c\u6bcf\u4e2aextension\u90fd\u9700\u8981\u6709\u4e00\u4e2aentry point function\uff0c\u5982\u679c\u90fd\u6307\u5b9a\u4e3a sqlite3_extension_init \u7684\u8bdd\uff0c\u5219\u5c31\u5bfc\u81f4name collision\u4e86\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0csqlite\u91c7\u7528\u4e86\u4e00\u5b9a\u7684\u547d\u540d\u65b9\u6848: sqlite3_X_init \uff0c\u53c2\u89c1\u539f\u6587\u7684\"2. Loading An Extension\"\u7ae0\u8282\u3002 NOTE: Extensions\u7684\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f: 1) statically linked 2) run-time load","title":"1. Overview"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#2-loading-an-extension","text":"NOTE: \u672c\u8282\u4ecb\u7ecdrun-time load\u65b9\u6cd5\u3002\u4e0b\u9762\u662fsqlite\u63d0\u4f9b\u7684\u65b9\u6cd5: 1) C: sqlite3_load_extension() 2) SQL function: Load_extension(X,Y) 3) command-line shell , extensions can be loaded using the \" .load \" dot-command \u65e0\u8bba\u54ea\u79cd\u65b9\u5f0f\uff0c\u975e\u5e38\u91cd\u8981\u7684\u662f\u5bf9 entry point function \u7684\u6307\u5b9a\u3002\u5176\u5b9e\u4e5f\u53ef\u4ee5\u4e0d\u6307\u5b9a\uff0csqlite\u7684\u9ed8\u8ba4\u5bfb\u627e\u89c4\u5219\u80fd\u591f\u81ea\u52a8\u627e\u5230 entry point function \u3002 For security reasons, extension loading is turned off by default. In order to use either the C-language or SQL extension loading functions, one must first enable extension loading using the sqlite3_db_config (db, SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION ,1,NULL) C-language API in your application. NOTE: \u5fc5\u987b\u8981\u9996\u5148\u5f00\u542f\u624d\u80fd\u591f\u4f7f\u7528","title":"2. Loading An Extension"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#3-compiling-a-loadable-extension","text":"gcc -g -fPIC -shared YourCode.c -o YourCode.so NOTE: \u5176\u5b9e\u5c31\u662f\u666e\u901a\u7684\u7f16\u8bd1so\u7684\u65b9\u5f0f","title":"3. Compiling A Loadable Extension"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#4-programming-loadable-extensions","text":"NOTE: \u4e0d\u540c\u7684\u7c7b\u578b\u7684extension\u4f7f\u7528\u4e0d\u540c\u7684\u5b9e\u73b0","title":"4. Programming Loadable Extensions"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#5-persistent-loadable-extensions","text":"The default behavior for a loadable extension is that it is unloaded from process memory when the database connection that originally invoked sqlite3_load_extension() closes. However, if the initialization procedure returns SQLITE_OK_LOAD_PERMANENTLY instead of SQLITE_OK , then the extension will not be unloaded ( xDlClose will not be invoked) and the extension will remain in process memory indefinitely. The SQLITE_OK_LOAD_PERMANENTLY return value is useful for extensions that want to register new VFSes . To clarify: an extension for which the initialization function returns SQLITE_OK_LOAD_PERMANENTLY continues to exist in memory after the database connection closes. However, the extension is not automatically registered with subsequent database connections. This makes it possible to load extensions that implement new VFSes . To persistently load and register an extension that implements new SQL functions , collating sequences, and/or virtual tables, such that those added capabilities are available to all subsequent database connections, then the initialization routine should also invoke sqlite3_auto_extension() on a subfunction that will register those services. NOTE:\u81ea\u52a8load\u3001register\u7279\u6027\u975e\u5e38\u91cd\u8981\u3002 \u5bf9\u4e8e SQL functions \uff0c\u8c8c\u4f3c\u5b83\u4eec\u5fc5\u987b\u8981persistently load and register \u3002 The vfsstat.c extension show an example of a loadable extension that persistently registers both a new VFS and a new virtual table. The sqlite3_vfsstat_init() initialization routine in that extension is called only once, when the extension is first loaded. It registers the new \"vfslog\" VFS just that one time, and it returns SQLITE_OK_LOAD_PERMANENTLY so that the code used to implement the \"vfslog\" VFS will remain in memory. The initialization routine also invokes sqlite3_auto_extension() on a pointer to the \" vstatRegister() \" function so that all subsequent database connections will invoke the \" vstatRegister() \" function as they start up, and hence register the \"vfsstat\" virtual table.","title":"5. Persistent Loadable Extensions"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#6-statically-linking-a-run-time-loadable-extension","text":"","title":"6. Statically Linking A Run-Time Loadable Extension"},{"location":"Implementation/SQLite/doc/Extensions/Run-Time-Loadable-Extensions/#7-implementation-details","text":"SQLite implements run-time extension loading using the xDlOpen() , xDlError() , xDlSym() , and xDlClose() methods of the sqlite3_vfs object. These methods are implemented using the dlopen() library on unix (which explains why SQLite commonly need to be linked against the \" -ldl \" library on unix systems) and using LoadLibrary() API on Windows. In a custom VFS for unusual systems, these methods can all be omitted, in which case the run-time extension loading mechanism will not work (though you will still be able to statically link the extension code, assuming the entry pointers are uniquely named). SQLite can be compiled with SQLITE_OMIT_LOAD_EXTENSION to omit the extension loading code from the build. NOTE: \u5173\u4e8e dlopen \uff0c\u53c2\u89c1\u5de5\u7a0bLinux-OS\u7684 Programming\\Object-file\\Shared-library","title":"7. Implementation Details"},{"location":"Implementation/SQLite/doc/Programming-Interfaces/How-To-Compile-SQLite/","text":"How To Compile SQLite # NOTE: \u5bf9\u4e8e\u4ec5\u4ec5\u662f\u4f7f\u7528\u7684\u4eba\u800c\u8a00\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0cAmalgamation \u6bd4 Individual Source Files \u7b80\u5355\uff1b\u5bf9\u4e8e\u5f00\u53d1\u8005\u800c\u8a00\uff0c\u5219\u540e\u8005\u66f4\u52a0\u6e05\u6670\u3002","title":"How-To-Compile-SQLite"},{"location":"Implementation/SQLite/doc/Programming-Interfaces/How-To-Compile-SQLite/#how-to-compile-sqlite","text":"NOTE: \u5bf9\u4e8e\u4ec5\u4ec5\u662f\u4f7f\u7528\u7684\u4eba\u800c\u8a00\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0cAmalgamation \u6bd4 Individual Source Files \u7b80\u5355\uff1b\u5bf9\u4e8e\u5f00\u53d1\u8005\u800c\u8a00\uff0c\u5219\u540e\u8005\u66f4\u52a0\u6e05\u6670\u3002","title":"How To Compile SQLite"},{"location":"Implementation/SQLite/doc/Programming-Interfaces/Setting-The-Result-Of-An-SQL-Function/","text":"Setting The Result Of An SQL Function # The sqlite3_result_text() , sqlite3_result_text16() , sqlite3_result_text16le() , and sqlite3_result_text16be() interfaces set the return value of the application-defined function to be a text string which is represented as UTF-8, UTF-16 native byte order, UTF-16 little endian, or UTF-16 big endian, respectively. The sqlite3_result_text64() interface sets the return value of an application-defined function to be a text string in an encoding specified by the fifth (and last) parameter, which must be one of SQLITE_UTF8 , SQLITE_UTF16 , SQLITE_UTF16BE , or SQLITE_UTF16LE . SQLite takes the text result from the application from the 2nd parameter of the sqlite3_result_text* interfaces. If the 3rd parameter to the sqlite3_result_text* interfaces is negative, then SQLite takes result text from the 2nd parameter through the first zero character. If the 3rd parameter to the sqlite3_result_text* interfaces is non-negative, then as many bytes (not characters) of the text pointed to by the 2nd parameter are taken as the application-defined function result. If the 3rd parameter is non-negative, then it must be the byte offset into the string where the NUL terminator would appear if the string where NUL terminated. If any NUL characters occur in the string at a byte offset that is less than the value of the 3rd parameter, then the resulting string will contain embedded NULs and the result of expressions operating on strings with embedded NULs is undefined. If the 4th parameter to the sqlite3_result_text* interfaces or sqlite3_result_blob is a non-NULL pointer, then SQLite calls that function as the destructor on the text or BLOB result when it has finished using that result. If the 4th parameter to the sqlite3_result_text* interfaces or to sqlite3_result_blob is the special constant SQLITE_STATIC , then SQLite assumes that the text or BLOB result is in constant space and does not copy the content of the parameter nor call a destructor on the content when it has finished using that result. If the 4th parameter to the sqlite3_result_text* interfaces or sqlite3_result_blob is the special constant SQLITE_TRANSIENT then SQLite makes a copy of the result into space obtained from sqlite3_malloc() before it returns.","title":"Setting-The-Result-Of-An-SQL-Function"},{"location":"Implementation/SQLite/doc/Programming-Interfaces/Setting-The-Result-Of-An-SQL-Function/#setting-the-result-of-an-sql-function","text":"The sqlite3_result_text() , sqlite3_result_text16() , sqlite3_result_text16le() , and sqlite3_result_text16be() interfaces set the return value of the application-defined function to be a text string which is represented as UTF-8, UTF-16 native byte order, UTF-16 little endian, or UTF-16 big endian, respectively. The sqlite3_result_text64() interface sets the return value of an application-defined function to be a text string in an encoding specified by the fifth (and last) parameter, which must be one of SQLITE_UTF8 , SQLITE_UTF16 , SQLITE_UTF16BE , or SQLITE_UTF16LE . SQLite takes the text result from the application from the 2nd parameter of the sqlite3_result_text* interfaces. If the 3rd parameter to the sqlite3_result_text* interfaces is negative, then SQLite takes result text from the 2nd parameter through the first zero character. If the 3rd parameter to the sqlite3_result_text* interfaces is non-negative, then as many bytes (not characters) of the text pointed to by the 2nd parameter are taken as the application-defined function result. If the 3rd parameter is non-negative, then it must be the byte offset into the string where the NUL terminator would appear if the string where NUL terminated. If any NUL characters occur in the string at a byte offset that is less than the value of the 3rd parameter, then the resulting string will contain embedded NULs and the result of expressions operating on strings with embedded NULs is undefined. If the 4th parameter to the sqlite3_result_text* interfaces or sqlite3_result_blob is a non-NULL pointer, then SQLite calls that function as the destructor on the text or BLOB result when it has finished using that result. If the 4th parameter to the sqlite3_result_text* interfaces or to sqlite3_result_blob is the special constant SQLITE_STATIC , then SQLite assumes that the text or BLOB result is in constant space and does not copy the content of the parameter nor call a destructor on the content when it has finished using that result. If the 4th parameter to the sqlite3_result_text* interfaces or sqlite3_result_blob is the special constant SQLITE_TRANSIENT then SQLite makes a copy of the result into space obtained from sqlite3_malloc() before it returns.","title":"Setting The Result Of An SQL Function"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/","text":"Architecture of SQLite # Introduction # A nearby diagram shows the main components of SQLite and how they interoperate. The text below explains the roles of the various components. NOTE: \u4e0b\u9762\u8fd9\u79cd\u56fe\u662f\u6e90\u81ea\u4e8e The SQLite OS Interface or \"VFS\" \uff0c\u5b83\u4ee5\u5c42\u6b21\u5316\u7684\u7ed3\u6784\u5c55\u793a\u4e86sqlite\u7684architecture\u3002 Overview # SQLite works by compiling SQL text into bytecode , then running that bytecode using a virtual machine. interface function sqlite3_prepare_v2() and related interfaces compiler for converting SQL text into bytecode \u5bf9\u5e94\u7684\u662f\u4e0a\u56fe\u4e2d\u7684sql compiler sqlite3_stmt object container for a single bytecode program using to implement a single SQL statement sqlite3_step() interface passes a bytecode program into the virtual machine, and runs the program until it either completes, or forms a row of result to be returned, or hits a fatal error, or is interrupted Interface # Tokenizer # When a string containing SQL statements is to be evaluated it is first sent to the tokenizer. The tokenizer breaks the SQL text into tokens and hands those tokens one by one to the parser. The tokenizer is hand-coded in the file tokenize.c . Note that in this design, the tokenizer calls the parser. People who are familiar with YACC and BISON may be accustomed to doing things the other way around \u2014 having the parser call the tokenizer. Having the tokenizer call the parser is better, though, because it can be made threadsafe and it runs faster. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff0csqlite\u7684tokenizer\u662f\u81ea\u5df1\u5b9e\u73b0\u7684\uff0c\u5e76\u6ca1\u6709\u4f7f\u7528 Lex (software) Parser # The parser assigns meaning to tokens based on their context. The parser for SQLite is generated using the Lemon parser generator . Code Generator # NOTE: \u8fd9\u4e2a\u6b65\u9aa4\u662f\u6700\u6700\u590d\u6742\u7684\uff0c\u5b83\u9700\u8981\u8003\u8651database\u7684\u5e95\u5c42\u5b9e\u73b0\uff0c\u6bd4\u5982table\u662f\u5982\u4f55\u5b9e\u73b0\u7684\uff1b\u7136\u540e\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684code After the parser assembles tokens into a parse tree , the code generator runs to analyze the parser tree and generate bytecode that performs the work of the SQL statement. Bytecode Engine # The bytecode program created by the code generator is run by a virtual machine. SQLite implements SQL functions using callbacks to C-language routines. Even the built-in SQL functions are implemented this way. B-Tree # NOTE: \u5173\u4e8eB-Tree\uff0c\u53c2\u89c1\u5de5\u7a0bdiscrete\u3002 An SQLite database is maintained on disk using a B-tree implementation found in the btree.c source file. OS Interface # In order to provide portability between across operating systems, SQLite uses abstract object called the VFS . NOTE: VFS\u662fvirtual file system\uff0c\u663e\u7136\u5b83\u662f\u4e00\u79cdabstraction Utilities #","title":"Architecture-of-SQLite"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#architecture-of-sqlite","text":"","title":"Architecture of SQLite"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#introduction","text":"A nearby diagram shows the main components of SQLite and how they interoperate. The text below explains the roles of the various components. NOTE: \u4e0b\u9762\u8fd9\u79cd\u56fe\u662f\u6e90\u81ea\u4e8e The SQLite OS Interface or \"VFS\" \uff0c\u5b83\u4ee5\u5c42\u6b21\u5316\u7684\u7ed3\u6784\u5c55\u793a\u4e86sqlite\u7684architecture\u3002","title":"Introduction"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#overview","text":"SQLite works by compiling SQL text into bytecode , then running that bytecode using a virtual machine. interface function sqlite3_prepare_v2() and related interfaces compiler for converting SQL text into bytecode \u5bf9\u5e94\u7684\u662f\u4e0a\u56fe\u4e2d\u7684sql compiler sqlite3_stmt object container for a single bytecode program using to implement a single SQL statement sqlite3_step() interface passes a bytecode program into the virtual machine, and runs the program until it either completes, or forms a row of result to be returned, or hits a fatal error, or is interrupted","title":"Overview"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#interface","text":"","title":"Interface"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#tokenizer","text":"When a string containing SQL statements is to be evaluated it is first sent to the tokenizer. The tokenizer breaks the SQL text into tokens and hands those tokens one by one to the parser. The tokenizer is hand-coded in the file tokenize.c . Note that in this design, the tokenizer calls the parser. People who are familiar with YACC and BISON may be accustomed to doing things the other way around \u2014 having the parser call the tokenizer. Having the tokenizer call the parser is better, though, because it can be made threadsafe and it runs faster. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff0csqlite\u7684tokenizer\u662f\u81ea\u5df1\u5b9e\u73b0\u7684\uff0c\u5e76\u6ca1\u6709\u4f7f\u7528 Lex (software)","title":"Tokenizer"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#parser","text":"The parser assigns meaning to tokens based on their context. The parser for SQLite is generated using the Lemon parser generator .","title":"Parser"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#code-generator","text":"NOTE: \u8fd9\u4e2a\u6b65\u9aa4\u662f\u6700\u6700\u590d\u6742\u7684\uff0c\u5b83\u9700\u8981\u8003\u8651database\u7684\u5e95\u5c42\u5b9e\u73b0\uff0c\u6bd4\u5982table\u662f\u5982\u4f55\u5b9e\u73b0\u7684\uff1b\u7136\u540e\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684code After the parser assembles tokens into a parse tree , the code generator runs to analyze the parser tree and generate bytecode that performs the work of the SQL statement.","title":"Code Generator"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#bytecode-engine","text":"The bytecode program created by the code generator is run by a virtual machine. SQLite implements SQL functions using callbacks to C-language routines. Even the built-in SQL functions are implemented this way.","title":"Bytecode Engine"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#b-tree","text":"NOTE: \u5173\u4e8eB-Tree\uff0c\u53c2\u89c1\u5de5\u7a0bdiscrete\u3002 An SQLite database is maintained on disk using a B-tree implementation found in the btree.c source file.","title":"B-Tree"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#os-interface","text":"In order to provide portability between across operating systems, SQLite uses abstract object called the VFS . NOTE: VFS\u662fvirtual file system\uff0c\u663e\u7136\u5b83\u662f\u4e00\u79cdabstraction","title":"OS Interface"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Architecture-of-SQLite/#utilities","text":"","title":"Utilities"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/TODO/","text":"TODO # SQLite\u5982\u4f55\u6839\u636eAST\u6765\u751f\u6210command\uff1f # \u4e5f\u5c31\u662f\u5b83\u7684code generation\u8fc7\u7a0b\u3002","title":"TODO"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/TODO/#todo","text":"","title":"TODO"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/TODO/#sqliteastcommand","text":"\u4e5f\u5c31\u662f\u5b83\u7684code generation\u8fc7\u7a0b\u3002","title":"SQLite\u5982\u4f55\u6839\u636eAST\u6765\u751f\u6210command\uff1f"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/","text":"The Virtual Table Mechanism Of SQLite # 1. Introduction # A virtual table is an object that is registered with an open SQLite database connection . From the perspective of an SQL statement , the virtual table object looks like any other table or view. But behind the scenes, queries and updates on a virtual table invoke callback methods of the virtual table object instead of reading and writing on the database file. NOTE: \u663e\u7136\uff0cvirtual table is an abstraction\uff1bvirtual table\u7684callback method\uff0c\u5728\u201c2. Virtual Table Methods\u201d\u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002 One cannot create a trigger on a virtual table. One cannot create additional indices on a virtual table. (Virtual tables can have indices but that must be built into the virtual table implementation. Indices cannot be added separately using CREATE INDEX statements.) One cannot run ALTER TABLE ... ADD COLUMN commands against a virtual table. NOTE: \u4e0a\u8ff0cannot\u8981\u5982\u4f55\u7406\u89e3\uff1f\u662f\u6307\u4e00\u65e6\u7528\u6237\u63d0\u4ea4\u4e86\u8fd9\u6837\u7684\u8bed\u53e5\uff0c\u5c31\u4f1a\u5bfc\u81f4\u5d29\u6e83\uff1f\u8fd8\u662f\u5bf9\u5e94\u7684\u8bed\u53e5\u65e0\u6cd5\u88ab\u6267\u884c\uff1f\u9700\u8981\u5b9e\u8df5\u6765\u9a8c\u8bc1\u3002 Individual virtual table implementations might impose additional constraints. For example, some virtual implementations might provide read-only tables. Or some virtual table implementations might allow INSERT or DELETE but not UPDATE . Or some virtual table implementations might limit the kinds of UPDATEs that can be made. NOTE: \u8fd9\u4e9bconstrain\u8981\u5982\u4f55\u6765\u5b9e\u73b0\uff1f See the list of virtual tables page for a longer list of actual virtual table implementations. 1.1. Usage # CREATE VIRTUAL TABLE # A virtual table is created using a CREATE VIRTUAL TABLE statement. NOTE:\u601d\u8003\uff1a\u5982\u4f55register module\uff1f\u8fd9\u5728\u4e0b\u9762\u7684\u201c1.2. Implementation\u201d\u7ae0\u8282\u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002 Module-argument # The format of the arguments to the module is very general. Each module-argument may contain keywords, string literals, identifiers, numbers, and punctuation. Each module-argument is passed as written (as text) into the constructor method of the virtual table implementation when the virtual table is created and that constructor is responsible for parsing and interpreting the arguments. The argument syntax is sufficiently general that a virtual table implementation can, if it wants to, interpret its arguments as column definitions in an ordinary CREATE TABLE statement. The implementation could also impose some other interpretation on the arguments. NOTE: \u7531constructor method\u6765\u5b9e\u73b0\u5bf9module-argument\u7684parsing and interpreting\uff1b \u53ef\u4ee5\u5c06column definition\u901a\u8fc7module-argument\u4f20\u5165\u3002 1.1.1. Temporary virtual tables # 1.1.2. Eponymous virtual tables # NOTE: \"eponymous\"\u7684\u610f\u601d\u662f: \u4ee5\u672c\u540d\u547d\u540d\u7684 \u6240\u8c13\u7684Eponymous virtual table\uff0c\u5176\u5b9e\u5c31\u662fsqlite\u5b9e\u73b0\u4e2d\uff0c\u4f7f\u7528\u5230\u7684virtual table\uff0c\u6bd4\u5982\u975e\u5e38\u5178\u578b\u7684\uff1a dbstat virtual table . 1.2. Implementation # The sqlite3_module structure # NOTE: \u66f4\u52a0\u51c6\u786e\u5730\u8bf4\u662f\u201cvirtual table module\u201d\uff0c\u8fd9\u4e2a\u540d\u79f0\u66f4\u597d\u7406\u89e3\u3002 Think of a module as a class from which one can construct multiple virtual tables having similar properties. For example, one might have a module that provides read-only access to comma-separated-value (CSV) files on disk. That one module can then be used to create several virtual tables where each virtual table refers to a different CSV file. NOTE: \u4e5f\u5c31\u662f\u8bf4\uff0c\u4e00\u7c7bvirtual table\uff0c\u9700\u8981\u5b9e\u73b0\u4e00\u4e2avirtual table module\uff0c\u6bd4\u5982\u4e0a\u9762\u63d0\u53ca\u7684\uff1a read-only access to comma-separated-value (CSV) files\u3002 struct sqlite3_module { int iVersion; int (*xCreate)(sqlite3*, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr); int (*xConnect)(sqlite3*, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr); int (*xBestIndex)(sqlite3_vtab *pVTab, sqlite3_index_info*); int (*xDisconnect)(sqlite3_vtab *pVTab); int (*xDestroy)(sqlite3_vtab *pVTab); int (*xOpen)(sqlite3_vtab *pVTab, sqlite3_vtab_cursor **ppCursor); int (*xClose)(sqlite3_vtab_cursor*); int (*xFilter)(sqlite3_vtab_cursor*, int idxNum, const char *idxStr, int argc, sqlite3_value **argv); int (*xNext)(sqlite3_vtab_cursor*); int (*xEof)(sqlite3_vtab_cursor*); int (*xColumn)(sqlite3_vtab_cursor*, sqlite3_context*, int); int (*xRowid)(sqlite3_vtab_cursor*, sqlite_int64 *pRowid); int (*xUpdate)(sqlite3_vtab *, int, sqlite3_value **, sqlite_int64 *); int (*xBegin)(sqlite3_vtab *pVTab); int (*xSync)(sqlite3_vtab *pVTab); int (*xCommit)(sqlite3_vtab *pVTab); int (*xRollback)(sqlite3_vtab *pVTab); int (*xFindFunction)(sqlite3_vtab *pVtab, int nArg, const char *zName, void (**pxFunc)(sqlite3_context*,int,sqlite3_value**), void **ppArg); int (*Rename)(sqlite3_vtab *pVtab, const char *zNew); /* The methods above are in version 1 of the sqlite_module object. Those ** below are for version 2 and greater. */ int (*xSavepoint)(sqlite3_vtab *pVTab, int); int (*xRelease)(sqlite3_vtab *pVTab, int); int (*xRollbackTo)(sqlite3_vtab *pVTab, int); /* The methods above are in versions 1 and 2 of the sqlite_module object. ** Those below are for version 3 and greater. */ int (*xShadowName)(const char*); }; NOTE: \u4f20\u5165\u4e00\u4e2a sqlite3_module \u5b9e\u4f8b\uff0c\u8be5\u5b9e\u4f8b\u7684\u6bcf\u4e2a\u6210\u5458\u6307\u5411\u5bf9\u5e94\u7684\u5b9e\u73b0\u51fd\u6570 The module structure defines all of the methods for each virtual table object. The sqlite3_vtab structure # struct sqlite3_vtab { const sqlite3_module *pModule; int nRef; char *zErrMsg; }; Virtual table implementations will normally subclass this structure to add additional private and implementation-specific fields. NOTE: \u5982\u4f55\u5b9e\u73b0subclass\uff1fC\u4e2d\u8c8c\u4f3c\u6ca1\u6709subclass\u673a\u5236\uff1b\u5728File ext/misc/csv.c from the latest check-in \u4e2d\u7ed9\u51fa\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u4f8b\u5b50: C /* An instance of the CSV virtual table */ typedef struct CsvTable { sqlite3_vtab base; /* Base class. Must be first */ char *zFilename; /* Name of the CSV file */ char *zData; /* Raw CSV data in lieu of zFilename */ long iStart; /* Offset to start of data in zFilename */ int nCol; /* Number of columns in the CSV file */ unsigned int tstFlags; /* Bit values used for testing */ } CsvTable; The nRef field is used internally by the SQLite core and should not be altered by the virtual table implementation. The virtual table implementation may pass error message text to the core by putting an error message string in zErrMsg . Space to hold this error message string must be obtained from an SQLite memory allocation function such as sqlite3_mprintf() or sqlite3_malloc() . Prior to assigning a new value to zErrMsg , the virtual table implementation must free any preexisting content of zErrMsg using sqlite3_free() . Failure to do this will result in a memory leak. NOTE: \u770b\u4e86\uff0csqlite\u662f\u81ea\u5df1\u5b9e\u73b0\u7684memory management\u3002 The sqlite3_vtab_cursor structure # NOTE: sqlite3_vtab_cursor \u5176\u5b9e\u76f8\u5f53\u4e8e\u4e00\u4e2a pointer\uff0c\u8fd9\u4e2a\u7ed3\u6784\u975e\u5e38\u91cd\u8981\uff0c\u540e\u7eed\u7684\u5f88\u591a\u64cd\u4f5c\u90fd\u662f\u5728\u5b83\u7684\u57fa\u7840\u4e0a\u5b8c\u6210\u7684\uff0c\u5728\"2. Virtual Table Methods\"\u7ae0\u8282\u4e2d\uff0c\u4f1a\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002 Once again, practical implementations will likely subclass this structure to add additional private fields. NOTE:\u5728File ext/misc/csv.c from the latest check-in \u4e2d\u7ed9\u51fa\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u4f8b\u5b50: C /* A cursor for the CSV virtual table */ typedef struct CsvCursor { sqlite3_vtab_cursor base; /* Base class. Must be first */ CsvReader rdr; /* The CsvReader object */ char **azVal; /* Value of the current row */ int *aLen; /* Length of each entry */ sqlite3_int64 iRowid; /* The current rowid. Negative for EOF */ } CsvCursor; Register module: sqlite3_create_module # Before a CREATE VIRTUAL TABLE statement can be run, the module specified in that statement must be registered with the database connection. This is accomplished using either of the sqlite3_create_module() or sqlite3_create_module_v2() interfaces. int sqlite3_create_module( sqlite3 *db, /* SQLite connection to register module with */ const char *zName, /* Name of the module */ const sqlite3_module *, /* Methods for the module */ void * /* Client data for xCreate/xConnect */ ); int sqlite3_create_module_v2( sqlite3 *db, /* SQLite connection to register module with */ const char *zName, /* Name of the module */ const sqlite3_module *, /* Methods for the module */ void *, /* Client data for xCreate/xConnect */ void(*xDestroy)(void*) /* Client data destructor function */ ); 1.3. Virtual Tables And Shared Cache # 1.4. Creating New Virtual Table Implementations # NOTE: virtual table module\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f: \u5b9e\u73b0\u65b9\u5f0f \u8bf4\u660e Run-Time Loadable Extensions \u548cSQLite\u7f16\u8bd1\u5230\u4e00\u8d77 2. Virtual Table Methods # Summary of methods # NOTE: \u672c\u6bb5\u662f\u6211\u6dfb\u52a0\u7684\uff0c\u539f\u6587\u5e76\u6ca1\u6709 method explanation xCreate CREATE VIRTUAL TABLE xConnect establish a new connection to an existing virtual table xBestIndex the best way to access the virtual table xDisconnect destructor for a connection to the virtual table xDestroy DROP TABLE statement xOpen creates a new cursor used for accessing (read and/or writing) a virtual table required xClose closes a cursor previously opened by xOpen . xEof xFilter begins a search of a virtual table xNext xColumn required xUpdate insert, delete, or update stack order: \u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\u3002 \u64cd\u4f5ccursor\u7684method: \u90fd\u662frequired 1) xOpen \u590d\u4f4dcursor 2) xClose 3) xEof \u5224\u65ad\u662f\u5426\u5230\u8fbe\u672b\u5c3e 4) xFilter 5) xNext \u79fb\u52a8cursor 2.1. The xCreate Method # int (*xCreate)(sqlite3 *db, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr); argv # \u662f\u5426\u5fc5\u4f20 \u8bf4\u660e argv[0] yes the name of the module being invoked argv[1] yes the name of the database in which the new virtual table is being created argv[2] yes the name of the new virtual table, as specified following the TABLE keyword in the CREATE VIRTUAL TABLE statement argv[4]-argv[argc-1] no the fourth and subsequent strings in the argv[] array report the arguments to the module name in the CREATE VIRTUAL TABLE statement. ppVTab # The job of this method is to construct the new virtual table object (an sqlite3_vtab object) and return a pointer to it in *ppVTab . sqlite3_declare_vtab() # The second argument to sqlite3_declare_vtab() must a zero-terminated UTF-8 string that contains a well-formed CREATE TABLE statement that defines the columns in the virtual table and their data types. The name of the table in this CREATE TABLE statement is ignored, as are all constraints. Only the column names and datatypes matter. The CREATE TABLE statement string need not to be held in persistent memory. The string can be deallocated and/or reused as soon as the sqlite3_declare_vtab() routine returns. NOTE: \u53c2\u6570 zCreateTable \u662f\u6709\u8c01\u6765\u7ec4\u7ec7\uff1f If the xCreate method is the exact same pointer as the xConnect method, that indicates that the virtual table does not need to initialize backing store. Such a virtual table can be used as an eponymous virtual table or as a named virtual table using CREATE VIRTUAL TABLE or both. NOTE: backing store\u57282.2. The xConnect Method\u4e2d\u4e5f\u6709\u6240\u63d0\u53ca\uff0c\u5e76\u4e14\u5176\u4e2d\u8fdb\u884c\u4e86\u66f4\u52a0\u8be6\u7ec6\u7684\u8bf4\u660e 2.1.1. Hidden columns in virtual tables # 2.1.2. Table-valued functions # 2.1.3. WITHOUT ROWID Virtual Tables # 2.2. The xConnect Method # The xCreate and xConnect methods are only different when the virtual table has some kind of backing store that must be initialized the first time the virtual table is created. The xCreate method creates and initializes the backing store. The xConnect method just connects to an existing backing store. 2.3. The xBestIndex Method # The SQLite core calls the xBestIndex method when it is compiling a query that involves a virtual table . In other words, SQLite calls this method when it is running sqlite3_prepare() or the equivalent. By calling this method, the SQLite core is saying to the virtual table that it needs to access some subset of the rows in the virtual table and it wants to know the most efficient way to do that access. The xBestIndex method replies with information that the SQLite core can then use to conduct an efficient search of the virtual table. 2.3.1. Inputs # 2.6. The xOpen Method # int (*xOpen)(sqlite3_vtab *pVTab, sqlite3_vtab_cursor **ppCursor); NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f: xOpen \u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570 ppCursor \u662f\u4e00\u4e2a\u4e8c\u7ea7\u6307\u9488\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u9700\u8981\u7531programmer\u6765\u5b9e\u73b0\u5bf9\u5b83\u7684allocation\uff0c\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u505a\u5462\uff1f\u6709\u5982\u4e0b\u539f\u56e0: \u5728\"1.2. Implementation\"\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\uff0c sqlite3_vtab_cursor \u662f\u5141\u8bb8subclass\u7684\uff0c\u6240\u4ee5\uff0c\u4e3a\u4e86\u80fd\u591f\u652f\u6301user subclass\uff0c\u6240\u4ee5\u5fc5\u987b\u8981\u7531user\u6765\u8fdb\u884callocation 2.9. The xFilter Method # NOTE:\u5982\u4f55\u5b9e\u73b0\u591a\u6761\u4ef6\u8fc7\u6ee4\uff1f 2.11. The xColumn Method # 2.12. The xRowid Method # NOTE: \u5982\u4f55\u6765\u5b9e\u73b0\uff1f 2.13. The xUpdate Method #","title":"Virtual-Table-Mechanism-Of-SQLite"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#the-virtual-table-mechanism-of-sqlite","text":"","title":"The Virtual Table Mechanism Of SQLite"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#1-introduction","text":"A virtual table is an object that is registered with an open SQLite database connection . From the perspective of an SQL statement , the virtual table object looks like any other table or view. But behind the scenes, queries and updates on a virtual table invoke callback methods of the virtual table object instead of reading and writing on the database file. NOTE: \u663e\u7136\uff0cvirtual table is an abstraction\uff1bvirtual table\u7684callback method\uff0c\u5728\u201c2. Virtual Table Methods\u201d\u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002 One cannot create a trigger on a virtual table. One cannot create additional indices on a virtual table. (Virtual tables can have indices but that must be built into the virtual table implementation. Indices cannot be added separately using CREATE INDEX statements.) One cannot run ALTER TABLE ... ADD COLUMN commands against a virtual table. NOTE: \u4e0a\u8ff0cannot\u8981\u5982\u4f55\u7406\u89e3\uff1f\u662f\u6307\u4e00\u65e6\u7528\u6237\u63d0\u4ea4\u4e86\u8fd9\u6837\u7684\u8bed\u53e5\uff0c\u5c31\u4f1a\u5bfc\u81f4\u5d29\u6e83\uff1f\u8fd8\u662f\u5bf9\u5e94\u7684\u8bed\u53e5\u65e0\u6cd5\u88ab\u6267\u884c\uff1f\u9700\u8981\u5b9e\u8df5\u6765\u9a8c\u8bc1\u3002 Individual virtual table implementations might impose additional constraints. For example, some virtual implementations might provide read-only tables. Or some virtual table implementations might allow INSERT or DELETE but not UPDATE . Or some virtual table implementations might limit the kinds of UPDATEs that can be made. NOTE: \u8fd9\u4e9bconstrain\u8981\u5982\u4f55\u6765\u5b9e\u73b0\uff1f See the list of virtual tables page for a longer list of actual virtual table implementations.","title":"1. Introduction"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#11-usage","text":"","title":"1.1. Usage"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#create-virtual-table","text":"A virtual table is created using a CREATE VIRTUAL TABLE statement. NOTE:\u601d\u8003\uff1a\u5982\u4f55register module\uff1f\u8fd9\u5728\u4e0b\u9762\u7684\u201c1.2. Implementation\u201d\u7ae0\u8282\u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002","title":"CREATE VIRTUAL TABLE"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#module-argument","text":"The format of the arguments to the module is very general. Each module-argument may contain keywords, string literals, identifiers, numbers, and punctuation. Each module-argument is passed as written (as text) into the constructor method of the virtual table implementation when the virtual table is created and that constructor is responsible for parsing and interpreting the arguments. The argument syntax is sufficiently general that a virtual table implementation can, if it wants to, interpret its arguments as column definitions in an ordinary CREATE TABLE statement. The implementation could also impose some other interpretation on the arguments. NOTE: \u7531constructor method\u6765\u5b9e\u73b0\u5bf9module-argument\u7684parsing and interpreting\uff1b \u53ef\u4ee5\u5c06column definition\u901a\u8fc7module-argument\u4f20\u5165\u3002","title":"Module-argument"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#111-temporary-virtual-tables","text":"","title":"1.1.1. Temporary virtual tables"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#112-eponymous-virtual-tables","text":"NOTE: \"eponymous\"\u7684\u610f\u601d\u662f: \u4ee5\u672c\u540d\u547d\u540d\u7684 \u6240\u8c13\u7684Eponymous virtual table\uff0c\u5176\u5b9e\u5c31\u662fsqlite\u5b9e\u73b0\u4e2d\uff0c\u4f7f\u7528\u5230\u7684virtual table\uff0c\u6bd4\u5982\u975e\u5e38\u5178\u578b\u7684\uff1a dbstat virtual table .","title":"1.1.2. Eponymous virtual tables"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#12-implementation","text":"","title":"1.2. Implementation"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#the-sqlite3_module-structure","text":"NOTE: \u66f4\u52a0\u51c6\u786e\u5730\u8bf4\u662f\u201cvirtual table module\u201d\uff0c\u8fd9\u4e2a\u540d\u79f0\u66f4\u597d\u7406\u89e3\u3002 Think of a module as a class from which one can construct multiple virtual tables having similar properties. For example, one might have a module that provides read-only access to comma-separated-value (CSV) files on disk. That one module can then be used to create several virtual tables where each virtual table refers to a different CSV file. NOTE: \u4e5f\u5c31\u662f\u8bf4\uff0c\u4e00\u7c7bvirtual table\uff0c\u9700\u8981\u5b9e\u73b0\u4e00\u4e2avirtual table module\uff0c\u6bd4\u5982\u4e0a\u9762\u63d0\u53ca\u7684\uff1a read-only access to comma-separated-value (CSV) files\u3002 struct sqlite3_module { int iVersion; int (*xCreate)(sqlite3*, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr); int (*xConnect)(sqlite3*, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr); int (*xBestIndex)(sqlite3_vtab *pVTab, sqlite3_index_info*); int (*xDisconnect)(sqlite3_vtab *pVTab); int (*xDestroy)(sqlite3_vtab *pVTab); int (*xOpen)(sqlite3_vtab *pVTab, sqlite3_vtab_cursor **ppCursor); int (*xClose)(sqlite3_vtab_cursor*); int (*xFilter)(sqlite3_vtab_cursor*, int idxNum, const char *idxStr, int argc, sqlite3_value **argv); int (*xNext)(sqlite3_vtab_cursor*); int (*xEof)(sqlite3_vtab_cursor*); int (*xColumn)(sqlite3_vtab_cursor*, sqlite3_context*, int); int (*xRowid)(sqlite3_vtab_cursor*, sqlite_int64 *pRowid); int (*xUpdate)(sqlite3_vtab *, int, sqlite3_value **, sqlite_int64 *); int (*xBegin)(sqlite3_vtab *pVTab); int (*xSync)(sqlite3_vtab *pVTab); int (*xCommit)(sqlite3_vtab *pVTab); int (*xRollback)(sqlite3_vtab *pVTab); int (*xFindFunction)(sqlite3_vtab *pVtab, int nArg, const char *zName, void (**pxFunc)(sqlite3_context*,int,sqlite3_value**), void **ppArg); int (*Rename)(sqlite3_vtab *pVtab, const char *zNew); /* The methods above are in version 1 of the sqlite_module object. Those ** below are for version 2 and greater. */ int (*xSavepoint)(sqlite3_vtab *pVTab, int); int (*xRelease)(sqlite3_vtab *pVTab, int); int (*xRollbackTo)(sqlite3_vtab *pVTab, int); /* The methods above are in versions 1 and 2 of the sqlite_module object. ** Those below are for version 3 and greater. */ int (*xShadowName)(const char*); }; NOTE: \u4f20\u5165\u4e00\u4e2a sqlite3_module \u5b9e\u4f8b\uff0c\u8be5\u5b9e\u4f8b\u7684\u6bcf\u4e2a\u6210\u5458\u6307\u5411\u5bf9\u5e94\u7684\u5b9e\u73b0\u51fd\u6570 The module structure defines all of the methods for each virtual table object.","title":"The sqlite3_module structure"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#the-sqlite3_vtab-structure","text":"struct sqlite3_vtab { const sqlite3_module *pModule; int nRef; char *zErrMsg; }; Virtual table implementations will normally subclass this structure to add additional private and implementation-specific fields. NOTE: \u5982\u4f55\u5b9e\u73b0subclass\uff1fC\u4e2d\u8c8c\u4f3c\u6ca1\u6709subclass\u673a\u5236\uff1b\u5728File ext/misc/csv.c from the latest check-in \u4e2d\u7ed9\u51fa\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u4f8b\u5b50: C /* An instance of the CSV virtual table */ typedef struct CsvTable { sqlite3_vtab base; /* Base class. Must be first */ char *zFilename; /* Name of the CSV file */ char *zData; /* Raw CSV data in lieu of zFilename */ long iStart; /* Offset to start of data in zFilename */ int nCol; /* Number of columns in the CSV file */ unsigned int tstFlags; /* Bit values used for testing */ } CsvTable; The nRef field is used internally by the SQLite core and should not be altered by the virtual table implementation. The virtual table implementation may pass error message text to the core by putting an error message string in zErrMsg . Space to hold this error message string must be obtained from an SQLite memory allocation function such as sqlite3_mprintf() or sqlite3_malloc() . Prior to assigning a new value to zErrMsg , the virtual table implementation must free any preexisting content of zErrMsg using sqlite3_free() . Failure to do this will result in a memory leak. NOTE: \u770b\u4e86\uff0csqlite\u662f\u81ea\u5df1\u5b9e\u73b0\u7684memory management\u3002","title":"The sqlite3_vtab structure"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#the-sqlite3_vtab_cursor-structure","text":"NOTE: sqlite3_vtab_cursor \u5176\u5b9e\u76f8\u5f53\u4e8e\u4e00\u4e2a pointer\uff0c\u8fd9\u4e2a\u7ed3\u6784\u975e\u5e38\u91cd\u8981\uff0c\u540e\u7eed\u7684\u5f88\u591a\u64cd\u4f5c\u90fd\u662f\u5728\u5b83\u7684\u57fa\u7840\u4e0a\u5b8c\u6210\u7684\uff0c\u5728\"2. Virtual Table Methods\"\u7ae0\u8282\u4e2d\uff0c\u4f1a\u5bf9\u6b64\u8fdb\u884c\u603b\u7ed3\u3002 Once again, practical implementations will likely subclass this structure to add additional private fields. NOTE:\u5728File ext/misc/csv.c from the latest check-in \u4e2d\u7ed9\u51fa\u4e86\u8fd9\u6837\u7684\u4e00\u4e2a\u4f8b\u5b50: C /* A cursor for the CSV virtual table */ typedef struct CsvCursor { sqlite3_vtab_cursor base; /* Base class. Must be first */ CsvReader rdr; /* The CsvReader object */ char **azVal; /* Value of the current row */ int *aLen; /* Length of each entry */ sqlite3_int64 iRowid; /* The current rowid. Negative for EOF */ } CsvCursor;","title":"The sqlite3_vtab_cursor structure"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#register-module-sqlite3_create_module","text":"Before a CREATE VIRTUAL TABLE statement can be run, the module specified in that statement must be registered with the database connection. This is accomplished using either of the sqlite3_create_module() or sqlite3_create_module_v2() interfaces. int sqlite3_create_module( sqlite3 *db, /* SQLite connection to register module with */ const char *zName, /* Name of the module */ const sqlite3_module *, /* Methods for the module */ void * /* Client data for xCreate/xConnect */ ); int sqlite3_create_module_v2( sqlite3 *db, /* SQLite connection to register module with */ const char *zName, /* Name of the module */ const sqlite3_module *, /* Methods for the module */ void *, /* Client data for xCreate/xConnect */ void(*xDestroy)(void*) /* Client data destructor function */ );","title":"Register module: sqlite3_create_module"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#13-virtual-tables-and-shared-cache","text":"","title":"1.3. Virtual Tables And Shared Cache"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#14-creating-new-virtual-table-implementations","text":"NOTE: virtual table module\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f: \u5b9e\u73b0\u65b9\u5f0f \u8bf4\u660e Run-Time Loadable Extensions \u548cSQLite\u7f16\u8bd1\u5230\u4e00\u8d77","title":"1.4. Creating New Virtual Table Implementations"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#2-virtual-table-methods","text":"","title":"2. Virtual Table Methods"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#summary-of-methods","text":"NOTE: \u672c\u6bb5\u662f\u6211\u6dfb\u52a0\u7684\uff0c\u539f\u6587\u5e76\u6ca1\u6709 method explanation xCreate CREATE VIRTUAL TABLE xConnect establish a new connection to an existing virtual table xBestIndex the best way to access the virtual table xDisconnect destructor for a connection to the virtual table xDestroy DROP TABLE statement xOpen creates a new cursor used for accessing (read and/or writing) a virtual table required xClose closes a cursor previously opened by xOpen . xEof xFilter begins a search of a virtual table xNext xColumn required xUpdate insert, delete, or update stack order: \u4e00\u5bf9\u76f8\u53cd\u7684\u64cd\u4f5c\u3002 \u64cd\u4f5ccursor\u7684method: \u90fd\u662frequired 1) xOpen \u590d\u4f4dcursor 2) xClose 3) xEof \u5224\u65ad\u662f\u5426\u5230\u8fbe\u672b\u5c3e 4) xFilter 5) xNext \u79fb\u52a8cursor","title":"Summary of methods"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#21-the-xcreate-method","text":"int (*xCreate)(sqlite3 *db, void *pAux, int argc, char *const*argv, sqlite3_vtab **ppVTab, char **pzErr);","title":"2.1. The xCreate Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#argv","text":"\u662f\u5426\u5fc5\u4f20 \u8bf4\u660e argv[0] yes the name of the module being invoked argv[1] yes the name of the database in which the new virtual table is being created argv[2] yes the name of the new virtual table, as specified following the TABLE keyword in the CREATE VIRTUAL TABLE statement argv[4]-argv[argc-1] no the fourth and subsequent strings in the argv[] array report the arguments to the module name in the CREATE VIRTUAL TABLE statement.","title":"argv"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#ppvtab","text":"The job of this method is to construct the new virtual table object (an sqlite3_vtab object) and return a pointer to it in *ppVTab .","title":"ppVTab"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#sqlite3_declare_vtab","text":"The second argument to sqlite3_declare_vtab() must a zero-terminated UTF-8 string that contains a well-formed CREATE TABLE statement that defines the columns in the virtual table and their data types. The name of the table in this CREATE TABLE statement is ignored, as are all constraints. Only the column names and datatypes matter. The CREATE TABLE statement string need not to be held in persistent memory. The string can be deallocated and/or reused as soon as the sqlite3_declare_vtab() routine returns. NOTE: \u53c2\u6570 zCreateTable \u662f\u6709\u8c01\u6765\u7ec4\u7ec7\uff1f If the xCreate method is the exact same pointer as the xConnect method, that indicates that the virtual table does not need to initialize backing store. Such a virtual table can be used as an eponymous virtual table or as a named virtual table using CREATE VIRTUAL TABLE or both. NOTE: backing store\u57282.2. The xConnect Method\u4e2d\u4e5f\u6709\u6240\u63d0\u53ca\uff0c\u5e76\u4e14\u5176\u4e2d\u8fdb\u884c\u4e86\u66f4\u52a0\u8be6\u7ec6\u7684\u8bf4\u660e","title":"sqlite3_declare_vtab()"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#211-hidden-columns-in-virtual-tables","text":"","title":"2.1.1. Hidden columns in virtual tables"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#212-table-valued-functions","text":"","title":"2.1.2. Table-valued functions"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#213-without-rowid-virtual-tables","text":"","title":"2.1.3. WITHOUT ROWID Virtual Tables"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#22-the-xconnect-method","text":"The xCreate and xConnect methods are only different when the virtual table has some kind of backing store that must be initialized the first time the virtual table is created. The xCreate method creates and initializes the backing store. The xConnect method just connects to an existing backing store.","title":"2.2. The xConnect Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#23-the-xbestindex-method","text":"The SQLite core calls the xBestIndex method when it is compiling a query that involves a virtual table . In other words, SQLite calls this method when it is running sqlite3_prepare() or the equivalent. By calling this method, the SQLite core is saying to the virtual table that it needs to access some subset of the rows in the virtual table and it wants to know the most efficient way to do that access. The xBestIndex method replies with information that the SQLite core can then use to conduct an efficient search of the virtual table.","title":"2.3. The xBestIndex Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#231-inputs","text":"","title":"2.3.1. Inputs"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#26-the-xopen-method","text":"int (*xOpen)(sqlite3_vtab *pVTab, sqlite3_vtab_cursor **ppCursor); NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f: xOpen \u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570 ppCursor \u662f\u4e00\u4e2a\u4e8c\u7ea7\u6307\u9488\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u9700\u8981\u7531programmer\u6765\u5b9e\u73b0\u5bf9\u5b83\u7684allocation\uff0c\u4e3a\u4ec0\u4e48\u8981\u8fd9\u6837\u505a\u5462\uff1f\u6709\u5982\u4e0b\u539f\u56e0: \u5728\"1.2. Implementation\"\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\uff0c sqlite3_vtab_cursor \u662f\u5141\u8bb8subclass\u7684\uff0c\u6240\u4ee5\uff0c\u4e3a\u4e86\u80fd\u591f\u652f\u6301user subclass\uff0c\u6240\u4ee5\u5fc5\u987b\u8981\u7531user\u6765\u8fdb\u884callocation","title":"2.6. The xOpen Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#29-the-xfilter-method","text":"NOTE:\u5982\u4f55\u5b9e\u73b0\u591a\u6761\u4ef6\u8fc7\u6ee4\uff1f","title":"2.9. The xFilter Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#211-the-xcolumn-method","text":"","title":"2.11. The xColumn Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#212-the-xrowid-method","text":"NOTE: \u5982\u4f55\u6765\u5b9e\u73b0\uff1f","title":"2.12. The xRowid Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/#213-the-xupdate-method","text":"","title":"2.13. The xUpdate Method"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/","text":"Example CSV # \u672c\u6587\u662f\u9605\u8bfb ext/misc/csv.c from the latest check-in \u7684\u7b14\u8bb0\u3002 Usage # NOTE: \u6e90\u4ee3\u7801\u4e2d\uff0c\u5934\u90e8\u7ed9\u51fa\u7684\u6ce8\u91ca\u4e2d\u8bf4\u660e\u7684usage\u5982\u4e0b\uff1a .load ./csv # \u52a0\u8f7dextension CREATE VIRTUAL TABLE temp.csv USING csv(filename=FILENAME); SELECT * FROM csv; NOTE: \u6211\u7b2c\u4e00\u6b21\u9519\u8bef\u7684\u5c06 temp.csv \u7406\u89e3\u4e3a table-name \uff0c\u4f46\u662f SELECT \u8bed\u53e5\u4e2d\u7684 table-name \u4e3a csv \uff0c\u663e\u7136\u4e0e\u524d\u9762\u7684\u77db\u76fe\u3002\u540e\u6765\u67e5\u770b\u4e86 1.1. Usage \u65b9\u77e5: temp.csv \u4e3a schema-name.table-name \u3002 The columns are named \"c1\", \"c2\", \"c3\", ... by default. Or the application can define its own CREATE TABLE statement using the schema= parameter , like this: CREATE VIRTUAL TABLE temp.csv2 USING csv( filename = \"../http.log\", schema = \"CREATE TABLE x(date,ipaddr,url,referrer,userAgent)\" ); NOTE: \u4e0a\u9762\u7684\u63cf\u8ff0\u662f\u60f3\u544a\u8bc9\u6211\u4eec\uff0c\u53ef\u4ee5\u901a\u8fc7 schema= parameter \u6765\u81ea\u5b9a\u4e49table\u7684column\u3002 Instead of specifying a file, the text of the CSV can be loaded using the data= parameter . NOTE: \u53ef\u4ee5\u901a\u8fc7file name\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7 data= parameter \u7684\u65b9\u5f0f\u6765\u6307\u5b9aCSV\u6570\u636e If the columns=N parameter is supplied, then the CSV file is assumed to have N columns. If both the columns= and schema= parameters are omitted, then the number and names of the columns is determined by the first line of the CSV input. NOTE: \u7406\u89e3usage\u975e\u5e38\u91cd\u8981\uff0c csvtabConnect \u5c31\u662f\u57fa\u4e8e\u5b83\u5b9e\u73b0\u7684\u3002 \u5b9e\u73b0\u65b9\u5f0f # \u91c7\u7528\u7684\u662f Run-Time Loadable Extensions \uff0c\u56e0\u4e3a\u5b83\u7684\u5934\u6587\u4ef6\u5305\u542b\u4e86: #include <sqlite3ext.h> sqlite3_module # \u5b83\u7684 sqlite3_module \u662f CsvModule xCreate and xConnect # call back \u5b9e\u73b0 xCreate csvtabCreate xConnect csvtabConnect \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\"The xConnect and xCreate methods do the same thing, but they must be different so that the virtual table is not an eponymous virtual table\"\uff0c\u67e5\u770b\u5176\u5b9e\u73b0\u53ef\u77e5\uff0c csvtabCreate \u76f4\u63a5\u8c03\u7528\u7684 csvtabConnect \uff0c\u5173\u4e8e\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff0c\u5728 2.2. The xConnect Method \u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002 Virtual table struct: CsvTable # \u57281.2. Implementation\u4e2d\u8bf4\u660e:\"Virtual table implementations will normally subclass this structure to add additional private and implementation-specific fields\"\uff0c\u5728\u672c\u5b9e\u73b0\u4e2d\uff0c\u5c31\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u505a\u7684: /* An instance of the CSV virtual table */ typedef struct CsvTable { sqlite3_vtab base; /* Base class. Must be first */ char *zFilename; /* Name of the CSV file */ char *zData; /* Raw CSV data in lieu of zFilename */ long iStart; /* Offset to start of data in zFilename */ int nCol; /* Number of columns in the CSV file */ unsigned int tstFlags; /* Bit values used for testing */ } CsvTable; \u9700\u8981\u5bf9\u6210\u5458\u53d8\u91cf zFilename \u548c zData \u8fdb\u884c\u7279\u6b8a\u8bf4\u660e: \u5728\"Usage\"\u7ae0\u8282\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\"Instead of specifying a file, the text of the CSV can be loaded using the data= parameter \"\uff0c\u4e5f\u5c31\u662f\u8bf4\uff1a\u53ef\u4ee5\u901a\u8fc7file name\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7 data= parameter \u7684\u65b9\u5f0f\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u6ce8\u91ca\"Raw CSV data in lieu of zFilename\"\u7684\u610f\u601d\u662f\uff1a\u539f\u59cbCSV\u6570\u636e\u4ee3\u66ffzFilename\uff0c\u4e5f\u5c31\u662f\u8bf4: \u6210\u5458\u53d8\u91cf \u8bf4\u660e zFilename \u4fdd\u5b58\u201cName of the CSV file\" zData \u4fdd\u5b58\u901a\u8fc7 data= parameter \u6307\u5b9a\u7684CSV data Virtual table cursor struct: CsvCursor # \u57281.2. Implementation\u4e2d\u8bf4\u660e:\"practical implementations will likely subclass this structure to add additional private fields.\"\uff0c\u5728\u672c\u5b9e\u73b0\u4e2d\uff0c\u5c31\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u505a\u7684: /* A cursor for the CSV virtual table */ typedef struct CsvCursor { sqlite3_vtab_cursor base; /* Base class. Must be first */ CsvReader rdr; /* The CsvReader object */ char **azVal; /* Value of the current row */ int *aLen; /* Length of each entry */ sqlite3_int64 iRowid; /* The current rowid. Negative for EOF */ } CsvCursor; CsvReader # \u5c01\u88c5\u7684csv file /* A context object used when read a CSV file. */ typedef struct CsvReader CsvReader; struct CsvReader { FILE *in; /* Read the CSV text from this input stream */ char *z; /* Accumulated text for a field */ int n; /* Number of bytes in z */ int nAlloc; /* Space allocated for z[] */ int nLine; /* Current line number */ int bNotFirst; /* True if prior text has been seen */ int cTerm; /* Character that terminated the most recent field */ size_t iIn; /* Next unread character in the input buffer */ size_t nIn; /* Number of characters in the input buffer */ char *zIn; /* The input buffer */ char zErr[CSV_MXERR]; /* Error message */ };","title":"Example-CSV"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#example-csv","text":"\u672c\u6587\u662f\u9605\u8bfb ext/misc/csv.c from the latest check-in \u7684\u7b14\u8bb0\u3002","title":"Example CSV"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#usage","text":"NOTE: \u6e90\u4ee3\u7801\u4e2d\uff0c\u5934\u90e8\u7ed9\u51fa\u7684\u6ce8\u91ca\u4e2d\u8bf4\u660e\u7684usage\u5982\u4e0b\uff1a .load ./csv # \u52a0\u8f7dextension CREATE VIRTUAL TABLE temp.csv USING csv(filename=FILENAME); SELECT * FROM csv; NOTE: \u6211\u7b2c\u4e00\u6b21\u9519\u8bef\u7684\u5c06 temp.csv \u7406\u89e3\u4e3a table-name \uff0c\u4f46\u662f SELECT \u8bed\u53e5\u4e2d\u7684 table-name \u4e3a csv \uff0c\u663e\u7136\u4e0e\u524d\u9762\u7684\u77db\u76fe\u3002\u540e\u6765\u67e5\u770b\u4e86 1.1. Usage \u65b9\u77e5: temp.csv \u4e3a schema-name.table-name \u3002 The columns are named \"c1\", \"c2\", \"c3\", ... by default. Or the application can define its own CREATE TABLE statement using the schema= parameter , like this: CREATE VIRTUAL TABLE temp.csv2 USING csv( filename = \"../http.log\", schema = \"CREATE TABLE x(date,ipaddr,url,referrer,userAgent)\" ); NOTE: \u4e0a\u9762\u7684\u63cf\u8ff0\u662f\u60f3\u544a\u8bc9\u6211\u4eec\uff0c\u53ef\u4ee5\u901a\u8fc7 schema= parameter \u6765\u81ea\u5b9a\u4e49table\u7684column\u3002 Instead of specifying a file, the text of the CSV can be loaded using the data= parameter . NOTE: \u53ef\u4ee5\u901a\u8fc7file name\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7 data= parameter \u7684\u65b9\u5f0f\u6765\u6307\u5b9aCSV\u6570\u636e If the columns=N parameter is supplied, then the CSV file is assumed to have N columns. If both the columns= and schema= parameters are omitted, then the number and names of the columns is determined by the first line of the CSV input. NOTE: \u7406\u89e3usage\u975e\u5e38\u91cd\u8981\uff0c csvtabConnect \u5c31\u662f\u57fa\u4e8e\u5b83\u5b9e\u73b0\u7684\u3002","title":"Usage"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#_1","text":"\u91c7\u7528\u7684\u662f Run-Time Loadable Extensions \uff0c\u56e0\u4e3a\u5b83\u7684\u5934\u6587\u4ef6\u5305\u542b\u4e86: #include <sqlite3ext.h>","title":"\u5b9e\u73b0\u65b9\u5f0f"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#sqlite3_module","text":"\u5b83\u7684 sqlite3_module \u662f CsvModule","title":"sqlite3_module"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#xcreate-and-xconnect","text":"call back \u5b9e\u73b0 xCreate csvtabCreate xConnect csvtabConnect \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\"The xConnect and xCreate methods do the same thing, but they must be different so that the virtual table is not an eponymous virtual table\"\uff0c\u67e5\u770b\u5176\u5b9e\u73b0\u53ef\u77e5\uff0c csvtabCreate \u76f4\u63a5\u8c03\u7528\u7684 csvtabConnect \uff0c\u5173\u4e8e\u8fd9\u6837\u505a\u7684\u539f\u56e0\uff0c\u5728 2.2. The xConnect Method \u4e2d\u8fdb\u884c\u4e86\u8be6\u7ec6\u4ecb\u7ecd\u3002","title":"xCreate and xConnect"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#virtual-table-struct-csvtable","text":"\u57281.2. Implementation\u4e2d\u8bf4\u660e:\"Virtual table implementations will normally subclass this structure to add additional private and implementation-specific fields\"\uff0c\u5728\u672c\u5b9e\u73b0\u4e2d\uff0c\u5c31\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u505a\u7684: /* An instance of the CSV virtual table */ typedef struct CsvTable { sqlite3_vtab base; /* Base class. Must be first */ char *zFilename; /* Name of the CSV file */ char *zData; /* Raw CSV data in lieu of zFilename */ long iStart; /* Offset to start of data in zFilename */ int nCol; /* Number of columns in the CSV file */ unsigned int tstFlags; /* Bit values used for testing */ } CsvTable; \u9700\u8981\u5bf9\u6210\u5458\u53d8\u91cf zFilename \u548c zData \u8fdb\u884c\u7279\u6b8a\u8bf4\u660e: \u5728\"Usage\"\u7ae0\u8282\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\"Instead of specifying a file, the text of the CSV can be loaded using the data= parameter \"\uff0c\u4e5f\u5c31\u662f\u8bf4\uff1a\u53ef\u4ee5\u901a\u8fc7file name\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7 data= parameter \u7684\u65b9\u5f0f\u6765\u6307\u5b9aCSV\u6570\u636e\uff0c\u6ce8\u91ca\"Raw CSV data in lieu of zFilename\"\u7684\u610f\u601d\u662f\uff1a\u539f\u59cbCSV\u6570\u636e\u4ee3\u66ffzFilename\uff0c\u4e5f\u5c31\u662f\u8bf4: \u6210\u5458\u53d8\u91cf \u8bf4\u660e zFilename \u4fdd\u5b58\u201cName of the CSV file\" zData \u4fdd\u5b58\u901a\u8fc7 data= parameter \u6307\u5b9a\u7684CSV data","title":"Virtual table struct: CsvTable"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#virtual-table-cursor-struct-csvcursor","text":"\u57281.2. Implementation\u4e2d\u8bf4\u660e:\"practical implementations will likely subclass this structure to add additional private fields.\"\uff0c\u5728\u672c\u5b9e\u73b0\u4e2d\uff0c\u5c31\u662f\u6309\u7167\u8fd9\u79cd\u65b9\u5f0f\u505a\u7684: /* A cursor for the CSV virtual table */ typedef struct CsvCursor { sqlite3_vtab_cursor base; /* Base class. Must be first */ CsvReader rdr; /* The CsvReader object */ char **azVal; /* Value of the current row */ int *aLen; /* Length of each entry */ sqlite3_int64 iRowid; /* The current rowid. Negative for EOF */ } CsvCursor;","title":"Virtual table cursor struct: CsvCursor"},{"location":"Implementation/SQLite/doc/Technical-and-Design-Documentation/Virtual-Table-Mechanism-Of-SQLite/Example-CSV/#csvreader","text":"\u5c01\u88c5\u7684csv file /* A context object used when read a CSV file. */ typedef struct CsvReader CsvReader; struct CsvReader { FILE *in; /* Read the CSV text from this input stream */ char *z; /* Accumulated text for a field */ int n; /* Number of bytes in z */ int nAlloc; /* Space allocated for z[] */ int nLine; /* Current line number */ int bNotFirst; /* True if prior text has been seen */ int cTerm; /* Character that terminated the most recent field */ size_t iIn; /* Next unread character in the input buffer */ size_t nIn; /* Number of characters in the input buffer */ char *zIn; /* The input buffer */ char zErr[CSV_MXERR]; /* Error message */ };","title":"CsvReader"},{"location":"Implementation/SQLite/src/sqlite/","text":"SQLite Source Repository This repository contains the complete source code for the SQLite database engine . Some test scripts are also included. However, many other test scripts and most of the documentation are managed separately. Version Control # SQLite sources are managed using the Fossil , a distributed version control system that was specifically designed and written to support SQLite development. The Fossil repository contains the urtext. If you are reading this on GitHub or some other Git repository or service, then you are looking at a mirror. The names of check-ins and other artifacts in a Git mirror are different from the official names for those objects. The offical names for check-ins are found in a footer on the check-in comment for authorized mirrors. The official check-in name can also be seen in the manifest.uuid file in the root of the tree. Always use the official name, not the Git-name, when communicating about an SQLite check-in. If you pulled your SQLite source code from a secondary source and want to verify its integrity, there are hints on how to do that in the Verifying Code Authenticity section below. Obtaining The Code # If you do not want to use Fossil, you can download tarballs or ZIP archives or SQLite archives as follows: Lastest trunk check-in as Tarball , ZIP-archive , or SQLite-archive . Latest release as Tarball , ZIP-archive , or SQLite-archive . For other check-ins, substitute an appropriate branch name or tag or hash prefix in place of \"release\" in the URLs of the previous bullet. Or browse the timeline to locate the check-in desired, click on its information page link, then click on the \"Tarball\" or \"ZIP Archive\" links on the information page. If you do want to use Fossil to check out the source tree, first install Fossil version 2.0 or later. (Source tarballs and precompiled binaries available here . Fossil is a stand-alone program. To install, simply download or build the single executable file and put that file someplace on your $PATH.) Then run commands like this: mkdir ~/sqlite cd ~/sqlite fossil clone https://www.sqlite.org/src sqlite.fossil fossil open sqlite.fossil After setting up a repository using the steps above, you can always update to the lastest version using: fossil update trunk ;# latest trunk check-in fossil update release ;# latest official release Or type \"fossil ui\" to get a web-based user interface. Compiling # First create a directory in which to place the build products. It is recommended, but not required, that the build directory be separate from the source directory. Cd into the build directory and then from the build directory run the configure script found at the root of the source tree. Then run \"make\". For example: tar xzf sqlite.tar.gz ;# Unpack the source tree into \"sqlite\" mkdir bld ;# Build will occur in a sibling directory cd bld ;# Change to the build directory ../sqlite/configure ;# Run the configure script make ;# Run the makefile. make sqlite3.c ;# Build the \"amalgamation\" source file make test ;# Run some tests (requires Tcl) See the makefile for additional targets. The configure script uses autoconf 2.61 and libtool. If the configure script does not work out for you, there is a generic makefile named \"Makefile.linux-gcc\" in the top directory of the source tree that you can copy and edit to suit your needs. Comments on the generic makefile show what changes are needed. Using MSVC # On Windows, all applicable build products can be compiled with MSVC. First open the command prompt window associated with the desired compiler version (e.g. \"Developer Command Prompt for VS2013\"). Next, use NMAKE with the provided \"Makefile.msc\" to build one of the supported targets. For example: mkdir bld cd bld nmake /f Makefile.msc TOP=..\\sqlite nmake /f Makefile.msc sqlite3.c TOP=..\\sqlite nmake /f Makefile.msc sqlite3.dll TOP=..\\sqlite nmake /f Makefile.msc sqlite3.exe TOP=..\\sqlite nmake /f Makefile.msc test TOP=..\\sqlite There are several build options that can be set via the NMAKE command line. For example, to build for WinRT, simply add \"FOR_WINRT=1\" argument to the \"sqlite3.dll\" command line above. When debugging into the SQLite code, adding the \"DEBUG=1\" argument to one of the above command lines is recommended. SQLite does not require Tcl to run, but a Tcl installation is required by the makefiles (including those for MSVC). SQLite contains a lot of generated code and Tcl is used to do much of that code generation. Source Code Tour # Most of the core source files are in the src/ subdirectory. The src/ folder also contains files used to build the \"testfixture\" test harness. The names of the source files used by \"testfixture\" all begin with \"test\". The src/ also contains the \"shell.c\" file which is the main program for the \"sqlite3.exe\" command-line shell and the \"tclsqlite.c\" file which implements the Tcl bindings for SQLite. (Historical note: SQLite began as a Tcl extension and only later escaped to the wild as an independent library.) Test scripts and programs are found in the test/ subdirectory. Addtional test code is found in other source repositories. See How SQLite Is Tested for additional information. The ext/ subdirectory contains code for extensions. The Full-text search engine is in ext/fts3 . The R-Tree engine is in ext/rtree . The ext/misc subdirectory contains a number of smaller, single-file extensions, such as a REGEXP operator. The tool/ subdirectory contains various scripts and programs used for building generated source code files or for testing or for generating accessory programs such as \"sqlite3_analyzer(.exe)\". Generated Source Code Files # Several of the C-language source files used by SQLite are generated from other sources rather than being typed in manually by a programmer. This section will summarize those automatically-generated files. To create all of the automatically-generated files, simply run \"make target_source\". The \"target_source\" make target will create a subdirectory \"tsrc/\" and fill it with all the source files needed to build SQLite, both manually-edited files and automatically-generated files. The SQLite interface is defined by the sqlite3.h header file, which is generated from src/sqlite.h.in, ./manifest.uuid, and ./VERSION. The Tcl script at tool/mksqlite3h.tcl does the conversion. The manifest.uuid file contains the SHA3 hash of the particular check-in and is used to generate the SQLITE_SOURCE_ID macro. The VERSION file contains the current SQLite version number. The sqlite3.h header is really just a copy of src/sqlite.h.in with the source-id and version number inserted at just the right spots. Note that comment text in the sqlite3.h file is used to generate much of the SQLite API documentation. The Tcl scripts used to generate that documentation are in a separate source repository. The SQL language parser is parse.c which is generate from a grammar in the src/parse.y file. The conversion of \"parse.y\" into \"parse.c\" is done by the lemon LALR(1) parser generator. The source code for lemon is at tool/lemon.c. Lemon uses the tool/lempar.c file as a template for generating its parser. Lemon also generates the parse.h header file, at the same time it generates parse.c. The opcodes.h header file contains macros that define the numbers corresponding to opcodes in the \"VDBE\" virtual machine. The opcodes.h file is generated by the scanning the src/vdbe.c source file. The Tcl script at ./mkopcodeh.tcl does this scan and generates opcodes.h. A second Tcl script, ./mkopcodec.tcl, then scans opcodes.h to generate the opcodes.c source file, which contains a reverse mapping from opcode-number to opcode-name that is used for EXPLAIN output. The keywordhash.h header file contains the definition of a hash table that maps SQL language keywords (ex: \"CREATE\", \"SELECT\", \"INDEX\", etc.) into the numeric codes used by the parse.c parser. The keywordhash.h file is generated by a C-language program at tool mkkeywordhash.c. The pragma.h header file contains various definitions used to parse and implement the PRAGMA statements. The header is generated by a script tool/mkpragmatab.tcl . If you want to add a new PRAGMA, edit the tool/mkpragmatab.tcl file to insert the information needed by the parser for your new PRAGMA, then run the script to regenerate the pragma.h header file. The Amalgamation # All of the individual C source code and header files (both manually-edited and automatically-generated) can be combined into a single big source file sqlite3.c called \"the amalgamation\". The amalgamation is the recommended way of using SQLite in a larger application. Combining all individual source code files into a single big source code file allows the C compiler to perform more cross-procedure analysis and generate better code. SQLite runs about 5% faster when compiled from the amalgamation versus when compiled from individual source files. The amalgamation is generated from the tool/mksqlite3c.tcl Tcl script. First, all of the individual source files must be gathered into the tsrc/ subdirectory (using the equivalent of \"make target_source\") then the tool/mksqlite3c.tcl script is run to copy them all together in just the right order while resolving internal \"#include\" references. The amalgamation source file is more than 200K lines long. Some symbolic debuggers (most notably MSVC) are unable to deal with files longer than 64K lines. To work around this, a separate Tcl script, tool/split-sqlite3c.tcl, can be run on the amalgamation to break it up into a single small C file called sqlite3-all.c that does #include on about seven other files named sqlite3-1.c , sqlite3-2.c , ..., sqlite3-7.c . In this way, all of the source code is contained within a single translation unit so that the compiler can do extra cross-procedure optimization, but no individual source file exceeds 32K lines in length. How It All Fits Together # SQLite is modular in design. See the architectural description for details. Other documents that are useful in (helping to understand how SQLite works include the file format description, the virtual machine that runs prepared statements, the description of how transactions work , and the overview of the query planner . Years of effort have gone into optimizating SQLite, both for small size and high performance. And optimizations tend to result in complex code. So there is a lot of complexity in the current SQLite implementation. It will not be the easiest library in the world to hack. Key files: sqlite.h.in - This file defines the public interface to the SQLite library. Readers will need to be familiar with this interface before trying to understand how the library works internally. sqliteInt.h - this header file defines many of the data objects used internally by SQLite. In addition to \"sqliteInt.h\", some subsystems have their own header files. parse.y - This file describes the LALR(1) grammar that SQLite uses to parse SQL statements, and the actions that are taken at each step in the parsing process. vdbe.c - This file implements the virtual machine that runs prepared statements. There are various helper files whose names begin with \"vdbe\". The VDBE has access to the vdbeInt.h header file which defines internal data objects. The rest of SQLite interacts with the VDBE through an interface defined by vdbe.h. where.c - This file (together with its helper files named by \"where*.c\") analyzes the WHERE clause and generates virtual machine code to run queries efficiently. This file is sometimes called the \"query optimizer\". It has its own private header file, whereInt.h, that defines data objects used internally. btree.c - This file contains the implementation of the B-Tree storage engine used by SQLite. The interface to the rest of the system is defined by \"btree.h\". The \"btreeInt.h\" header defines objects used internally by btree.c and not published to the rest of the system. pager.c - This file contains the \"pager\" implementation, the module that implements transactions. The \"pager.h\" header file defines the interface between pager.c and the rest of the system. os_unix.c and os_win.c - These two files implement the interface between SQLite and the underlying operating system using the run-time pluggable VFS interface. shell.c.in - This file is not part of the core SQLite library. This is the file that, when linked against sqlite3.a, generates the \"sqlite3.exe\" command-line shell. The \"shell.c.in\" file is transformed into \"shell.c\" as part of the build process. tclsqlite.c - This file implements the Tcl bindings for SQLite. It is not part of the core SQLite library. But as most of the tests in this repository are written in Tcl, the Tcl language bindings are important. test*.c - Files in the src/ folder that begin with \"test\" go into building the \"testfixture.exe\" program. The testfixture.exe program is an enhanced Tcl shell. The testfixture.exe program runs scripts in the test/ folder to validate the core SQLite code. The testfixture program (and some other test programs too) is build and run when you type \"make test\". ext/misc/json1.c - This file implements the various JSON functions that are build into SQLite. There are many other source files. Each has a succinct header comment that describes its purpose and role within the larger system. Verifying Code Authenticity # The manifest file at the root directory of the source tree contains either a SHA3-256 hash (for newer files) or a SHA1 hash (for older files) for every source file in the repository. The SHA3-256 hash of the manifest file itself is the official name of the version of the source tree that you have. The manifest.uuid file should contain the SHA3-256 hash of the manifest file. If all of the above hash comparisons are correct, then you can be confident that your source tree is authentic and unadulterated. The format of the manifest file should be mostly self-explanatory, but if you want details, they are available here . Contacts # The main SQLite website is http://www.sqlite.org/ with geographically distributed backups at http://www2.sqlite.org/ and http://www3.sqlite.org/ .","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/#version-control","text":"SQLite sources are managed using the Fossil , a distributed version control system that was specifically designed and written to support SQLite development. The Fossil repository contains the urtext. If you are reading this on GitHub or some other Git repository or service, then you are looking at a mirror. The names of check-ins and other artifacts in a Git mirror are different from the official names for those objects. The offical names for check-ins are found in a footer on the check-in comment for authorized mirrors. The official check-in name can also be seen in the manifest.uuid file in the root of the tree. Always use the official name, not the Git-name, when communicating about an SQLite check-in. If you pulled your SQLite source code from a secondary source and want to verify its integrity, there are hints on how to do that in the Verifying Code Authenticity section below.","title":"Version Control"},{"location":"Implementation/SQLite/src/sqlite/#obtaining-the-code","text":"If you do not want to use Fossil, you can download tarballs or ZIP archives or SQLite archives as follows: Lastest trunk check-in as Tarball , ZIP-archive , or SQLite-archive . Latest release as Tarball , ZIP-archive , or SQLite-archive . For other check-ins, substitute an appropriate branch name or tag or hash prefix in place of \"release\" in the URLs of the previous bullet. Or browse the timeline to locate the check-in desired, click on its information page link, then click on the \"Tarball\" or \"ZIP Archive\" links on the information page. If you do want to use Fossil to check out the source tree, first install Fossil version 2.0 or later. (Source tarballs and precompiled binaries available here . Fossil is a stand-alone program. To install, simply download or build the single executable file and put that file someplace on your $PATH.) Then run commands like this: mkdir ~/sqlite cd ~/sqlite fossil clone https://www.sqlite.org/src sqlite.fossil fossil open sqlite.fossil After setting up a repository using the steps above, you can always update to the lastest version using: fossil update trunk ;# latest trunk check-in fossil update release ;# latest official release Or type \"fossil ui\" to get a web-based user interface.","title":"Obtaining The Code"},{"location":"Implementation/SQLite/src/sqlite/#compiling","text":"First create a directory in which to place the build products. It is recommended, but not required, that the build directory be separate from the source directory. Cd into the build directory and then from the build directory run the configure script found at the root of the source tree. Then run \"make\". For example: tar xzf sqlite.tar.gz ;# Unpack the source tree into \"sqlite\" mkdir bld ;# Build will occur in a sibling directory cd bld ;# Change to the build directory ../sqlite/configure ;# Run the configure script make ;# Run the makefile. make sqlite3.c ;# Build the \"amalgamation\" source file make test ;# Run some tests (requires Tcl) See the makefile for additional targets. The configure script uses autoconf 2.61 and libtool. If the configure script does not work out for you, there is a generic makefile named \"Makefile.linux-gcc\" in the top directory of the source tree that you can copy and edit to suit your needs. Comments on the generic makefile show what changes are needed.","title":"Compiling"},{"location":"Implementation/SQLite/src/sqlite/#using-msvc","text":"On Windows, all applicable build products can be compiled with MSVC. First open the command prompt window associated with the desired compiler version (e.g. \"Developer Command Prompt for VS2013\"). Next, use NMAKE with the provided \"Makefile.msc\" to build one of the supported targets. For example: mkdir bld cd bld nmake /f Makefile.msc TOP=..\\sqlite nmake /f Makefile.msc sqlite3.c TOP=..\\sqlite nmake /f Makefile.msc sqlite3.dll TOP=..\\sqlite nmake /f Makefile.msc sqlite3.exe TOP=..\\sqlite nmake /f Makefile.msc test TOP=..\\sqlite There are several build options that can be set via the NMAKE command line. For example, to build for WinRT, simply add \"FOR_WINRT=1\" argument to the \"sqlite3.dll\" command line above. When debugging into the SQLite code, adding the \"DEBUG=1\" argument to one of the above command lines is recommended. SQLite does not require Tcl to run, but a Tcl installation is required by the makefiles (including those for MSVC). SQLite contains a lot of generated code and Tcl is used to do much of that code generation.","title":"Using MSVC"},{"location":"Implementation/SQLite/src/sqlite/#source-code-tour","text":"Most of the core source files are in the src/ subdirectory. The src/ folder also contains files used to build the \"testfixture\" test harness. The names of the source files used by \"testfixture\" all begin with \"test\". The src/ also contains the \"shell.c\" file which is the main program for the \"sqlite3.exe\" command-line shell and the \"tclsqlite.c\" file which implements the Tcl bindings for SQLite. (Historical note: SQLite began as a Tcl extension and only later escaped to the wild as an independent library.) Test scripts and programs are found in the test/ subdirectory. Addtional test code is found in other source repositories. See How SQLite Is Tested for additional information. The ext/ subdirectory contains code for extensions. The Full-text search engine is in ext/fts3 . The R-Tree engine is in ext/rtree . The ext/misc subdirectory contains a number of smaller, single-file extensions, such as a REGEXP operator. The tool/ subdirectory contains various scripts and programs used for building generated source code files or for testing or for generating accessory programs such as \"sqlite3_analyzer(.exe)\".","title":"Source Code Tour"},{"location":"Implementation/SQLite/src/sqlite/#generated-source-code-files","text":"Several of the C-language source files used by SQLite are generated from other sources rather than being typed in manually by a programmer. This section will summarize those automatically-generated files. To create all of the automatically-generated files, simply run \"make target_source\". The \"target_source\" make target will create a subdirectory \"tsrc/\" and fill it with all the source files needed to build SQLite, both manually-edited files and automatically-generated files. The SQLite interface is defined by the sqlite3.h header file, which is generated from src/sqlite.h.in, ./manifest.uuid, and ./VERSION. The Tcl script at tool/mksqlite3h.tcl does the conversion. The manifest.uuid file contains the SHA3 hash of the particular check-in and is used to generate the SQLITE_SOURCE_ID macro. The VERSION file contains the current SQLite version number. The sqlite3.h header is really just a copy of src/sqlite.h.in with the source-id and version number inserted at just the right spots. Note that comment text in the sqlite3.h file is used to generate much of the SQLite API documentation. The Tcl scripts used to generate that documentation are in a separate source repository. The SQL language parser is parse.c which is generate from a grammar in the src/parse.y file. The conversion of \"parse.y\" into \"parse.c\" is done by the lemon LALR(1) parser generator. The source code for lemon is at tool/lemon.c. Lemon uses the tool/lempar.c file as a template for generating its parser. Lemon also generates the parse.h header file, at the same time it generates parse.c. The opcodes.h header file contains macros that define the numbers corresponding to opcodes in the \"VDBE\" virtual machine. The opcodes.h file is generated by the scanning the src/vdbe.c source file. The Tcl script at ./mkopcodeh.tcl does this scan and generates opcodes.h. A second Tcl script, ./mkopcodec.tcl, then scans opcodes.h to generate the opcodes.c source file, which contains a reverse mapping from opcode-number to opcode-name that is used for EXPLAIN output. The keywordhash.h header file contains the definition of a hash table that maps SQL language keywords (ex: \"CREATE\", \"SELECT\", \"INDEX\", etc.) into the numeric codes used by the parse.c parser. The keywordhash.h file is generated by a C-language program at tool mkkeywordhash.c. The pragma.h header file contains various definitions used to parse and implement the PRAGMA statements. The header is generated by a script tool/mkpragmatab.tcl . If you want to add a new PRAGMA, edit the tool/mkpragmatab.tcl file to insert the information needed by the parser for your new PRAGMA, then run the script to regenerate the pragma.h header file.","title":"Generated Source Code Files"},{"location":"Implementation/SQLite/src/sqlite/#the-amalgamation","text":"All of the individual C source code and header files (both manually-edited and automatically-generated) can be combined into a single big source file sqlite3.c called \"the amalgamation\". The amalgamation is the recommended way of using SQLite in a larger application. Combining all individual source code files into a single big source code file allows the C compiler to perform more cross-procedure analysis and generate better code. SQLite runs about 5% faster when compiled from the amalgamation versus when compiled from individual source files. The amalgamation is generated from the tool/mksqlite3c.tcl Tcl script. First, all of the individual source files must be gathered into the tsrc/ subdirectory (using the equivalent of \"make target_source\") then the tool/mksqlite3c.tcl script is run to copy them all together in just the right order while resolving internal \"#include\" references. The amalgamation source file is more than 200K lines long. Some symbolic debuggers (most notably MSVC) are unable to deal with files longer than 64K lines. To work around this, a separate Tcl script, tool/split-sqlite3c.tcl, can be run on the amalgamation to break it up into a single small C file called sqlite3-all.c that does #include on about seven other files named sqlite3-1.c , sqlite3-2.c , ..., sqlite3-7.c . In this way, all of the source code is contained within a single translation unit so that the compiler can do extra cross-procedure optimization, but no individual source file exceeds 32K lines in length.","title":"The Amalgamation"},{"location":"Implementation/SQLite/src/sqlite/#how-it-all-fits-together","text":"SQLite is modular in design. See the architectural description for details. Other documents that are useful in (helping to understand how SQLite works include the file format description, the virtual machine that runs prepared statements, the description of how transactions work , and the overview of the query planner . Years of effort have gone into optimizating SQLite, both for small size and high performance. And optimizations tend to result in complex code. So there is a lot of complexity in the current SQLite implementation. It will not be the easiest library in the world to hack. Key files: sqlite.h.in - This file defines the public interface to the SQLite library. Readers will need to be familiar with this interface before trying to understand how the library works internally. sqliteInt.h - this header file defines many of the data objects used internally by SQLite. In addition to \"sqliteInt.h\", some subsystems have their own header files. parse.y - This file describes the LALR(1) grammar that SQLite uses to parse SQL statements, and the actions that are taken at each step in the parsing process. vdbe.c - This file implements the virtual machine that runs prepared statements. There are various helper files whose names begin with \"vdbe\". The VDBE has access to the vdbeInt.h header file which defines internal data objects. The rest of SQLite interacts with the VDBE through an interface defined by vdbe.h. where.c - This file (together with its helper files named by \"where*.c\") analyzes the WHERE clause and generates virtual machine code to run queries efficiently. This file is sometimes called the \"query optimizer\". It has its own private header file, whereInt.h, that defines data objects used internally. btree.c - This file contains the implementation of the B-Tree storage engine used by SQLite. The interface to the rest of the system is defined by \"btree.h\". The \"btreeInt.h\" header defines objects used internally by btree.c and not published to the rest of the system. pager.c - This file contains the \"pager\" implementation, the module that implements transactions. The \"pager.h\" header file defines the interface between pager.c and the rest of the system. os_unix.c and os_win.c - These two files implement the interface between SQLite and the underlying operating system using the run-time pluggable VFS interface. shell.c.in - This file is not part of the core SQLite library. This is the file that, when linked against sqlite3.a, generates the \"sqlite3.exe\" command-line shell. The \"shell.c.in\" file is transformed into \"shell.c\" as part of the build process. tclsqlite.c - This file implements the Tcl bindings for SQLite. It is not part of the core SQLite library. But as most of the tests in this repository are written in Tcl, the Tcl language bindings are important. test*.c - Files in the src/ folder that begin with \"test\" go into building the \"testfixture.exe\" program. The testfixture.exe program is an enhanced Tcl shell. The testfixture.exe program runs scripts in the test/ folder to validate the core SQLite code. The testfixture program (and some other test programs too) is build and run when you type \"make test\". ext/misc/json1.c - This file implements the various JSON functions that are build into SQLite. There are many other source files. Each has a succinct header comment that describes its purpose and role within the larger system.","title":"How It All Fits Together"},{"location":"Implementation/SQLite/src/sqlite/#verifying-code-authenticity","text":"The manifest file at the root directory of the source tree contains either a SHA3-256 hash (for newer files) or a SHA1 hash (for older files) for every source file in the repository. The SHA3-256 hash of the manifest file itself is the official name of the version of the source tree that you have. The manifest.uuid file should contain the SHA3-256 hash of the manifest file. If all of the above hash comparisons are correct, then you can be confident that your source tree is authentic and unadulterated. The format of the manifest file should be mostly self-explanatory, but if you want details, they are available here .","title":"Verifying Code Authenticity"},{"location":"Implementation/SQLite/src/sqlite/#contacts","text":"The main SQLite website is http://www.sqlite.org/ with geographically distributed backups at http://www2.sqlite.org/ and http://www3.sqlite.org/ .","title":"Contacts"},{"location":"Implementation/SQLite/src/sqlite/LICENSE/","text":"The author disclaims copyright to this source code. In place of a legal notice, here is a blessing: May you do good and not evil. May you find forgiveness for yourself and forgive others. May you share freely, never taking more than you give.","title":"LICENSE"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/","text":"The new-security-options branch # The problem that the new-security-options branch tries to solve # An attacker might modify the schema of an SQLite database by adding structures that cause code to run when some other application opens and reads the database. For example, the attacker might replace a table definition with a view. Or the attacker might add triggers to tables or views, or add new CHECK constraints or generated columns or indexes with expressions in the index list or in the WHERE clause. If the added features invoke SQL functions or virtual tables with side effects, that might cause harm to the system if run by a high-privilege victim. Or, the added features might exfiltrate information if the database is read by a high-privilege victim. The changes in this branch strive to make it easier for high-privilege applications to safely read SQLite database files that might have been maliciously corrupted by an attacker. Overview of changes in new-security-options # The basic idea is to tag every SQL function and virtual table with one of three risk levels: Innocuous Normal Direct-Only Innocuous functions/vtabs are safe and can be used at any time. Direct-only elements, in contrast, might have cause side-effects and should only be used from top-level SQL, not from within triggers or views nor in elements of the schema such as CHECK constraint, DEFAULT values, generated columns, index expressions, or in the WHERE clause of a partial index that are potentially under the control of an attacker. Normal elements behave like Innocuous if TRUSTED_SCHEMA=on and behave like direct-only if TRUSTED_SCHEMA=off. Application-defined functions and virtual tables go in as Normal unless the application takes deliberate steps to change the risk level. For backwards compatibility, the default is TRUSTED_SCHEMA=on. Documentation will be updated to recommend applications turn TRUSTED_SCHEMA to off. An innocuous function or virtual table is one that can only read content from the database file in which it resides, and can only alter the database in which it resides. Most SQL functions are innocuous. For example, there is no harm in an attacker running the abs() function. Direct-only elements that have side-effects that go outside the database file in which it lives, or return information from outside of the database file. Examples of direct-only elements include: The fts3_tokenizer() function The writefile() function The readfile() function The zipvfs virtual table The csv virtual table We do not want an attacker to be able to add these kinds of things to the database schema and possibly trick a high-privilege application from performing any of these actions. Therefore, functions and vtabs with side-effects are marked as Direct-Only. Legacy applications might add other risky functions or vtabs. Those will go in as \"Normal\" by default. For optimal security, we want those risky app-defined functions and vtabs to be direct-only, but making that the default might break some legacy applications. Hence, all app-defined functions and vtabs go in as Normal, but the application can switch them over to \"Direct-Only\" behavior using a single pragma. The restrictions on the use of functions and virtual tables do not apply to TEMP. A TEMP VIEW or a TEMP TRIGGER can use any valid SQL function or virtual table. The idea is that TEMP views and triggers must be directly created by the application and are thus under the control of the application. TEMP views and triggers cannot be created by an attacker who corrupts the schema of a persistent database file. Hence TEMP views and triggers are safe. Specific changes # New sqlite3_db_config() option SQLITE_DBCONFIG_TRUSTED_SCHEMA for turning TRUSTED_SCHEMA on and off. It defaults to ON. Compile-time option -DSQLITE_TRUSTED_SCHEMA=0 causes the default TRUSTED_SCHEMA setting to be off. New pragma \"PRAGMA trusted_schema=(ON|OFF);\". This provides access to the TRUSTED_SCHEMA setting for application coded using scripting languages or other secondary languages where they are unable to make calls to sqlite3_db_config(). New options for the \"enc\" parameter to sqlite3_create_function() and its kin: SQLITE_INNOCUOUS \u2192 tags the new functions as Innocuous SQLITE_DIRECTONLY \u2192 tags the new functions as Direct-Only New options to sqlite3_vtab_config(): SQLITE_VTAB_INNOCUOUS \u2192 tags the vtab as Innocuous SQLITE_VTAB_DIRECTONLY \u2192 tags the vtab as Direct-Only Change many of the functions and virtual tables in the SQLite source tree to use one of the tags above. Enhanced PRAGMA function_list and virtual-table \"pragma_function_list\" with additional columns. The columns now are: name \u2192 Name of the function builtin \u2192 1 for built-in functions. 0 otherwise. type \u2192 's'=Scalar, 'a'=Aggregate, 'w'=Window enc \u2192 'utf8', 'utf16le', or 'utf16be' narg \u2192 number of argument flags \u2192 Bitmask of SQLITE_INNOCUOUS, SQLITE_DIRECTONLY, SQLITE_DETERMINISTIC, SQLITE_SUBTYPE, and SQLITE_FUNC_INTERNAL flags. The last four columns are new. The function_list PRAGMA now also shows all entries for each function. So, for example, if a function can take either 2 or 3 arguments, there are separate rows for the 2-argument and 3-argument versions of the function. Additional Notes # The function_list enhancements allow the application to query the set of SQL functions that meet various criteria. For example, to see all SQL functions that are never allowed to be used in the schema or in trigger or views: SELECT DISTINCT name FROM pragma_function_list WHERE (flags & 0x80000)!=0 ORDER BY name; Doing the same is not possible for virtual tables, as a virtual table might be Innocuous, Normal, or Direct-Only depending on the arguments passed into the xConnect method.","title":"The new-security-options branch"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/#the-new-security-options-branch","text":"","title":"The new-security-options branch"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/#the-problem-that-the-new-security-options-branch-tries-to-solve","text":"An attacker might modify the schema of an SQLite database by adding structures that cause code to run when some other application opens and reads the database. For example, the attacker might replace a table definition with a view. Or the attacker might add triggers to tables or views, or add new CHECK constraints or generated columns or indexes with expressions in the index list or in the WHERE clause. If the added features invoke SQL functions or virtual tables with side effects, that might cause harm to the system if run by a high-privilege victim. Or, the added features might exfiltrate information if the database is read by a high-privilege victim. The changes in this branch strive to make it easier for high-privilege applications to safely read SQLite database files that might have been maliciously corrupted by an attacker.","title":"The problem that the new-security-options branch tries to solve"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/#overview-of-changes-in-new-security-options","text":"The basic idea is to tag every SQL function and virtual table with one of three risk levels: Innocuous Normal Direct-Only Innocuous functions/vtabs are safe and can be used at any time. Direct-only elements, in contrast, might have cause side-effects and should only be used from top-level SQL, not from within triggers or views nor in elements of the schema such as CHECK constraint, DEFAULT values, generated columns, index expressions, or in the WHERE clause of a partial index that are potentially under the control of an attacker. Normal elements behave like Innocuous if TRUSTED_SCHEMA=on and behave like direct-only if TRUSTED_SCHEMA=off. Application-defined functions and virtual tables go in as Normal unless the application takes deliberate steps to change the risk level. For backwards compatibility, the default is TRUSTED_SCHEMA=on. Documentation will be updated to recommend applications turn TRUSTED_SCHEMA to off. An innocuous function or virtual table is one that can only read content from the database file in which it resides, and can only alter the database in which it resides. Most SQL functions are innocuous. For example, there is no harm in an attacker running the abs() function. Direct-only elements that have side-effects that go outside the database file in which it lives, or return information from outside of the database file. Examples of direct-only elements include: The fts3_tokenizer() function The writefile() function The readfile() function The zipvfs virtual table The csv virtual table We do not want an attacker to be able to add these kinds of things to the database schema and possibly trick a high-privilege application from performing any of these actions. Therefore, functions and vtabs with side-effects are marked as Direct-Only. Legacy applications might add other risky functions or vtabs. Those will go in as \"Normal\" by default. For optimal security, we want those risky app-defined functions and vtabs to be direct-only, but making that the default might break some legacy applications. Hence, all app-defined functions and vtabs go in as Normal, but the application can switch them over to \"Direct-Only\" behavior using a single pragma. The restrictions on the use of functions and virtual tables do not apply to TEMP. A TEMP VIEW or a TEMP TRIGGER can use any valid SQL function or virtual table. The idea is that TEMP views and triggers must be directly created by the application and are thus under the control of the application. TEMP views and triggers cannot be created by an attacker who corrupts the schema of a persistent database file. Hence TEMP views and triggers are safe.","title":"Overview of changes in new-security-options"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/#specific-changes","text":"New sqlite3_db_config() option SQLITE_DBCONFIG_TRUSTED_SCHEMA for turning TRUSTED_SCHEMA on and off. It defaults to ON. Compile-time option -DSQLITE_TRUSTED_SCHEMA=0 causes the default TRUSTED_SCHEMA setting to be off. New pragma \"PRAGMA trusted_schema=(ON|OFF);\". This provides access to the TRUSTED_SCHEMA setting for application coded using scripting languages or other secondary languages where they are unable to make calls to sqlite3_db_config(). New options for the \"enc\" parameter to sqlite3_create_function() and its kin: SQLITE_INNOCUOUS \u2192 tags the new functions as Innocuous SQLITE_DIRECTONLY \u2192 tags the new functions as Direct-Only New options to sqlite3_vtab_config(): SQLITE_VTAB_INNOCUOUS \u2192 tags the vtab as Innocuous SQLITE_VTAB_DIRECTONLY \u2192 tags the vtab as Direct-Only Change many of the functions and virtual tables in the SQLite source tree to use one of the tags above. Enhanced PRAGMA function_list and virtual-table \"pragma_function_list\" with additional columns. The columns now are: name \u2192 Name of the function builtin \u2192 1 for built-in functions. 0 otherwise. type \u2192 's'=Scalar, 'a'=Aggregate, 'w'=Window enc \u2192 'utf8', 'utf16le', or 'utf16be' narg \u2192 number of argument flags \u2192 Bitmask of SQLITE_INNOCUOUS, SQLITE_DIRECTONLY, SQLITE_DETERMINISTIC, SQLITE_SUBTYPE, and SQLITE_FUNC_INTERNAL flags. The last four columns are new. The function_list PRAGMA now also shows all entries for each function. So, for example, if a function can take either 2 or 3 arguments, there are separate rows for the 2-argument and 3-argument versions of the function.","title":"Specific changes"},{"location":"Implementation/SQLite/src/sqlite/doc/trusted-schema/#additional-notes","text":"The function_list enhancements allow the application to query the set of SQL functions that meet various criteria. For example, to see all SQL functions that are never allowed to be used in the schema or in trigger or views: SELECT DISTINCT name FROM pragma_function_list WHERE (flags & 0x80000)!=0 ORDER BY name; Doing the same is not possible for virtual tables, as a virtual table might be Innocuous, Normal, or Direct-Only depending on the arguments passed into the xConnect method.","title":"Additional Notes"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/","text":"Wal-Mode Blocking Locks # On some Unix-like systems, SQLite may be configured to use POSIX blocking locks by: building the library with SQLITE_ENABLE_SETLK_TIMEOUT defined, and configuring a timeout in ms using the sqlite3_busy_timeout() API. Blocking locks may be advantageous as (a) waiting database clients do not need to continuously poll the database lock, and (b) using blocking locks facilitates transfer of OS priority between processes when a high priority process is blocked by a lower priority one. Only read/write clients use blocking locks. Clients that have read-only access to the *-shm file nevery use blocking locks. Threads or processes that access a single database at a time never deadlock as a result of blocking database locks. But it is of course possible for threads that lock multiple databases simultaneously to do so. In most cases the OS will detect the deadlock and return an error. Wal Recovery # Wal database \"recovery\" is a process required when the number of connected database clients changes from zero to one. In this case, a client is considered to connect to the database when it first reads data from it. Before recovery commences, an exclusive WRITER lock is taken. Without blocking locks, if two clients attempt recovery simultaneously, one fails to obtain the WRITER lock and either invokes the busy-handler callback or returns SQLITE_BUSY to the user. With blocking locks configured, the second client blocks on the WRITER lock. Database Readers # Usually, read-only are not blocked by any other database clients, so they have no need of blocking locks. If a read-only transaction is being opened on a snapshot, the CHECKPOINTER lock is required briefly as part of opening the transaction (to check that a checkpointer is not currently overwriting the snapshot being opened). A blocking lock is used to obtain the CHECKPOINTER lock in this case. A snapshot opener may therefore block on and transfer priority to a checkpointer in some cases. Database Writers # A database writer must obtain the exclusive WRITER lock. It uses a blocking lock to do so if any of the following are true: the transaction is an implicit one consisting of a single DML or DDL statement, or the transaction is opened using BEGIN IMMEDIATE or BEGIN EXCLUSIVE, or the first SQL statement executed following the BEGIN command is a DML or DDL statement (not a read-only statement like a SELECT). In other words, in all cases except when an open read-transaction is upgraded to a write-transaction. In that case a non-blocking lock is used. Database Checkpointers # Database checkpointers takes the following locks, in order: The exclusive CHECKPOINTER lock. The exclusive WRITER lock (FULL, RESTART and TRUNCATE only). Exclusive lock on read-mark slots 1-N. These are immediately released after being taken. Exclusive lock on read-mark 0. Exclusive lock on read-mark slots 1-N again. These are immediately released after being taken (RESTART and TRUNCATE only). All of the above use blocking locks. Summary # With blocking locks configured, the only cases in which clients should see an SQLITE_BUSY error are: if the OS does not grant a blocking lock before the configured timeout expires, and when an open read-transaction is upgraded to a write-transaction. In all other cases the blocking locks implementation should prevent clients from having to handle SQLITE_BUSY errors and facilitate appropriate transfer of priorities between competing clients. Clients that lock multiple databases simultaneously must be wary of deadlock.","title":"Wal-Mode Blocking Locks"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#wal-mode-blocking-locks","text":"On some Unix-like systems, SQLite may be configured to use POSIX blocking locks by: building the library with SQLITE_ENABLE_SETLK_TIMEOUT defined, and configuring a timeout in ms using the sqlite3_busy_timeout() API. Blocking locks may be advantageous as (a) waiting database clients do not need to continuously poll the database lock, and (b) using blocking locks facilitates transfer of OS priority between processes when a high priority process is blocked by a lower priority one. Only read/write clients use blocking locks. Clients that have read-only access to the *-shm file nevery use blocking locks. Threads or processes that access a single database at a time never deadlock as a result of blocking database locks. But it is of course possible for threads that lock multiple databases simultaneously to do so. In most cases the OS will detect the deadlock and return an error.","title":"Wal-Mode Blocking Locks"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#wal-recovery","text":"Wal database \"recovery\" is a process required when the number of connected database clients changes from zero to one. In this case, a client is considered to connect to the database when it first reads data from it. Before recovery commences, an exclusive WRITER lock is taken. Without blocking locks, if two clients attempt recovery simultaneously, one fails to obtain the WRITER lock and either invokes the busy-handler callback or returns SQLITE_BUSY to the user. With blocking locks configured, the second client blocks on the WRITER lock.","title":"Wal Recovery"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#database-readers","text":"Usually, read-only are not blocked by any other database clients, so they have no need of blocking locks. If a read-only transaction is being opened on a snapshot, the CHECKPOINTER lock is required briefly as part of opening the transaction (to check that a checkpointer is not currently overwriting the snapshot being opened). A blocking lock is used to obtain the CHECKPOINTER lock in this case. A snapshot opener may therefore block on and transfer priority to a checkpointer in some cases.","title":"Database Readers"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#database-writers","text":"A database writer must obtain the exclusive WRITER lock. It uses a blocking lock to do so if any of the following are true: the transaction is an implicit one consisting of a single DML or DDL statement, or the transaction is opened using BEGIN IMMEDIATE or BEGIN EXCLUSIVE, or the first SQL statement executed following the BEGIN command is a DML or DDL statement (not a read-only statement like a SELECT). In other words, in all cases except when an open read-transaction is upgraded to a write-transaction. In that case a non-blocking lock is used.","title":"Database Writers"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#database-checkpointers","text":"Database checkpointers takes the following locks, in order: The exclusive CHECKPOINTER lock. The exclusive WRITER lock (FULL, RESTART and TRUNCATE only). Exclusive lock on read-mark slots 1-N. These are immediately released after being taken. Exclusive lock on read-mark 0. Exclusive lock on read-mark slots 1-N again. These are immediately released after being taken (RESTART and TRUNCATE only). All of the above use blocking locks.","title":"Database Checkpointers"},{"location":"Implementation/SQLite/src/sqlite/doc/wal-lock/#summary","text":"With blocking locks configured, the only cases in which clients should see an SQLITE_BUSY error are: if the OS does not grant a blocking lock before the configured timeout expires, and when an open read-transaction is upgraded to a write-transaction. In all other cases the blocking locks implementation should prevent clients from having to handle SQLITE_BUSY errors and facilitate appropriate transfer of priorities between competing clients. Clients that lock multiple databases simultaneously must be wary of deadlock.","title":"Summary"},{"location":"Implementation/SQLite/src/sqlite/ext/","text":"Loadable Extensions # Various loadable extensions for SQLite are found in subfolders. Most subfolders are dedicated to a single loadable extension (for example FTS5, or RTREE). But the misc/ subfolder contains a collection of smaller single-file extensions.","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/ext/#loadable-extensions","text":"Various loadable extensions for SQLite are found in subfolders. Most subfolders are dedicated to a single loadable extension (for example FTS5, or RTREE). But the misc/ subfolder contains a collection of smaller single-file extensions.","title":"Loadable Extensions"},{"location":"Implementation/SQLite/src/sqlite/ext/expert/","text":"SQLite Expert Extension # This folder contains code for a simple system to propose useful indexes given a database and a set of SQL queries. It works as follows: The user database schema is copied to a temporary database. All SQL queries are prepared against the temporary database. Information regarding the WHERE and ORDER BY clauses, and other query features that affect index selection are recorded. The information gathered in step 2 is used to create candidate indexes - indexes that the planner might have made use of in the previous step, had they been available. A subset of the data in the user database is used to generate statistics for all existing indexes and the candidate indexes generated in step 3 above. The SQL queries are prepared a second time. If the planner uses any of the indexes created in step 3, they are recommended to the user. C API # The SQLite expert C API is defined in sqlite3expert.h. Most uses will proceed as follows: An sqlite3expert object is created by calling sqlite3_expert_new() . A database handle opened by the user is passed as an argument. The sqlite3expert object is configured with one or more SQL statements by making one or more calls to sqlite3_expert_sql() . Each call may specify a single SQL statement, or multiple statements separated by semi-colons. Optionally, the sqlite3_expert_config() API may be used to configure the size of the data subset used to generate index statistics. Using a smaller subset of the data can speed up the analysis. sqlite3_expert_analyze() is called to run the analysis. One or more calls are made to sqlite3_expert_report() to extract components of the results of the analysis. sqlite3_expert_destroy() is called to free all resources. Refer to comments in sqlite3expert.h for further details. sqlite3_expert application # The file \"expert.c\" contains the code for a command line application that uses the API described above. It can be compiled with (for example): gcc -O2 sqlite3.c expert.c sqlite3expert.c -o sqlite3_expert Assuming the database is named \"test.db\", it can then be run to analyze a single query: ./sqlite3_expert -sql <sql-query> test.db Or an entire text file worth of queries with: ./sqlite3_expert -file <text-file> test.db By default, sqlite3_expert generates index statistics using all the data in the user database. For a large database, this may be prohibitively time consuming. The \"-sample\" option may be used to configure sqlite3_expert to generate statistics based on an integer percentage of the user database as follows: # Generate statistics based on 25% of the user database rows: ./sqlite3_expert -sample 25 -sql <sql-query> test.db # Do not generate any statistics at all: ./sqlite3_expert -sample 0 -sql <sql-query> test.db","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/ext/expert/#sqlite-expert-extension","text":"This folder contains code for a simple system to propose useful indexes given a database and a set of SQL queries. It works as follows: The user database schema is copied to a temporary database. All SQL queries are prepared against the temporary database. Information regarding the WHERE and ORDER BY clauses, and other query features that affect index selection are recorded. The information gathered in step 2 is used to create candidate indexes - indexes that the planner might have made use of in the previous step, had they been available. A subset of the data in the user database is used to generate statistics for all existing indexes and the candidate indexes generated in step 3 above. The SQL queries are prepared a second time. If the planner uses any of the indexes created in step 3, they are recommended to the user.","title":"SQLite Expert Extension"},{"location":"Implementation/SQLite/src/sqlite/ext/expert/#c-api","text":"The SQLite expert C API is defined in sqlite3expert.h. Most uses will proceed as follows: An sqlite3expert object is created by calling sqlite3_expert_new() . A database handle opened by the user is passed as an argument. The sqlite3expert object is configured with one or more SQL statements by making one or more calls to sqlite3_expert_sql() . Each call may specify a single SQL statement, or multiple statements separated by semi-colons. Optionally, the sqlite3_expert_config() API may be used to configure the size of the data subset used to generate index statistics. Using a smaller subset of the data can speed up the analysis. sqlite3_expert_analyze() is called to run the analysis. One or more calls are made to sqlite3_expert_report() to extract components of the results of the analysis. sqlite3_expert_destroy() is called to free all resources. Refer to comments in sqlite3expert.h for further details.","title":"C API"},{"location":"Implementation/SQLite/src/sqlite/ext/expert/#sqlite3_expert-application","text":"The file \"expert.c\" contains the code for a command line application that uses the API described above. It can be compiled with (for example): gcc -O2 sqlite3.c expert.c sqlite3expert.c -o sqlite3_expert Assuming the database is named \"test.db\", it can then be run to analyze a single query: ./sqlite3_expert -sql <sql-query> test.db Or an entire text file worth of queries with: ./sqlite3_expert -file <text-file> test.db By default, sqlite3_expert generates index statistics using all the data in the user database. For a large database, this may be prohibitively time consuming. The \"-sample\" option may be used to configure sqlite3_expert to generate statistics based on an integer percentage of the user database as follows: # Generate statistics based on 25% of the user database rows: ./sqlite3_expert -sample 25 -sql <sql-query> test.db # Do not generate any statistics at all: ./sqlite3_expert -sample 0 -sql <sql-query> test.db","title":"sqlite3_expert application"},{"location":"Implementation/SQLite/src/sqlite/ext/misc/","text":"Miscellaneous Extensions # This folder contains a collection of smaller loadable extensions. See https://www.sqlite.org/loadext.html for instructions on how to compile and use loadable extensions. Each extension in this folder is implemented in a single file of C code. Each source file contains a description in its header comment. See the header comments for details about each extension. Additional notes are as follows: carray.c \u2014 This module implements the carray table-valued function. It is a good example of how to go about implementing a custom table-valued function . csv.c \u2014 A virtual table for reading Comma-Separated-Value (CSV) files . dbdump.c \u2014 This is not actually a loadable extension, but rather a library that implements an approximate equivalent to the \".dump\" command of the command-line shell . json1.c \u2014 Various SQL functions and table-valued functions for processing JSON. This extension is already built into the SQLite amalgamation . See https://sqlite.org/json1.html for additional information. memvfs.c \u2014 This file implements a custom VFS that stores an entire database file in a single block of RAM. It serves as a good example of how to implement a simple custom VFS. rot13.c \u2014 This file implements the very simple rot13() substitution function. This file makes a good template for implementing new custom SQL functions for SQLite. series.c \u2014 This is an implementation of the \"generate_series\" virtual table . It can make a good template for new custom virtual table implementations. shathree.c \u2014 An implementation of the sha3() and sha3_query() SQL functions. The file is named \"shathree.c\" instead of \"sha3.c\" because the default entry point names in SQLite are based on the source filename with digits removed, so if we used the name \"sha3.c\" then the entry point would conflict with the prior \"sha1.c\" extension. unionvtab.c \u2014 Implementation of the unionvtab and swarmvtab virtual tables. These virtual tables allow a single large table to be spread out across multiple database files. In the case of swarmvtab, the individual database files can be attached on demand. zipfile.c \u2014 A virtual table that can read and write a ZIP archive .","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/ext/misc/#miscellaneous-extensions","text":"This folder contains a collection of smaller loadable extensions. See https://www.sqlite.org/loadext.html for instructions on how to compile and use loadable extensions. Each extension in this folder is implemented in a single file of C code. Each source file contains a description in its header comment. See the header comments for details about each extension. Additional notes are as follows: carray.c \u2014 This module implements the carray table-valued function. It is a good example of how to go about implementing a custom table-valued function . csv.c \u2014 A virtual table for reading Comma-Separated-Value (CSV) files . dbdump.c \u2014 This is not actually a loadable extension, but rather a library that implements an approximate equivalent to the \".dump\" command of the command-line shell . json1.c \u2014 Various SQL functions and table-valued functions for processing JSON. This extension is already built into the SQLite amalgamation . See https://sqlite.org/json1.html for additional information. memvfs.c \u2014 This file implements a custom VFS that stores an entire database file in a single block of RAM. It serves as a good example of how to implement a simple custom VFS. rot13.c \u2014 This file implements the very simple rot13() substitution function. This file makes a good template for implementing new custom SQL functions for SQLite. series.c \u2014 This is an implementation of the \"generate_series\" virtual table . It can make a good template for new custom virtual table implementations. shathree.c \u2014 An implementation of the sha3() and sha3_query() SQL functions. The file is named \"shathree.c\" instead of \"sha3.c\" because the default entry point names in SQLite are based on the source filename with digits removed, so if we used the name \"sha3.c\" then the entry point would conflict with the prior \"sha1.c\" extension. unionvtab.c \u2014 Implementation of the unionvtab and swarmvtab virtual tables. These virtual tables allow a single large table to be spread out across multiple database files. In the case of swarmvtab, the individual database files can be attached on demand. zipfile.c \u2014 A virtual table that can read and write a ZIP archive .","title":"Miscellaneous Extensions"},{"location":"Implementation/SQLite/src/sqlite/ext/repair/","text":"This folder contains extensions and utility programs intended to analyze live database files, detect problems, and possibly fix them. As SQLite is being used on larger and larger databases, database sizes are growing into the terabyte range. At that size, hardware malfunctions and/or cosmic rays will occasionally corrupt a database file. Detecting problems and fixing errors a terabyte-sized databases can take hours or days, and it is undesirable to take applications that depend on the databases off-line for such a long time. The utilities in the folder are intended to provide mechanisms for detecting and fixing problems in large databases while those databases are in active use. The utilities and extensions in this folder are experimental and under active development at the time of this writing (2017-10-12). If and when they stabilize, this README will be updated to reflect that fact.","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/ext/repair/test/","text":"To run these tests, first build sqlite3_checker: make sqlite3_checker Then run the \"test.tcl\" script using: ./sqlite3_checker --test $path/test.tcl Optionally add the full pathnames of individual *.test modules","title":"Index"},{"location":"Implementation/SQLite/src/sqlite/src/in-operator/","text":"IN-Operator Implementation Notes # Definitions: # An IN operator has one of the following formats: x IN (y1,y2,y3,...,yN) x IN (subquery) The \"x\" is referred to as the LHS (left-hand side). The list or subquery on the right is called the RHS (right-hand side). If the RHS is a list it must be a non-empty list. But if the RHS is a subquery, it can be an empty set. The LHS can be a scalar (a single quantity) or a vector (a list of two or or more values) or a subquery that returns one or more columns. We use the term \"vector\" to mean an actually list of values or a subquery that returns two or more columns. An isolated value or a subquery that returns a single columns is called a scalar. The RHS can be a subquery that returns a single column, a subquery that returns two or more columns, or a list of scalars. It is not currently support for the RHS to be a list of vectors. The number of columns for LHS must match the number of columns for the RHS. If the RHS is a list of values, then the LHS must be a scalar. If the RHS is a subquery returning N columns, then the LHS must be a vector of size N. NULL values can occur in either or both of the LHS and RHS. If the LHS contains only NULL values then we say that it is a \"total-NULL\". If the LHS contains some NULL values and some non-NULL values, then it is a \"partial-NULL\". For a scalar, there is no difference between a partial-NULL and a total-NULL. The RHS is a partial-NULL if any row contains a NULL value. The RHS is a total-NULL if it contains one or more rows that contain only NULL values. The LHS is called \"non-NULL\" if it contains no NULL values. The RHS is called \"non-NULL\" if it contains no NULL values in any row. The result of an IN operator is one of TRUE, FALSE, or NULL. A NULL result means that it cannot be determined if the LHS is contained in the RHS due to the presence of NULL values. In some contexts (for example, when the IN operator occurs in a WHERE clause) the system only needs a binary result: TRUE or NOT-TRUE. One can also to define a binary result of FALSE and NOT-FALSE, but it turns out that no extra optimizations are possible in that case, so if the FALSE/NOT-FALSE binary is needed, we have to compute the three-state TRUE/FALSE/NULL result and then combine the TRUE and NULL values into NOT-FALSE. A \"NOT IN\" operator is computed by first computing the equivalent IN operator, then interchanging the TRUE and FALSE results. Simple Full-Scan Algorithm # The following algorithm always compute the correct answer. However, this algorithm is suboptimal, especially if there are many rows on the RHS. Set the null-flag to false For each row in the RHS: Compare the LHS against the RHS If the LHS exactly matches the RHS, immediately return TRUE If the comparison result is NULL, set the null-flag to true If the null-flag is true, return NULL. Return FALSE Optimized Algorithm # The following procedure computes the same answer as the simple full-scan algorithm, though it does so with less work in the common case. This is the algorithm that is implemented in SQLite. If the RHS is a constant list of length 1 or 2, then rewrite the IN operator as a simple expression. Implement x IN (y1,y2) as if it were x=y1 OR x=y2 This is the INDEX_NOOP optimization and is only undertaken if the IN operator is used for membership testing. If the IN operator is driving a loop, then skip this step entirely. Check the LHS to see if it is a partial-NULL and if it is, jump ahead to step 5. Do a binary search of the RHS using the LHS as a probe. If an exact match is found, return TRUE. If the RHS is non-NULL then return FALSE. If we do not need to distinguish between FALSE and NULL, then return FALSE. For each row in the RHS, compare that row against the LHS and if the result is NULL, immediately return NULL. In the case of a scalar IN operator, we only need to look at the very first row the RHS because for a scalar RHS, all NULLs will always come first. If the RHS is empty, this step is a no-op. Return FALSE.","title":"In operator"},{"location":"Implementation/SQLite/src/sqlite/src/in-operator/#in-operator-implementation-notes","text":"","title":"IN-Operator Implementation Notes"},{"location":"Implementation/SQLite/src/sqlite/src/in-operator/#definitions","text":"An IN operator has one of the following formats: x IN (y1,y2,y3,...,yN) x IN (subquery) The \"x\" is referred to as the LHS (left-hand side). The list or subquery on the right is called the RHS (right-hand side). If the RHS is a list it must be a non-empty list. But if the RHS is a subquery, it can be an empty set. The LHS can be a scalar (a single quantity) or a vector (a list of two or or more values) or a subquery that returns one or more columns. We use the term \"vector\" to mean an actually list of values or a subquery that returns two or more columns. An isolated value or a subquery that returns a single columns is called a scalar. The RHS can be a subquery that returns a single column, a subquery that returns two or more columns, or a list of scalars. It is not currently support for the RHS to be a list of vectors. The number of columns for LHS must match the number of columns for the RHS. If the RHS is a list of values, then the LHS must be a scalar. If the RHS is a subquery returning N columns, then the LHS must be a vector of size N. NULL values can occur in either or both of the LHS and RHS. If the LHS contains only NULL values then we say that it is a \"total-NULL\". If the LHS contains some NULL values and some non-NULL values, then it is a \"partial-NULL\". For a scalar, there is no difference between a partial-NULL and a total-NULL. The RHS is a partial-NULL if any row contains a NULL value. The RHS is a total-NULL if it contains one or more rows that contain only NULL values. The LHS is called \"non-NULL\" if it contains no NULL values. The RHS is called \"non-NULL\" if it contains no NULL values in any row. The result of an IN operator is one of TRUE, FALSE, or NULL. A NULL result means that it cannot be determined if the LHS is contained in the RHS due to the presence of NULL values. In some contexts (for example, when the IN operator occurs in a WHERE clause) the system only needs a binary result: TRUE or NOT-TRUE. One can also to define a binary result of FALSE and NOT-FALSE, but it turns out that no extra optimizations are possible in that case, so if the FALSE/NOT-FALSE binary is needed, we have to compute the three-state TRUE/FALSE/NULL result and then combine the TRUE and NULL values into NOT-FALSE. A \"NOT IN\" operator is computed by first computing the equivalent IN operator, then interchanging the TRUE and FALSE results.","title":"Definitions:"},{"location":"Implementation/SQLite/src/sqlite/src/in-operator/#simple-full-scan-algorithm","text":"The following algorithm always compute the correct answer. However, this algorithm is suboptimal, especially if there are many rows on the RHS. Set the null-flag to false For each row in the RHS: Compare the LHS against the RHS If the LHS exactly matches the RHS, immediately return TRUE If the comparison result is NULL, set the null-flag to true If the null-flag is true, return NULL. Return FALSE","title":"Simple Full-Scan Algorithm"},{"location":"Implementation/SQLite/src/sqlite/src/in-operator/#optimized-algorithm","text":"The following procedure computes the same answer as the simple full-scan algorithm, though it does so with less work in the common case. This is the algorithm that is implemented in SQLite. If the RHS is a constant list of length 1 or 2, then rewrite the IN operator as a simple expression. Implement x IN (y1,y2) as if it were x=y1 OR x=y2 This is the INDEX_NOOP optimization and is only undertaken if the IN operator is used for membership testing. If the IN operator is driving a loop, then skip this step entirely. Check the LHS to see if it is a partial-NULL and if it is, jump ahead to step 5. Do a binary search of the RHS using the LHS as a probe. If an exact match is found, return TRUE. If the RHS is non-NULL then return FALSE. If we do not need to distinguish between FALSE and NULL, then return FALSE. For each row in the RHS, compare that row against the LHS and if the result is NULL, immediately return NULL. In the case of a scalar IN operator, we only need to look at the very first row the RHS because for a scalar RHS, all NULLs will always come first. If the RHS is empty, this step is a no-op. Return FALSE.","title":"Optimized Algorithm"},{"location":"Implementation/SQLite/src/sqlite/tool/dbtotxt/","text":"The dbtotxt Tool The dbtotxt utility program reads an SQLite database file and writes its raw binary content to screen as a hex dump for testing and debugging purposes. The hex-dump output is formatted in such a way as to be easily readable both by humans and by software. The dbtotxt utility has long been a part of the TH3 test suite. The output of dbtotxt can be embedded in TH3 test scripts and used to generate very specific database files, perhaps with deliberately introduced corruption. The cov1/corrupt*.test modules in TH3 make extensive use of dbtotxt. More recently (2018-12-13) the dbtotxt utility has been added to the SQLite core and the command-line shell (CLI) has been augmented to be able to read dbtotxt output. The CLI dot-command is: .open --hexdb ?OPTIONAL-FILENAME? If the OPTIONAL-FILENAME is included, then content is read from that file. If OPTIONAL-FILENAME is omitted, then the text is taken from the input stream, terminated by the \"| end\" line of the dbtotxt text. This allows small test databases to be embedded directly in scripts. Consider this example: .open --hexdb | size 8192 pagesize 4096 filename x9.db | page 1 offset 0 | 0: 53 51 4c 69 74 65 20 66 6f 72 6d 61 74 20 33 00 SQLite format 3. | 16: 10 00 01 01 00 40 20 20 00 00 00 04 00 00 00 02 .....@ ........ | 32: 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 04 ................ | 48: 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 00 ................ | 80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 04 ................ | 96: 00 2e 30 38 0d 00 00 00 01 0f c0 00 0f c0 00 00 ..08............ | 4032: 3e 01 06 17 11 11 01 69 74 61 62 6c 65 74 31 74 >......itablet1t | 4048: 31 02 43 52 45 41 54 45 20 54 41 42 4c 45 20 74 1.CREATE TABLE t | 4064: 31 28 78 2c 79 20 44 45 46 41 55 4c 54 20 78 27 1(x,y DEFAULT x' | 4080: 66 66 27 2c 7a 20 44 45 46 41 55 4c 54 20 30 29 ff',z DEFAULT 0) | page 2 offset 4096 | 0: 0d 08 14 00 04 00 10 00 0e 05 0a 0f 04 15 00 10 ................ | 16: 88 02 03 05 90 04 0e 08 00 00 00 00 00 00 00 00 ................ | 1040: 00 00 00 00 ff 87 7c 02 05 8f 78 0e 08 00 00 00 ......|...x..... | 2064: 00 00 00 ff 0c 0a 01 fb 00 00 00 00 00 00 00 00 ................ | 2560: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 83 ................ | 2576: 78 01 05 87 70 0e 08 00 00 00 00 00 00 00 00 00 x...p........... | 3072: 00 00 00 00 00 00 00 00 00 ff 00 00 01 fb 00 00 ................ | 3584: 00 00 00 00 00 83 78 00 05 87 70 0e 08 00 00 00 ......x...p..... | 4080: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ff ................ | end x9.db SELECT rowid FROM t1; PRAGMA integrity_check; You can run this script to see that the database file is correctly decoded and loaded. Furthermore, you can make subtle corruptions to the input database simply by editing the hexadecimal description, then rerun the script to verify that SQLite correctly handles the corruption.","title":"Dbtotxt"},{"location":"Theory/Concurrency-Control-in-DBMS/","text":"Concurrency control in DBMS # Multiple model # \u4f7f\u7528multiple model\u6765\u63cf\u8ff0DBMS\u4e2d\u7684concurrency model: Concurrency unit: transaction Shared data # table Unit # transaction\u3002 wikipedia Non-lock concurrency control # In Computer Science , in the field of databases , non-lock concurrency control is a concurrency control method used in relational databases without using locking . There are several non-lock concurrency control methods, which involve the use of timestamps on transaction to determine transaction priority: Optimistic concurrency control Timestamp-based concurrency control Multiversion concurrency control NOTE: \u7531\u4e8e\u8fd9\u4e9bconcurrency control\u65b9\u5f0f\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8eDBMS\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5176\u4ed6\u7684\u9886\u57df\uff0c\u6240\u4ee5\u5e76\u6ca1\u6709\u5c06\u5b83\u4eec\u7684\u5b9e\u73b0\u653e\u5230\u672c\u5de5\u7a0b\uff0c\u800c\u662f\u653e\u5230\u4e86\u5de5\u7a0bparallel-computing\u4e2d\u3002 geeksforgeeks Concurrency Control in DBMS # Concurrency Control deals with interleaved execution of more than one transaction. In the next article, we will see what is serializability and how to find whether a schedule is serializable or not.","title":"Concurrency control in DBMS"},{"location":"Theory/Concurrency-Control-in-DBMS/#concurrency-control-in-dbms","text":"","title":"Concurrency control in DBMS"},{"location":"Theory/Concurrency-Control-in-DBMS/#multiple-model","text":"\u4f7f\u7528multiple model\u6765\u63cf\u8ff0DBMS\u4e2d\u7684concurrency model: Concurrency unit: transaction","title":"Multiple model"},{"location":"Theory/Concurrency-Control-in-DBMS/#shared-data","text":"table","title":"Shared data"},{"location":"Theory/Concurrency-Control-in-DBMS/#unit","text":"transaction\u3002","title":"Unit"},{"location":"Theory/Concurrency-Control-in-DBMS/#wikipedia-non-lock-concurrency-control","text":"In Computer Science , in the field of databases , non-lock concurrency control is a concurrency control method used in relational databases without using locking . There are several non-lock concurrency control methods, which involve the use of timestamps on transaction to determine transaction priority: Optimistic concurrency control Timestamp-based concurrency control Multiversion concurrency control NOTE: \u7531\u4e8e\u8fd9\u4e9bconcurrency control\u65b9\u5f0f\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8eDBMS\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5176\u4ed6\u7684\u9886\u57df\uff0c\u6240\u4ee5\u5e76\u6ca1\u6709\u5c06\u5b83\u4eec\u7684\u5b9e\u73b0\u653e\u5230\u672c\u5de5\u7a0b\uff0c\u800c\u662f\u653e\u5230\u4e86\u5de5\u7a0bparallel-computing\u4e2d\u3002","title":"wikipedia Non-lock concurrency control"},{"location":"Theory/Concurrency-Control-in-DBMS/#geeksforgeeks-concurrency-control-in-dbms","text":"Concurrency Control deals with interleaved execution of more than one transaction. In the next article, we will see what is serializability and how to find whether a schedule is serializable or not.","title":"geeksforgeeks Concurrency Control in DBMS"},{"location":"Theory/Concurrency-Control-in-DBMS/Problem/","text":"Problem # Read write of multiple model # \u4f7f\u7528multiple model\u7684Read write\u6765\u8fdb\u884c\u5206\u6790: 1\u3001 Read\u2013write conflict 2\u3001 Write\u2013read conflict 3\u3001 Write\u2013write conflict TODO # https://www.csestack.org/different-types-read-write-conflict-database/ https://enacademic.com/dic.nsf/enwiki/140060 https://www.sqlshack.com/dirty-reads-and-the-read-uncommitted-isolation-level/","title":"Problem"},{"location":"Theory/Concurrency-Control-in-DBMS/Problem/#problem","text":"","title":"Problem"},{"location":"Theory/Concurrency-Control-in-DBMS/Problem/#read-write-of-multiple-model","text":"\u4f7f\u7528multiple model\u7684Read write\u6765\u8fdb\u884c\u5206\u6790: 1\u3001 Read\u2013write conflict 2\u3001 Write\u2013read conflict 3\u3001 Write\u2013write conflict","title":"Read write of multiple  model"},{"location":"Theory/Concurrency-Control-in-DBMS/Problem/#todo","text":"https://www.csestack.org/different-types-read-write-conflict-database/ https://enacademic.com/dic.nsf/enwiki/140060 https://www.sqlshack.com/dirty-reads-and-the-read-uncommitted-isolation-level/","title":"TODO"},{"location":"Theory/Database-transaction/ACID/","text":"ACID # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u6709DB transaction\u624d\u5177\u5907ACID\u7279\u6027\uff0c\u5176\u4ed6\u7684transaction\u4e0d\u4e00\u5b9a\u5177\u5907ACID\u7279\u6027\u3002 cnblogs \u6570\u636e\u5e93\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\u4ee5\u53ca\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b # \u672c\u7bc7\u8bb2\u8bc9\u6570\u636e\u5e93\u4e2d\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\uff08ACID\uff09\uff0c\u5e76\u4e14\u5c06\u4f1a\u8be6\u7ec6\u5730\u8bf4\u660e\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u3002 \u5982\u679c\u4e00\u4e2a\u6570\u636e\u5e93\u58f0\u79f0\u652f\u6301\u4e8b\u52a1\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48\u8be5\u6570\u636e\u5e93\u5fc5\u987b\u8981\u5177\u5907\u4ee5\u4e0b\u56db\u4e2a\u7279\u6027\uff1a \u2474 \u539f\u5b50\u6027\uff08Atomicity\uff09 # \u539f\u5b50\u6027\u662f\u6307\u4e8b\u52a1\u5305\u542b\u7684\u6240\u6709\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u6210\u529f\uff0c\u8981\u4e48\u5168\u90e8\u5931\u8d25\u56de\u6eda\uff0c\u8fd9\u548c\u524d\u9762\u4e24\u7bc7\u535a\u5ba2\u4ecb\u7ecd\u4e8b\u52a1\u7684\u529f\u80fd\u662f\u4e00\u6837\u7684\u6982\u5ff5\uff0c\u56e0\u6b64\u4e8b\u52a1\u7684\u64cd\u4f5c\u5982\u679c\u6210\u529f\u5c31\u5fc5\u987b\u8981\u5b8c\u5168\u5e94\u7528\u5230\u6570\u636e\u5e93\uff0c\u5982\u679c\u64cd\u4f5c\u5931\u8d25\u5219\u4e0d\u80fd\u5bf9\u6570\u636e\u5e93\u6709\u4efb\u4f55\u5f71\u54cd\u3002 \u2475 \u4e00\u81f4\u6027\uff08Consistency\uff09 # \u4e00\u81f4\u6027\u662f\u6307\u4e8b\u52a1\u5fc5\u987b\u4f7f\u6570\u636e\u5e93\u4ece\u4e00\u4e2a\u4e00\u81f4\u6027\u72b6\u6001\u53d8\u6362\u5230\u53e6\u4e00\u4e2a\u4e00\u81f4\u6027\u72b6\u6001\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u4e8b\u52a1\u6267\u884c\u4e4b\u524d\u548c\u6267\u884c\u4e4b\u540e\u90fd\u5fc5\u987b\u5904\u4e8e\u4e00\u81f4\u6027\u72b6\u6001\u3002 \u62ff\u8f6c\u8d26\u6765\u8bf4\uff0c\u5047\u8bbe\u7528\u6237A\u548c\u7528\u6237B\u4e24\u8005\u7684\u94b1\u52a0\u8d77\u6765\u4e00\u5171\u662f5000\uff0c\u90a3\u4e48\u4e0d\u7ba1A\u548cB\u4e4b\u95f4\u5982\u4f55\u8f6c\u8d26\uff0c\u8f6c\u51e0\u6b21\u8d26\uff0c\u4e8b\u52a1\u7ed3\u675f\u540e\u4e24\u4e2a\u7528\u6237\u7684\u94b1\u76f8\u52a0\u8d77\u6765\u5e94\u8be5\u8fd8\u5f97\u662f5000\uff0c\u8fd9\u5c31\u662f\u4e8b\u52a1\u7684\u4e00\u81f4\u6027\u3002 \u2476 \u9694\u79bb\u6027\uff08Isolation\uff09 # \u9694\u79bb\u6027 \u662f\u5f53\u591a\u4e2a\u7528\u6237\u5e76\u53d1\u8bbf\u95ee\u6570\u636e\u5e93\u65f6\uff0c\u6bd4\u5982\u64cd\u4f5c\u540c\u4e00\u5f20\u8868\u65f6\uff0c\u6570\u636e\u5e93\u4e3a\u6bcf\u4e00\u4e2a\u7528\u6237\u5f00\u542f\u7684\u4e8b\u52a1\uff0c\u4e0d\u80fd\u88ab\u5176\u4ed6\u4e8b\u52a1\u7684\u64cd\u4f5c\u6240\u5e72\u6270\uff0c\u591a\u4e2a\u5e76\u53d1\u4e8b\u52a1\u4e4b\u95f4\u8981\u76f8\u4e92 \u9694\u79bb \u3002 \u5373\u8981\u8fbe\u5230\u8fd9\u4e48\u4e00\u79cd\u6548\u679c\uff1a\u5bf9\u4e8e\u4efb\u610f\u4e24\u4e2a\u5e76\u53d1\u7684\u4e8b\u52a1T1\u548cT2\uff0c\u5728\u4e8b\u52a1T1\u770b\u6765\uff0cT2\u8981\u4e48\u5728T1\u5f00\u59cb\u4e4b\u524d\u5c31\u5df2\u7ecf\u7ed3\u675f\uff0c\u8981\u4e48\u5728T1\u7ed3\u675f\u4e4b\u540e\u624d\u5f00\u59cb\uff0c\u8fd9\u6837\u6bcf\u4e2a\u4e8b\u52a1\u90fd\u611f\u89c9\u4e0d\u5230\u6709\u5176\u4ed6\u4e8b\u52a1\u5728\u5e76\u53d1\u5730\u6267\u884c\u3002 \u5173\u4e8e\u4e8b\u52a1\u7684\u9694\u79bb\u6027\u6570\u636e\u5e93\u63d0\u4f9b\u4e86\u591a\u79cd\u9694\u79bb\u7ea7\u522b\uff0c\u7a0d\u540e\u4f1a\u4ecb\u7ecd\u5230\u3002 NOTE: \u53c2\u89c1\u6587\u7ae0level \u2477 \u6301\u4e45\u6027\uff08Durability\uff09 # \u6301\u4e45\u6027\u662f\u6307\u4e00\u4e2a\u4e8b\u52a1\u4e00\u65e6\u88ab\u63d0\u4ea4\u4e86\uff0c\u90a3\u4e48\u5bf9\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u7684\u6539\u53d8\u5c31\u662f\u6c38\u4e45\u6027\u7684\uff0c\u5373\u4fbf\u662f\u5728\u6570\u636e\u5e93\u7cfb\u7edf\u9047\u5230\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u4e22\u5931\u63d0\u4ea4\u4e8b\u52a1\u7684\u64cd\u4f5c\u3002 \u4f8b\u5982\u6211\u4eec\u5728\u4f7f\u7528JDBC\u64cd\u4f5c\u6570\u636e\u5e93\u65f6\uff0c\u5728\u63d0\u4ea4\u4e8b\u52a1\u65b9\u6cd5\u540e\uff0c\u63d0\u793a\u7528\u6237\u4e8b\u52a1\u64cd\u4f5c\u5b8c\u6210\uff0c\u5f53\u6211\u4eec\u7a0b\u5e8f\u6267\u884c\u5b8c\u6210\u76f4\u5230\u770b\u5230\u63d0\u793a\u540e\uff0c\u5c31\u53ef\u4ee5\u8ba4\u5b9a\u4e8b\u52a1\u4ee5\u53ca\u6b63\u786e\u63d0\u4ea4\uff0c\u5373\u4f7f\u8fd9\u65f6\u5019\u6570\u636e\u5e93\u51fa\u73b0\u4e86\u95ee\u9898\uff0c\u4e5f\u5fc5\u987b\u8981\u5c06\u6211\u4eec\u7684\u4e8b\u52a1\u5b8c\u5168\u6267\u884c\u5b8c\u6210\uff0c\u5426\u5219\u5c31\u4f1a\u9020\u6210\u6211\u4eec\u770b\u5230\u63d0\u793a\u4e8b\u52a1\u5904\u7406\u5b8c\u6bd5\uff0c\u4f46\u662f\u6570\u636e\u5e93\u56e0\u4e3a\u6545\u969c\u800c\u6ca1\u6709\u6267\u884c\u4e8b\u52a1\u7684\u91cd\u5927\u9519\u8bef\u3002 Problem # \u4ee5\u4e0a\u4ecb\u7ecd\u5b8c\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027(\u7b80\u79f0ACID)\uff0c\u73b0\u5728\u91cd\u70b9\u6765\u8bf4\u660e\u4e0b\u4e8b\u52a1\u7684 \u9694\u79bb\u6027 \uff0c\u5f53\u591a\u4e2a\u7ebf\u7a0b\u90fd\u5f00\u542f\u4e8b\u52a1\u64cd\u4f5c\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u65f6\uff0c\u6570\u636e\u5e93\u7cfb\u7edf\u8981\u80fd\u8fdb\u884c\u9694\u79bb\u64cd\u4f5c\uff0c\u4ee5\u4fdd\u8bc1\u5404\u4e2a\u7ebf\u7a0b\u83b7\u53d6\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u5728\u4ecb\u7ecd\u6570\u636e\u5e93\u63d0\u4f9b\u7684\u5404\u79cd \u9694\u79bb\u7ea7\u522b \u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u770b\u5982\u679c\u4e0d\u8003\u8651\u4e8b\u52a1\u7684 \u9694\u79bb\u6027 \uff0c\u4f1a\u53d1\u751f\u7684\u51e0\u79cd\u95ee\u9898\uff1a 1\uff0c\u810f\u8bfb # \u810f\u8bfb\u662f\u6307\u5728\u4e00\u4e2a\u4e8b\u52a1\u5904\u7406\u8fc7\u7a0b\u91cc\u8bfb\u53d6\u4e86\u53e6\u4e00\u4e2a\u672a\u63d0\u4ea4\u7684\u4e8b\u52a1\u4e2d\u7684\u6570\u636e\u3002 \u5f53\u4e00\u4e2a\u4e8b\u52a1\u6b63\u5728\u591a\u6b21\u4fee\u6539\u67d0\u4e2a\u6570\u636e\uff0c\u800c\u5728\u8fd9\u4e2a\u4e8b\u52a1\u4e2d\u8fd9\u591a\u6b21\u7684\u4fee\u6539\u90fd\u8fd8\u672a\u63d0\u4ea4\uff0c\u8fd9\u65f6\u4e00\u4e2a\u5e76\u53d1\u7684\u4e8b\u52a1\u6765\u8bbf\u95ee\u8be5\u6570\u636e\uff0c\u5c31\u4f1a\u9020\u6210\u4e24\u4e2a\u4e8b\u52a1\u5f97\u5230\u7684\u6570\u636e\u4e0d\u4e00\u81f4\u3002\u4f8b\u5982\uff1a\u7528\u6237A\u5411\u7528\u6237B\u8f6c\u8d26100\u5143\uff0c\u5bf9\u5e94SQL\u547d\u4ee4\u5982\u4e0b update account set money=money+100 where name=\u2019B\u2019; (\u6b64\u65f6A\u901a\u77e5B) update account set money=money - 100 where name=\u2019A\u2019; \u5f53\u53ea\u6267\u884c\u7b2c\u4e00\u6761SQL\u65f6\uff0cA\u901a\u77e5B\u67e5\u770b\u8d26\u6237\uff0cB\u53d1\u73b0\u786e\u5b9e\u94b1\u5df2\u5230\u8d26\uff08\u6b64\u65f6\u5373\u53d1\u751f\u4e86\u810f\u8bfb\uff09\uff0c\u800c\u4e4b\u540e\u65e0\u8bba\u7b2c\u4e8c\u6761SQL\u662f\u5426\u6267\u884c\uff0c\u53ea\u8981\u8be5\u4e8b\u52a1\u4e0d\u63d0\u4ea4\uff0c\u5219\u6240\u6709\u64cd\u4f5c\u90fd\u5c06\u56de\u6eda\uff0c\u90a3\u4e48\u5f53B\u4ee5\u540e\u518d\u6b21\u67e5\u770b\u8d26\u6237\u65f6\u5c31\u4f1a\u53d1\u73b0\u94b1\u5176\u5b9e\u5e76\u6ca1\u6709\u8f6c\u3002 2\uff0c\u4e0d\u53ef\u91cd\u590d\u8bfb # \u4e0d\u53ef\u91cd\u590d\u8bfb\u662f\u6307\u5728\u5bf9\u4e8e\u6570\u636e\u5e93\u4e2d\u7684\u67d0\u4e2a\u6570\u636e\uff0c\u4e00\u4e2a\u4e8b\u52a1\u8303\u56f4\u5185\u591a\u6b21\u67e5\u8be2\u5374\u8fd4\u56de\u4e86\u4e0d\u540c\u7684\u6570\u636e\u503c\uff0c\u8fd9\u662f\u7531\u4e8e\u5728\u67e5\u8be2\u95f4\u9694\uff0c\u88ab\u53e6\u4e00\u4e2a\u4e8b\u52a1\u4fee\u6539\u5e76\u63d0\u4ea4\u4e86\u3002 \u4f8b\u5982\u4e8b\u52a1T1\u5728\u8bfb\u53d6\u67d0\u4e00\u6570\u636e\uff0c\u800c\u4e8b\u52a1T2\u7acb\u9a6c\u4fee\u6539\u4e86\u8fd9\u4e2a\u6570\u636e\u5e76\u4e14\u63d0\u4ea4\u4e8b\u52a1\u7ed9\u6570\u636e\u5e93\uff0c\u4e8b\u52a1T1\u518d\u6b21\u8bfb\u53d6\u8be5\u6570\u636e\u5c31\u5f97\u5230\u4e86\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u53d1\u9001\u4e86\u4e0d\u53ef\u91cd\u590d\u8bfb\u3002 \u4e0d\u53ef\u91cd\u590d\u8bfb\u548c\u810f\u8bfb\u7684\u533a\u522b\u662f\uff0c\u810f\u8bfb\u662f\u67d0\u4e00\u4e8b\u52a1\u8bfb\u53d6\u4e86\u53e6\u4e00\u4e2a\u4e8b\u52a1\u672a\u63d0\u4ea4\u7684\u810f\u6570\u636e\uff0c\u800c\u4e0d\u53ef\u91cd\u590d\u8bfb\u5219\u662f\u8bfb\u53d6\u4e86\u524d\u4e00\u4e8b\u52a1\u63d0\u4ea4\u7684\u6570\u636e\u3002 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4e0d\u53ef\u91cd\u590d\u8bfb\u5e76\u4e0d\u662f\u95ee\u9898\uff0c\u6bd4\u5982\u6211\u4eec\u591a\u6b21\u67e5\u8be2\u67d0\u4e2a\u6570\u636e\u5f53\u7136\u4ee5\u6700\u540e\u67e5\u8be2\u5f97\u5230\u7684\u7ed3\u679c\u4e3a\u4e3b\u3002\u4f46\u5728\u53e6\u4e00\u4e9b\u60c5\u51b5\u4e0b\u5c31\u6709\u53ef\u80fd\u53d1\u751f\u95ee\u9898\uff0c\u4f8b\u5982\u5bf9\u4e8e\u540c\u4e00\u4e2a\u6570\u636eA\u548cB\u4f9d\u6b21\u67e5\u8be2\u5c31\u53ef\u80fd\u4e0d\u540c\uff0cA\u548cB\u5c31\u53ef\u80fd\u6253\u8d77\u6765\u4e86\u2026\u2026 3\uff0c\u865a\u8bfb(\u5e7b\u8bfb) # \u5e7b\u8bfb\u662f\u4e8b\u52a1\u975e\u72ec\u7acb\u6267\u884c\u65f6\u53d1\u751f\u7684\u4e00\u79cd\u73b0\u8c61\u3002\u4f8b\u5982\u4e8b\u52a1T1\u5bf9\u4e00\u4e2a\u8868\u4e2d\u6240\u6709\u7684\u884c\u7684\u67d0\u4e2a\u6570\u636e\u9879\u505a\u4e86\u4ece\u201c1\u201d\u4fee\u6539\u4e3a\u201c2\u201d\u7684\u64cd\u4f5c\uff0c\u8fd9\u65f6\u4e8b\u52a1T2\u53c8\u5bf9\u8fd9\u4e2a\u8868\u4e2d\u63d2\u5165\u4e86\u4e00\u884c\u6570\u636e\u9879\uff0c\u800c\u8fd9\u4e2a\u6570\u636e\u9879\u7684\u6570\u503c\u8fd8\u662f\u4e3a\u201c1\u201d\u5e76\u4e14\u63d0\u4ea4\u7ed9\u6570\u636e\u5e93\u3002\u800c\u64cd\u4f5c\u4e8b\u52a1T1\u7684\u7528\u6237\u5982\u679c\u518d\u67e5\u770b\u521a\u521a\u4fee\u6539\u7684\u6570\u636e\uff0c\u4f1a\u53d1\u73b0\u8fd8\u6709\u4e00\u884c\u6ca1\u6709\u4fee\u6539\uff0c\u5176\u5b9e\u8fd9\u884c\u662f\u4ece\u4e8b\u52a1T2\u4e2d\u6dfb\u52a0\u7684\uff0c\u5c31\u597d\u50cf\u4ea7\u751f\u5e7b\u89c9\u4e00\u6837\uff0c\u8fd9\u5c31\u662f\u53d1\u751f\u4e86\u5e7b\u8bfb\u3002 \u5e7b\u8bfb\u548c\u4e0d\u53ef\u91cd\u590d\u8bfb\u90fd\u662f\u8bfb\u53d6\u4e86\u53e6\u4e00\u6761\u5df2\u7ecf\u63d0\u4ea4\u7684\u4e8b\u52a1\uff08\u8fd9\u70b9\u5c31\u810f\u8bfb\u4e0d\u540c\uff09\uff0c\u6240\u4e0d\u540c\u7684\u662f\u4e0d\u53ef\u91cd\u590d\u8bfb\u67e5\u8be2\u7684\u90fd\u662f\u540c\u4e00\u4e2a\u6570\u636e\u9879\uff0c\u800c\u5e7b\u8bfb\u9488\u5bf9\u7684\u662f\u4e00\u6279\u6570\u636e\u6574\u4f53\uff08\u6bd4\u5982\u6570\u636e\u7684\u4e2a\u6570\uff09\u3002 Isolation level # \u73b0\u5728\u6765\u770b\u770bMySQL\u6570\u636e\u5e93\u4e3a\u6211\u4eec\u63d0\u4f9b\u7684\u56db\u79cd\u9694\u79bb\u7ea7\u522b\uff1a \u2460 Serializable (\u4e32\u884c\u5316)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u3001\u4e0d\u53ef\u91cd\u590d\u8bfb\u3001\u5e7b\u8bfb\u7684\u53d1\u751f\u3002 \u2461 Repeatable read (\u53ef\u91cd\u590d\u8bfb)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u3001\u4e0d\u53ef\u91cd\u590d\u8bfb\u7684\u53d1\u751f\u3002 \u2462 Read committed (\u8bfb\u5df2\u63d0\u4ea4)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u7684\u53d1\u751f\u3002 \u2463 Read uncommitted (\u8bfb\u672a\u63d0\u4ea4)\uff1a\u6700\u4f4e\u7ea7\u522b\uff0c\u4efb\u4f55\u60c5\u51b5\u90fd\u65e0\u6cd5\u4fdd\u8bc1\u3002 \u4ee5\u4e0a\u56db\u79cd\u9694\u79bb\u7ea7\u522b\u6700\u9ad8\u7684\u662fSerializable\u7ea7\u522b\uff0c\u6700\u4f4e\u7684\u662fRead uncommitted\u7ea7\u522b\uff0c\u5f53\u7136\u7ea7\u522b\u8d8a\u9ad8\uff0c\u6267\u884c\u6548\u7387\u5c31\u8d8a\u4f4e\u3002\u50cfSerializable\u8fd9\u6837\u7684\u7ea7\u522b\uff0c\u5c31\u662f\u4ee5\u9501\u8868\u7684\u65b9\u5f0f(\u7c7b\u4f3c\u4e8eJava\u591a\u7ebf\u7a0b\u4e2d\u7684\u9501)\u4f7f\u5f97\u5176\u4ed6\u7684\u7ebf\u7a0b\u53ea\u80fd\u5728\u9501\u5916\u7b49\u5f85\uff0c\u6240\u4ee5\u5e73\u65f6\u9009\u7528\u4f55\u79cd\u9694\u79bb\u7ea7\u522b\u5e94\u8be5\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u3002\u5728MySQL\u6570\u636e\u5e93\u4e2d\u9ed8\u8ba4\u7684\u9694\u79bb\u7ea7\u522b\u4e3aRepeatable read (\u53ef\u91cd\u590d\u8bfb)\u3002 \u5728MySQL\u6570\u636e\u5e93\u4e2d\uff0c\u652f\u6301\u4e0a\u9762\u56db\u79cd\u9694\u79bb\u7ea7\u522b\uff0c\u9ed8\u8ba4\u7684\u4e3aRepeatable read (\u53ef\u91cd\u590d\u8bfb)\uff1b\u800c\u5728Oracle\u6570\u636e\u5e93\u4e2d\uff0c\u53ea\u652f\u6301Serializable (\u4e32\u884c\u5316)\u7ea7\u522b\u548cRead committed (\u8bfb\u5df2\u63d0\u4ea4)\u8fd9\u4e24\u79cd\u7ea7\u522b\uff0c\u5176\u4e2d\u9ed8\u8ba4\u7684\u4e3aRead committed\u7ea7\u522b\u3002 \u5728MySQL\u6570\u636e\u5e93\u4e2d\u67e5\u770b\u5f53\u524d\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\uff1a select @@tx_isolation; \u5728MySQL\u6570\u636e\u5e93\u4e2d\u8bbe\u7f6e\u4e8b\u52a1\u7684\u9694\u79bb \u7ea7\u522b\uff1a set [glogal | session] transaction isolation level \u9694\u79bb\u7ea7\u522b\u540d\u79f0; set tx_isolation=\u2019\u9694\u79bb\u7ea7\u522b\u540d\u79f0;\u2019 \u4f8b1\uff1a\u67e5\u770b\u5f53\u524d\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\uff1a \u4f8b2\uff1a\u5c06\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u8bbe\u7f6e\u4e3aRead uncommitted\u7ea7\u522b\uff1a \u6216\uff1a \u8bb0\u4f4f\uff1a\u8bbe\u7f6e\u6570\u636e\u5e93\u7684\u9694\u79bb\u7ea7\u522b\u4e00\u5b9a\u8981\u662f\u5728\u5f00\u542f\u4e8b\u52a1\u4e4b\u524d\uff01 \u5982\u679c\u662f\u4f7f\u7528JDBC\u5bf9\u6570\u636e\u5e93\u7684\u4e8b\u52a1\u8bbe\u7f6e\u9694\u79bb\u7ea7\u522b\u7684\u8bdd\uff0c\u4e5f\u5e94\u8be5\u662f\u5728\u8c03\u7528Connection\u5bf9\u8c61\u7684setAutoCommit(false)\u65b9\u6cd5\u4e4b\u524d\u3002\u8c03\u7528Connection\u5bf9\u8c61\u7684setTransactionIsolation(level)\u5373\u53ef\u8bbe\u7f6e\u5f53\u524d\u94fe\u63a5\u7684\u9694\u79bb\u7ea7\u522b\uff0c\u81f3\u4e8e\u53c2\u6570level\uff0c\u53ef\u4ee5\u4f7f\u7528Connection\u5bf9\u8c61\u7684\u5b57\u6bb5\uff1a \u5728JDBC\u4e2d\u8bbe\u7f6e\u9694\u79bb\u7ea7\u522b\u7684\u90e8\u5206\u4ee3\u7801\uff1a \u540e\u8bb0\uff1a\u9694\u79bb\u7ea7\u522b\u7684\u8bbe\u7f6e\u53ea\u5bf9\u5f53\u524d\u94fe\u63a5\u6709\u6548\u3002\u5bf9\u4e8e\u4f7f\u7528MySQL\u547d\u4ee4\u7a97\u53e3\u800c\u8a00\uff0c\u4e00\u4e2a\u7a97\u53e3\u5c31\u76f8\u5f53\u4e8e\u4e00\u4e2a\u94fe\u63a5\uff0c\u5f53\u524d\u7a97\u53e3\u8bbe\u7f6e\u7684\u9694\u79bb\u7ea7\u522b\u53ea\u5bf9\u5f53\u524d\u7a97\u53e3\u4e2d\u7684\u4e8b\u52a1\u6709\u6548\uff1b\u5bf9\u4e8eJDBC\u64cd\u4f5c\u6570\u636e\u5e93\u6765\u8bf4\uff0c\u4e00\u4e2aConnection\u5bf9\u8c61\u76f8\u5f53\u4e8e\u4e00\u4e2a\u94fe\u63a5\uff0c\u800c\u5bf9\u4e8eConnection\u5bf9\u8c61\u8bbe\u7f6e\u7684\u9694\u79bb\u7ea7\u522b\u53ea\u5bf9\u8be5Connection\u5bf9\u8c61\u6709\u6548\uff0c\u4e0e\u5176\u4ed6\u94fe\u63a5Connection\u5bf9\u8c61\u65e0\u5173\u3002 \u53c2\u8003\u535a\u5ba2\uff1a http://www.zhihu.com/question/23989904 http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html http://www.cnblogs.com/xdp-gacl/p/3984001.html wikipedia ACID # In computer science , ACID ( atomicity , consistency , isolation , durability ) is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps. In the context of databases , a sequence of database operations that satisfies the ACID properties (which can be perceived as a single logical operation on the data) is called a transaction . For example, a transfer of funds from one bank account to another, even involving multiple changes such as debiting one account and crediting another, is a single transaction.","title":"ACID"},{"location":"Theory/Database-transaction/ACID/#acid","text":"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u6709DB transaction\u624d\u5177\u5907ACID\u7279\u6027\uff0c\u5176\u4ed6\u7684transaction\u4e0d\u4e00\u5b9a\u5177\u5907ACID\u7279\u6027\u3002","title":"ACID"},{"location":"Theory/Database-transaction/ACID/#cnblogs","text":"\u672c\u7bc7\u8bb2\u8bc9\u6570\u636e\u5e93\u4e2d\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\uff08ACID\uff09\uff0c\u5e76\u4e14\u5c06\u4f1a\u8be6\u7ec6\u5730\u8bf4\u660e\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u3002 \u5982\u679c\u4e00\u4e2a\u6570\u636e\u5e93\u58f0\u79f0\u652f\u6301\u4e8b\u52a1\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48\u8be5\u6570\u636e\u5e93\u5fc5\u987b\u8981\u5177\u5907\u4ee5\u4e0b\u56db\u4e2a\u7279\u6027\uff1a","title":"cnblogs \u6570\u636e\u5e93\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\u4ee5\u53ca\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b"},{"location":"Theory/Database-transaction/ACID/#1-atomicity","text":"\u539f\u5b50\u6027\u662f\u6307\u4e8b\u52a1\u5305\u542b\u7684\u6240\u6709\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u6210\u529f\uff0c\u8981\u4e48\u5168\u90e8\u5931\u8d25\u56de\u6eda\uff0c\u8fd9\u548c\u524d\u9762\u4e24\u7bc7\u535a\u5ba2\u4ecb\u7ecd\u4e8b\u52a1\u7684\u529f\u80fd\u662f\u4e00\u6837\u7684\u6982\u5ff5\uff0c\u56e0\u6b64\u4e8b\u52a1\u7684\u64cd\u4f5c\u5982\u679c\u6210\u529f\u5c31\u5fc5\u987b\u8981\u5b8c\u5168\u5e94\u7528\u5230\u6570\u636e\u5e93\uff0c\u5982\u679c\u64cd\u4f5c\u5931\u8d25\u5219\u4e0d\u80fd\u5bf9\u6570\u636e\u5e93\u6709\u4efb\u4f55\u5f71\u54cd\u3002","title":"\u2474 \u539f\u5b50\u6027\uff08Atomicity\uff09"},{"location":"Theory/Database-transaction/ACID/#2-consistency","text":"\u4e00\u81f4\u6027\u662f\u6307\u4e8b\u52a1\u5fc5\u987b\u4f7f\u6570\u636e\u5e93\u4ece\u4e00\u4e2a\u4e00\u81f4\u6027\u72b6\u6001\u53d8\u6362\u5230\u53e6\u4e00\u4e2a\u4e00\u81f4\u6027\u72b6\u6001\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u4e8b\u52a1\u6267\u884c\u4e4b\u524d\u548c\u6267\u884c\u4e4b\u540e\u90fd\u5fc5\u987b\u5904\u4e8e\u4e00\u81f4\u6027\u72b6\u6001\u3002 \u62ff\u8f6c\u8d26\u6765\u8bf4\uff0c\u5047\u8bbe\u7528\u6237A\u548c\u7528\u6237B\u4e24\u8005\u7684\u94b1\u52a0\u8d77\u6765\u4e00\u5171\u662f5000\uff0c\u90a3\u4e48\u4e0d\u7ba1A\u548cB\u4e4b\u95f4\u5982\u4f55\u8f6c\u8d26\uff0c\u8f6c\u51e0\u6b21\u8d26\uff0c\u4e8b\u52a1\u7ed3\u675f\u540e\u4e24\u4e2a\u7528\u6237\u7684\u94b1\u76f8\u52a0\u8d77\u6765\u5e94\u8be5\u8fd8\u5f97\u662f5000\uff0c\u8fd9\u5c31\u662f\u4e8b\u52a1\u7684\u4e00\u81f4\u6027\u3002","title":"\u2475 \u4e00\u81f4\u6027\uff08Consistency\uff09"},{"location":"Theory/Database-transaction/ACID/#3-isolation","text":"\u9694\u79bb\u6027 \u662f\u5f53\u591a\u4e2a\u7528\u6237\u5e76\u53d1\u8bbf\u95ee\u6570\u636e\u5e93\u65f6\uff0c\u6bd4\u5982\u64cd\u4f5c\u540c\u4e00\u5f20\u8868\u65f6\uff0c\u6570\u636e\u5e93\u4e3a\u6bcf\u4e00\u4e2a\u7528\u6237\u5f00\u542f\u7684\u4e8b\u52a1\uff0c\u4e0d\u80fd\u88ab\u5176\u4ed6\u4e8b\u52a1\u7684\u64cd\u4f5c\u6240\u5e72\u6270\uff0c\u591a\u4e2a\u5e76\u53d1\u4e8b\u52a1\u4e4b\u95f4\u8981\u76f8\u4e92 \u9694\u79bb \u3002 \u5373\u8981\u8fbe\u5230\u8fd9\u4e48\u4e00\u79cd\u6548\u679c\uff1a\u5bf9\u4e8e\u4efb\u610f\u4e24\u4e2a\u5e76\u53d1\u7684\u4e8b\u52a1T1\u548cT2\uff0c\u5728\u4e8b\u52a1T1\u770b\u6765\uff0cT2\u8981\u4e48\u5728T1\u5f00\u59cb\u4e4b\u524d\u5c31\u5df2\u7ecf\u7ed3\u675f\uff0c\u8981\u4e48\u5728T1\u7ed3\u675f\u4e4b\u540e\u624d\u5f00\u59cb\uff0c\u8fd9\u6837\u6bcf\u4e2a\u4e8b\u52a1\u90fd\u611f\u89c9\u4e0d\u5230\u6709\u5176\u4ed6\u4e8b\u52a1\u5728\u5e76\u53d1\u5730\u6267\u884c\u3002 \u5173\u4e8e\u4e8b\u52a1\u7684\u9694\u79bb\u6027\u6570\u636e\u5e93\u63d0\u4f9b\u4e86\u591a\u79cd\u9694\u79bb\u7ea7\u522b\uff0c\u7a0d\u540e\u4f1a\u4ecb\u7ecd\u5230\u3002 NOTE: \u53c2\u89c1\u6587\u7ae0level","title":"\u2476 \u9694\u79bb\u6027\uff08Isolation\uff09"},{"location":"Theory/Database-transaction/ACID/#4-durability","text":"\u6301\u4e45\u6027\u662f\u6307\u4e00\u4e2a\u4e8b\u52a1\u4e00\u65e6\u88ab\u63d0\u4ea4\u4e86\uff0c\u90a3\u4e48\u5bf9\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u7684\u6539\u53d8\u5c31\u662f\u6c38\u4e45\u6027\u7684\uff0c\u5373\u4fbf\u662f\u5728\u6570\u636e\u5e93\u7cfb\u7edf\u9047\u5230\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u4e22\u5931\u63d0\u4ea4\u4e8b\u52a1\u7684\u64cd\u4f5c\u3002 \u4f8b\u5982\u6211\u4eec\u5728\u4f7f\u7528JDBC\u64cd\u4f5c\u6570\u636e\u5e93\u65f6\uff0c\u5728\u63d0\u4ea4\u4e8b\u52a1\u65b9\u6cd5\u540e\uff0c\u63d0\u793a\u7528\u6237\u4e8b\u52a1\u64cd\u4f5c\u5b8c\u6210\uff0c\u5f53\u6211\u4eec\u7a0b\u5e8f\u6267\u884c\u5b8c\u6210\u76f4\u5230\u770b\u5230\u63d0\u793a\u540e\uff0c\u5c31\u53ef\u4ee5\u8ba4\u5b9a\u4e8b\u52a1\u4ee5\u53ca\u6b63\u786e\u63d0\u4ea4\uff0c\u5373\u4f7f\u8fd9\u65f6\u5019\u6570\u636e\u5e93\u51fa\u73b0\u4e86\u95ee\u9898\uff0c\u4e5f\u5fc5\u987b\u8981\u5c06\u6211\u4eec\u7684\u4e8b\u52a1\u5b8c\u5168\u6267\u884c\u5b8c\u6210\uff0c\u5426\u5219\u5c31\u4f1a\u9020\u6210\u6211\u4eec\u770b\u5230\u63d0\u793a\u4e8b\u52a1\u5904\u7406\u5b8c\u6bd5\uff0c\u4f46\u662f\u6570\u636e\u5e93\u56e0\u4e3a\u6545\u969c\u800c\u6ca1\u6709\u6267\u884c\u4e8b\u52a1\u7684\u91cd\u5927\u9519\u8bef\u3002","title":"\u2477 \u6301\u4e45\u6027\uff08Durability\uff09"},{"location":"Theory/Database-transaction/ACID/#problem","text":"\u4ee5\u4e0a\u4ecb\u7ecd\u5b8c\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027(\u7b80\u79f0ACID)\uff0c\u73b0\u5728\u91cd\u70b9\u6765\u8bf4\u660e\u4e0b\u4e8b\u52a1\u7684 \u9694\u79bb\u6027 \uff0c\u5f53\u591a\u4e2a\u7ebf\u7a0b\u90fd\u5f00\u542f\u4e8b\u52a1\u64cd\u4f5c\u6570\u636e\u5e93\u4e2d\u7684\u6570\u636e\u65f6\uff0c\u6570\u636e\u5e93\u7cfb\u7edf\u8981\u80fd\u8fdb\u884c\u9694\u79bb\u64cd\u4f5c\uff0c\u4ee5\u4fdd\u8bc1\u5404\u4e2a\u7ebf\u7a0b\u83b7\u53d6\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u5728\u4ecb\u7ecd\u6570\u636e\u5e93\u63d0\u4f9b\u7684\u5404\u79cd \u9694\u79bb\u7ea7\u522b \u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u770b\u5982\u679c\u4e0d\u8003\u8651\u4e8b\u52a1\u7684 \u9694\u79bb\u6027 \uff0c\u4f1a\u53d1\u751f\u7684\u51e0\u79cd\u95ee\u9898\uff1a","title":"Problem"},{"location":"Theory/Database-transaction/ACID/#1","text":"\u810f\u8bfb\u662f\u6307\u5728\u4e00\u4e2a\u4e8b\u52a1\u5904\u7406\u8fc7\u7a0b\u91cc\u8bfb\u53d6\u4e86\u53e6\u4e00\u4e2a\u672a\u63d0\u4ea4\u7684\u4e8b\u52a1\u4e2d\u7684\u6570\u636e\u3002 \u5f53\u4e00\u4e2a\u4e8b\u52a1\u6b63\u5728\u591a\u6b21\u4fee\u6539\u67d0\u4e2a\u6570\u636e\uff0c\u800c\u5728\u8fd9\u4e2a\u4e8b\u52a1\u4e2d\u8fd9\u591a\u6b21\u7684\u4fee\u6539\u90fd\u8fd8\u672a\u63d0\u4ea4\uff0c\u8fd9\u65f6\u4e00\u4e2a\u5e76\u53d1\u7684\u4e8b\u52a1\u6765\u8bbf\u95ee\u8be5\u6570\u636e\uff0c\u5c31\u4f1a\u9020\u6210\u4e24\u4e2a\u4e8b\u52a1\u5f97\u5230\u7684\u6570\u636e\u4e0d\u4e00\u81f4\u3002\u4f8b\u5982\uff1a\u7528\u6237A\u5411\u7528\u6237B\u8f6c\u8d26100\u5143\uff0c\u5bf9\u5e94SQL\u547d\u4ee4\u5982\u4e0b update account set money=money+100 where name=\u2019B\u2019; (\u6b64\u65f6A\u901a\u77e5B) update account set money=money - 100 where name=\u2019A\u2019; \u5f53\u53ea\u6267\u884c\u7b2c\u4e00\u6761SQL\u65f6\uff0cA\u901a\u77e5B\u67e5\u770b\u8d26\u6237\uff0cB\u53d1\u73b0\u786e\u5b9e\u94b1\u5df2\u5230\u8d26\uff08\u6b64\u65f6\u5373\u53d1\u751f\u4e86\u810f\u8bfb\uff09\uff0c\u800c\u4e4b\u540e\u65e0\u8bba\u7b2c\u4e8c\u6761SQL\u662f\u5426\u6267\u884c\uff0c\u53ea\u8981\u8be5\u4e8b\u52a1\u4e0d\u63d0\u4ea4\uff0c\u5219\u6240\u6709\u64cd\u4f5c\u90fd\u5c06\u56de\u6eda\uff0c\u90a3\u4e48\u5f53B\u4ee5\u540e\u518d\u6b21\u67e5\u770b\u8d26\u6237\u65f6\u5c31\u4f1a\u53d1\u73b0\u94b1\u5176\u5b9e\u5e76\u6ca1\u6709\u8f6c\u3002","title":"1\uff0c\u810f\u8bfb"},{"location":"Theory/Database-transaction/ACID/#2","text":"\u4e0d\u53ef\u91cd\u590d\u8bfb\u662f\u6307\u5728\u5bf9\u4e8e\u6570\u636e\u5e93\u4e2d\u7684\u67d0\u4e2a\u6570\u636e\uff0c\u4e00\u4e2a\u4e8b\u52a1\u8303\u56f4\u5185\u591a\u6b21\u67e5\u8be2\u5374\u8fd4\u56de\u4e86\u4e0d\u540c\u7684\u6570\u636e\u503c\uff0c\u8fd9\u662f\u7531\u4e8e\u5728\u67e5\u8be2\u95f4\u9694\uff0c\u88ab\u53e6\u4e00\u4e2a\u4e8b\u52a1\u4fee\u6539\u5e76\u63d0\u4ea4\u4e86\u3002 \u4f8b\u5982\u4e8b\u52a1T1\u5728\u8bfb\u53d6\u67d0\u4e00\u6570\u636e\uff0c\u800c\u4e8b\u52a1T2\u7acb\u9a6c\u4fee\u6539\u4e86\u8fd9\u4e2a\u6570\u636e\u5e76\u4e14\u63d0\u4ea4\u4e8b\u52a1\u7ed9\u6570\u636e\u5e93\uff0c\u4e8b\u52a1T1\u518d\u6b21\u8bfb\u53d6\u8be5\u6570\u636e\u5c31\u5f97\u5230\u4e86\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u53d1\u9001\u4e86\u4e0d\u53ef\u91cd\u590d\u8bfb\u3002 \u4e0d\u53ef\u91cd\u590d\u8bfb\u548c\u810f\u8bfb\u7684\u533a\u522b\u662f\uff0c\u810f\u8bfb\u662f\u67d0\u4e00\u4e8b\u52a1\u8bfb\u53d6\u4e86\u53e6\u4e00\u4e2a\u4e8b\u52a1\u672a\u63d0\u4ea4\u7684\u810f\u6570\u636e\uff0c\u800c\u4e0d\u53ef\u91cd\u590d\u8bfb\u5219\u662f\u8bfb\u53d6\u4e86\u524d\u4e00\u4e8b\u52a1\u63d0\u4ea4\u7684\u6570\u636e\u3002 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4e0d\u53ef\u91cd\u590d\u8bfb\u5e76\u4e0d\u662f\u95ee\u9898\uff0c\u6bd4\u5982\u6211\u4eec\u591a\u6b21\u67e5\u8be2\u67d0\u4e2a\u6570\u636e\u5f53\u7136\u4ee5\u6700\u540e\u67e5\u8be2\u5f97\u5230\u7684\u7ed3\u679c\u4e3a\u4e3b\u3002\u4f46\u5728\u53e6\u4e00\u4e9b\u60c5\u51b5\u4e0b\u5c31\u6709\u53ef\u80fd\u53d1\u751f\u95ee\u9898\uff0c\u4f8b\u5982\u5bf9\u4e8e\u540c\u4e00\u4e2a\u6570\u636eA\u548cB\u4f9d\u6b21\u67e5\u8be2\u5c31\u53ef\u80fd\u4e0d\u540c\uff0cA\u548cB\u5c31\u53ef\u80fd\u6253\u8d77\u6765\u4e86\u2026\u2026","title":"2\uff0c\u4e0d\u53ef\u91cd\u590d\u8bfb"},{"location":"Theory/Database-transaction/ACID/#3","text":"\u5e7b\u8bfb\u662f\u4e8b\u52a1\u975e\u72ec\u7acb\u6267\u884c\u65f6\u53d1\u751f\u7684\u4e00\u79cd\u73b0\u8c61\u3002\u4f8b\u5982\u4e8b\u52a1T1\u5bf9\u4e00\u4e2a\u8868\u4e2d\u6240\u6709\u7684\u884c\u7684\u67d0\u4e2a\u6570\u636e\u9879\u505a\u4e86\u4ece\u201c1\u201d\u4fee\u6539\u4e3a\u201c2\u201d\u7684\u64cd\u4f5c\uff0c\u8fd9\u65f6\u4e8b\u52a1T2\u53c8\u5bf9\u8fd9\u4e2a\u8868\u4e2d\u63d2\u5165\u4e86\u4e00\u884c\u6570\u636e\u9879\uff0c\u800c\u8fd9\u4e2a\u6570\u636e\u9879\u7684\u6570\u503c\u8fd8\u662f\u4e3a\u201c1\u201d\u5e76\u4e14\u63d0\u4ea4\u7ed9\u6570\u636e\u5e93\u3002\u800c\u64cd\u4f5c\u4e8b\u52a1T1\u7684\u7528\u6237\u5982\u679c\u518d\u67e5\u770b\u521a\u521a\u4fee\u6539\u7684\u6570\u636e\uff0c\u4f1a\u53d1\u73b0\u8fd8\u6709\u4e00\u884c\u6ca1\u6709\u4fee\u6539\uff0c\u5176\u5b9e\u8fd9\u884c\u662f\u4ece\u4e8b\u52a1T2\u4e2d\u6dfb\u52a0\u7684\uff0c\u5c31\u597d\u50cf\u4ea7\u751f\u5e7b\u89c9\u4e00\u6837\uff0c\u8fd9\u5c31\u662f\u53d1\u751f\u4e86\u5e7b\u8bfb\u3002 \u5e7b\u8bfb\u548c\u4e0d\u53ef\u91cd\u590d\u8bfb\u90fd\u662f\u8bfb\u53d6\u4e86\u53e6\u4e00\u6761\u5df2\u7ecf\u63d0\u4ea4\u7684\u4e8b\u52a1\uff08\u8fd9\u70b9\u5c31\u810f\u8bfb\u4e0d\u540c\uff09\uff0c\u6240\u4e0d\u540c\u7684\u662f\u4e0d\u53ef\u91cd\u590d\u8bfb\u67e5\u8be2\u7684\u90fd\u662f\u540c\u4e00\u4e2a\u6570\u636e\u9879\uff0c\u800c\u5e7b\u8bfb\u9488\u5bf9\u7684\u662f\u4e00\u6279\u6570\u636e\u6574\u4f53\uff08\u6bd4\u5982\u6570\u636e\u7684\u4e2a\u6570\uff09\u3002","title":"3\uff0c\u865a\u8bfb(\u5e7b\u8bfb)"},{"location":"Theory/Database-transaction/ACID/#isolation-level","text":"\u73b0\u5728\u6765\u770b\u770bMySQL\u6570\u636e\u5e93\u4e3a\u6211\u4eec\u63d0\u4f9b\u7684\u56db\u79cd\u9694\u79bb\u7ea7\u522b\uff1a \u2460 Serializable (\u4e32\u884c\u5316)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u3001\u4e0d\u53ef\u91cd\u590d\u8bfb\u3001\u5e7b\u8bfb\u7684\u53d1\u751f\u3002 \u2461 Repeatable read (\u53ef\u91cd\u590d\u8bfb)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u3001\u4e0d\u53ef\u91cd\u590d\u8bfb\u7684\u53d1\u751f\u3002 \u2462 Read committed (\u8bfb\u5df2\u63d0\u4ea4)\uff1a\u53ef\u907f\u514d\u810f\u8bfb\u7684\u53d1\u751f\u3002 \u2463 Read uncommitted (\u8bfb\u672a\u63d0\u4ea4)\uff1a\u6700\u4f4e\u7ea7\u522b\uff0c\u4efb\u4f55\u60c5\u51b5\u90fd\u65e0\u6cd5\u4fdd\u8bc1\u3002 \u4ee5\u4e0a\u56db\u79cd\u9694\u79bb\u7ea7\u522b\u6700\u9ad8\u7684\u662fSerializable\u7ea7\u522b\uff0c\u6700\u4f4e\u7684\u662fRead uncommitted\u7ea7\u522b\uff0c\u5f53\u7136\u7ea7\u522b\u8d8a\u9ad8\uff0c\u6267\u884c\u6548\u7387\u5c31\u8d8a\u4f4e\u3002\u50cfSerializable\u8fd9\u6837\u7684\u7ea7\u522b\uff0c\u5c31\u662f\u4ee5\u9501\u8868\u7684\u65b9\u5f0f(\u7c7b\u4f3c\u4e8eJava\u591a\u7ebf\u7a0b\u4e2d\u7684\u9501)\u4f7f\u5f97\u5176\u4ed6\u7684\u7ebf\u7a0b\u53ea\u80fd\u5728\u9501\u5916\u7b49\u5f85\uff0c\u6240\u4ee5\u5e73\u65f6\u9009\u7528\u4f55\u79cd\u9694\u79bb\u7ea7\u522b\u5e94\u8be5\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u3002\u5728MySQL\u6570\u636e\u5e93\u4e2d\u9ed8\u8ba4\u7684\u9694\u79bb\u7ea7\u522b\u4e3aRepeatable read (\u53ef\u91cd\u590d\u8bfb)\u3002 \u5728MySQL\u6570\u636e\u5e93\u4e2d\uff0c\u652f\u6301\u4e0a\u9762\u56db\u79cd\u9694\u79bb\u7ea7\u522b\uff0c\u9ed8\u8ba4\u7684\u4e3aRepeatable read (\u53ef\u91cd\u590d\u8bfb)\uff1b\u800c\u5728Oracle\u6570\u636e\u5e93\u4e2d\uff0c\u53ea\u652f\u6301Serializable (\u4e32\u884c\u5316)\u7ea7\u522b\u548cRead committed (\u8bfb\u5df2\u63d0\u4ea4)\u8fd9\u4e24\u79cd\u7ea7\u522b\uff0c\u5176\u4e2d\u9ed8\u8ba4\u7684\u4e3aRead committed\u7ea7\u522b\u3002 \u5728MySQL\u6570\u636e\u5e93\u4e2d\u67e5\u770b\u5f53\u524d\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\uff1a select @@tx_isolation; \u5728MySQL\u6570\u636e\u5e93\u4e2d\u8bbe\u7f6e\u4e8b\u52a1\u7684\u9694\u79bb \u7ea7\u522b\uff1a set [glogal | session] transaction isolation level \u9694\u79bb\u7ea7\u522b\u540d\u79f0; set tx_isolation=\u2019\u9694\u79bb\u7ea7\u522b\u540d\u79f0;\u2019 \u4f8b1\uff1a\u67e5\u770b\u5f53\u524d\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\uff1a \u4f8b2\uff1a\u5c06\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u8bbe\u7f6e\u4e3aRead uncommitted\u7ea7\u522b\uff1a \u6216\uff1a \u8bb0\u4f4f\uff1a\u8bbe\u7f6e\u6570\u636e\u5e93\u7684\u9694\u79bb\u7ea7\u522b\u4e00\u5b9a\u8981\u662f\u5728\u5f00\u542f\u4e8b\u52a1\u4e4b\u524d\uff01 \u5982\u679c\u662f\u4f7f\u7528JDBC\u5bf9\u6570\u636e\u5e93\u7684\u4e8b\u52a1\u8bbe\u7f6e\u9694\u79bb\u7ea7\u522b\u7684\u8bdd\uff0c\u4e5f\u5e94\u8be5\u662f\u5728\u8c03\u7528Connection\u5bf9\u8c61\u7684setAutoCommit(false)\u65b9\u6cd5\u4e4b\u524d\u3002\u8c03\u7528Connection\u5bf9\u8c61\u7684setTransactionIsolation(level)\u5373\u53ef\u8bbe\u7f6e\u5f53\u524d\u94fe\u63a5\u7684\u9694\u79bb\u7ea7\u522b\uff0c\u81f3\u4e8e\u53c2\u6570level\uff0c\u53ef\u4ee5\u4f7f\u7528Connection\u5bf9\u8c61\u7684\u5b57\u6bb5\uff1a \u5728JDBC\u4e2d\u8bbe\u7f6e\u9694\u79bb\u7ea7\u522b\u7684\u90e8\u5206\u4ee3\u7801\uff1a \u540e\u8bb0\uff1a\u9694\u79bb\u7ea7\u522b\u7684\u8bbe\u7f6e\u53ea\u5bf9\u5f53\u524d\u94fe\u63a5\u6709\u6548\u3002\u5bf9\u4e8e\u4f7f\u7528MySQL\u547d\u4ee4\u7a97\u53e3\u800c\u8a00\uff0c\u4e00\u4e2a\u7a97\u53e3\u5c31\u76f8\u5f53\u4e8e\u4e00\u4e2a\u94fe\u63a5\uff0c\u5f53\u524d\u7a97\u53e3\u8bbe\u7f6e\u7684\u9694\u79bb\u7ea7\u522b\u53ea\u5bf9\u5f53\u524d\u7a97\u53e3\u4e2d\u7684\u4e8b\u52a1\u6709\u6548\uff1b\u5bf9\u4e8eJDBC\u64cd\u4f5c\u6570\u636e\u5e93\u6765\u8bf4\uff0c\u4e00\u4e2aConnection\u5bf9\u8c61\u76f8\u5f53\u4e8e\u4e00\u4e2a\u94fe\u63a5\uff0c\u800c\u5bf9\u4e8eConnection\u5bf9\u8c61\u8bbe\u7f6e\u7684\u9694\u79bb\u7ea7\u522b\u53ea\u5bf9\u8be5Connection\u5bf9\u8c61\u6709\u6548\uff0c\u4e0e\u5176\u4ed6\u94fe\u63a5Connection\u5bf9\u8c61\u65e0\u5173\u3002 \u53c2\u8003\u535a\u5ba2\uff1a http://www.zhihu.com/question/23989904 http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html http://www.cnblogs.com/xdp-gacl/p/3984001.html","title":"Isolation level"},{"location":"Theory/Database-transaction/ACID/#wikipedia-acid","text":"In computer science , ACID ( atomicity , consistency , isolation , durability ) is a set of properties of database transactions intended to guarantee data validity despite errors, power failures, and other mishaps. In the context of databases , a sequence of database operations that satisfies the ACID properties (which can be perceived as a single logical operation on the data) is called a transaction . For example, a transfer of funds from one bank account to another, even involving multiple changes such as debiting one account and crediting another, is a single transaction.","title":"wikipedia ACID"},{"location":"Theory/Database-transaction/ACID/Atomicity/","text":"Atomicity (database systems) # \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u6709DB transaction\u624d\u5177\u5907ACID\u7279\u6027\uff0c\u5176\u4ed6\u7684transaction\u4e0d\u4e00\u5b9a\u5177\u5907ACID\u7279\u6027\u3002 cnblogs \u6570\u636e\u5e93\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\u4ee5\u53ca\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b # \u672c\u7bc7\u8bb2\u8bc9\u6570\u636e\u5e93\u4e2d\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\uff08ACID\uff09\uff0c\u5e76\u4e14\u5c06\u4f1a\u8be6\u7ec6\u5730\u8bf4\u660e\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u3002 \u5982\u679c\u4e00\u4e2a\u6570\u636e\u5e93\u58f0\u79f0\u652f\u6301\u4e8b\u52a1\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48\u8be5\u6570\u636e\u5e93\u5fc5\u987b\u8981\u5177\u5907\u4ee5\u4e0b\u56db\u4e2a\u7279\u6027\uff1a \u2474 \u539f\u5b50\u6027\uff08Atomicity\uff09 # \u539f\u5b50\u6027\u662f\u6307\u4e8b\u52a1\u5305\u542b\u7684\u6240\u6709\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u6210\u529f\uff0c\u8981\u4e48\u5168\u90e8\u5931\u8d25\u56de\u6eda\uff0c\u8fd9\u548c\u524d\u9762\u4e24\u7bc7\u535a\u5ba2\u4ecb\u7ecd\u4e8b\u52a1\u7684\u529f\u80fd\u662f\u4e00\u6837\u7684\u6982\u5ff5\uff0c\u56e0\u6b64\u4e8b\u52a1\u7684\u64cd\u4f5c\u5982\u679c\u6210\u529f\u5c31\u5fc5\u987b\u8981\u5b8c\u5168\u5e94\u7528\u5230\u6570\u636e\u5e93\uff0c\u5982\u679c\u64cd\u4f5c\u5931\u8d25\u5219\u4e0d\u80fd\u5bf9\u6570\u636e\u5e93\u6709\u4efb\u4f55\u5f71\u54cd\u3002 wikipedia Atomicity (database systems) # An atomic transaction is an indivisible and irreducible series of database operations such that either all occur, or nothing occurs.[ 1] A guarantee of atomicity prevents updates to the database occurring only partially, which can cause greater problems than rejecting the whole series outright. As a consequence, the transaction cannot be observed to be in progress by another database client. At one moment in time, it has not yet happened, and at the next it has already occurred in whole (or nothing happened if the transaction was cancelled in progress). NOTE: transaction\u7684atomicity\u610f\u5473\u7740\"all-or-nothing\"\uff0c\u5b83\u5e76\u4e0d\u8868\u793aDB\u5bf9transaction\u7684\u6267\u884c\u662f\u5b8c\u5168isolation\u7684(\u5728isolation\u7ae0\u8282\u4f1a\u8fdb\u884c\u4e13\u95e8\u63cf\u8ff0)\uff0cDB\u5bf9transaction\u7684\u6267\u884c\u662f\u5141\u8bb8\u4e00\u5b9a\u7a0b\u5ea6\u7684concurrency\u7684\uff0c\u8fd9\u5728 Theory\\Concurrency-Control-in-DBMS \u7ae0\u8282\u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u8fd9\u548c\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684atomic\u7684\u6982\u5ff5\u662f\u6709\u4e9b\u4e0d\u540c\u7684\uff0c\u4e3b\u8981\u662f\u56e0\u4e3aDBMS\u4e2d\uff0ctransaction\u662f\u8c03\u5ea6\u7684\u5355\u4f4d\uff0c\u800c\u4e0d\u662f\u6267\u884c\u7684\u5355\u4f4d\u3002 Orthogonality # NOTE: \u8fd9\u4e00\u6bb5\u7684\u5206\u6790\u662f\u975e\u5e38\u597d\u7684\uff0c\u63cf\u8ff0\u6e05\u695a\u4e86ACID\u4e4b\u95f4\u7684\u5173\u7cfb Atomicity does not behave completely orthogonally with regard to the other ACID properties of the transactions. For example, isolation relies on atomicity to roll back changes in the event of isolation failures such as deadlock ; consistency also relies on rollback in the event of a consistency-violation by an illegal transaction. Finally, atomicity itself relies on durability to ensure the atomicity of transactions even in the face of external failures. As a result of this, failure to detect errors and roll back the enclosing transaction may cause failures of isolation and consistency.","title":"Atomicity (database systems)"},{"location":"Theory/Database-transaction/ACID/Atomicity/#atomicity-database-systems","text":"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u53ea\u6709DB transaction\u624d\u5177\u5907ACID\u7279\u6027\uff0c\u5176\u4ed6\u7684transaction\u4e0d\u4e00\u5b9a\u5177\u5907ACID\u7279\u6027\u3002","title":"Atomicity (database systems)"},{"location":"Theory/Database-transaction/ACID/Atomicity/#cnblogs","text":"\u672c\u7bc7\u8bb2\u8bc9\u6570\u636e\u5e93\u4e2d\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\uff08ACID\uff09\uff0c\u5e76\u4e14\u5c06\u4f1a\u8be6\u7ec6\u5730\u8bf4\u660e\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b\u3002 \u5982\u679c\u4e00\u4e2a\u6570\u636e\u5e93\u58f0\u79f0\u652f\u6301\u4e8b\u52a1\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48\u8be5\u6570\u636e\u5e93\u5fc5\u987b\u8981\u5177\u5907\u4ee5\u4e0b\u56db\u4e2a\u7279\u6027\uff1a","title":"cnblogs \u6570\u636e\u5e93\u4e8b\u52a1\u7684\u56db\u5927\u7279\u6027\u4ee5\u53ca\u4e8b\u52a1\u7684\u9694\u79bb\u7ea7\u522b"},{"location":"Theory/Database-transaction/ACID/Atomicity/#1-atomicity","text":"\u539f\u5b50\u6027\u662f\u6307\u4e8b\u52a1\u5305\u542b\u7684\u6240\u6709\u64cd\u4f5c\u8981\u4e48\u5168\u90e8\u6210\u529f\uff0c\u8981\u4e48\u5168\u90e8\u5931\u8d25\u56de\u6eda\uff0c\u8fd9\u548c\u524d\u9762\u4e24\u7bc7\u535a\u5ba2\u4ecb\u7ecd\u4e8b\u52a1\u7684\u529f\u80fd\u662f\u4e00\u6837\u7684\u6982\u5ff5\uff0c\u56e0\u6b64\u4e8b\u52a1\u7684\u64cd\u4f5c\u5982\u679c\u6210\u529f\u5c31\u5fc5\u987b\u8981\u5b8c\u5168\u5e94\u7528\u5230\u6570\u636e\u5e93\uff0c\u5982\u679c\u64cd\u4f5c\u5931\u8d25\u5219\u4e0d\u80fd\u5bf9\u6570\u636e\u5e93\u6709\u4efb\u4f55\u5f71\u54cd\u3002","title":"\u2474 \u539f\u5b50\u6027\uff08Atomicity\uff09"},{"location":"Theory/Database-transaction/ACID/Atomicity/#wikipedia-atomicity-database-systems","text":"An atomic transaction is an indivisible and irreducible series of database operations such that either all occur, or nothing occurs.[ 1] A guarantee of atomicity prevents updates to the database occurring only partially, which can cause greater problems than rejecting the whole series outright. As a consequence, the transaction cannot be observed to be in progress by another database client. At one moment in time, it has not yet happened, and at the next it has already occurred in whole (or nothing happened if the transaction was cancelled in progress). NOTE: transaction\u7684atomicity\u610f\u5473\u7740\"all-or-nothing\"\uff0c\u5b83\u5e76\u4e0d\u8868\u793aDB\u5bf9transaction\u7684\u6267\u884c\u662f\u5b8c\u5168isolation\u7684(\u5728isolation\u7ae0\u8282\u4f1a\u8fdb\u884c\u4e13\u95e8\u63cf\u8ff0)\uff0cDB\u5bf9transaction\u7684\u6267\u884c\u662f\u5141\u8bb8\u4e00\u5b9a\u7a0b\u5ea6\u7684concurrency\u7684\uff0c\u8fd9\u5728 Theory\\Concurrency-Control-in-DBMS \u7ae0\u8282\u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002 \u8fd9\u548c\u6211\u4eec\u5e73\u65f6\u6240\u8bf4\u7684atomic\u7684\u6982\u5ff5\u662f\u6709\u4e9b\u4e0d\u540c\u7684\uff0c\u4e3b\u8981\u662f\u56e0\u4e3aDBMS\u4e2d\uff0ctransaction\u662f\u8c03\u5ea6\u7684\u5355\u4f4d\uff0c\u800c\u4e0d\u662f\u6267\u884c\u7684\u5355\u4f4d\u3002","title":"wikipedia Atomicity (database systems)"},{"location":"Theory/Database-transaction/ACID/Atomicity/#orthogonality","text":"NOTE: \u8fd9\u4e00\u6bb5\u7684\u5206\u6790\u662f\u975e\u5e38\u597d\u7684\uff0c\u63cf\u8ff0\u6e05\u695a\u4e86ACID\u4e4b\u95f4\u7684\u5173\u7cfb Atomicity does not behave completely orthogonally with regard to the other ACID properties of the transactions. For example, isolation relies on atomicity to roll back changes in the event of isolation failures such as deadlock ; consistency also relies on rollback in the event of a consistency-violation by an illegal transaction. Finally, atomicity itself relies on durability to ensure the atomicity of transactions even in the face of external failures. As a result of this, failure to detect errors and roll back the enclosing transaction may cause failures of isolation and consistency.","title":"Orthogonality"},{"location":"Theory/Database-transaction/ACID/Consistency%28database-systems%29/","text":"Consistency (database systems) # wikipedia Consistency (database systems) # Consistency in database systems refers to the requirement that any given database transaction must change affected data only in allowed ways. Any data written to the database must be valid according to all defined rules , including constraints , cascades , triggers , and any combination thereof. This does not guarantee correctness of the transaction in all ways the application programmer might have wanted (that is the responsibility of application-level code) but merely that any programming errors cannot result in the violation of any defined database constraints.[ 1] NOTE: \u5199\u5165database\u7684\u6570\u636e\u5fc5\u987b\u662f\u6709\u6548\u7684\uff0c\u5fc5\u987b\u662f\u7b26\u5408\u6570\u636e\u5e93\u7684\u89c4\u8303\u7684\uff1b As an ACID guarantee # Consistency is one of the four guarantees that define ACID transactions ; however, significant ambiguity exists about the nature of this guarantee. It is defined variously as: The guarantee that any transactions started in the future necessarily see the effects of other transactions committed in the past[ 2] [ 3] The guarantee that database constraints are not violated, particularly once a transaction commits[ 4] [ 5] [ 6] [ 7] The guarantee that operations in transactions are performed accurately, correctly, and with validity, with respect to application semantics[ 8] As these various definitions are not mutually exclusive, it is possible to design a system that guarantees \"consistency\" in every sense of the word, as most relational database management systems in common use today arguably do. As a CAP trade-off # The CAP theorem is based on three trade-offs, one of which is \"atomic consistency\" (shortened to \"consistency\" for the acronym), about which the authors note, \"Discussing atomic consistency is somewhat different than talking about an ACID database, as database consistency refers to transactions , while atomic consistency refers only to a property of a single request/response operation sequence. And it has a different meaning than the Atomic in ACID, as it subsumes\uff08\u5305\u62ec\uff09 the database notions of both Atomic and Consistent .\"[ 2] NOTE: \u5176\u5b9e\u8fd9\u7bc7\u6587\u7ae0\u7684\u5185\u5bb9\u662f\u6bd4\u8f83\u4e0d\u597d\u7684\uff0c\u5b83\u5728\u8fd9\u4e00\u6bb5\u5f3a\u8c03\u4e86\u5728consistency\u5728 database consistency \u548c CAP theorem \u4e2d\u7684\u5dee\u5f02\u6240\u5728\u3002","title":"Consistency (database systems)"},{"location":"Theory/Database-transaction/ACID/Consistency%28database-systems%29/#consistency-database-systems","text":"","title":"Consistency (database systems)"},{"location":"Theory/Database-transaction/ACID/Consistency%28database-systems%29/#wikipedia-consistency-database-systems","text":"Consistency in database systems refers to the requirement that any given database transaction must change affected data only in allowed ways. Any data written to the database must be valid according to all defined rules , including constraints , cascades , triggers , and any combination thereof. This does not guarantee correctness of the transaction in all ways the application programmer might have wanted (that is the responsibility of application-level code) but merely that any programming errors cannot result in the violation of any defined database constraints.[ 1] NOTE: \u5199\u5165database\u7684\u6570\u636e\u5fc5\u987b\u662f\u6709\u6548\u7684\uff0c\u5fc5\u987b\u662f\u7b26\u5408\u6570\u636e\u5e93\u7684\u89c4\u8303\u7684\uff1b","title":"wikipedia Consistency (database systems)"},{"location":"Theory/Database-transaction/ACID/Consistency%28database-systems%29/#as-an-acid-guarantee","text":"Consistency is one of the four guarantees that define ACID transactions ; however, significant ambiguity exists about the nature of this guarantee. It is defined variously as: The guarantee that any transactions started in the future necessarily see the effects of other transactions committed in the past[ 2] [ 3] The guarantee that database constraints are not violated, particularly once a transaction commits[ 4] [ 5] [ 6] [ 7] The guarantee that operations in transactions are performed accurately, correctly, and with validity, with respect to application semantics[ 8] As these various definitions are not mutually exclusive, it is possible to design a system that guarantees \"consistency\" in every sense of the word, as most relational database management systems in common use today arguably do.","title":"As an ACID guarantee"},{"location":"Theory/Database-transaction/ACID/Consistency%28database-systems%29/#as-a-cap-trade-off","text":"The CAP theorem is based on three trade-offs, one of which is \"atomic consistency\" (shortened to \"consistency\" for the acronym), about which the authors note, \"Discussing atomic consistency is somewhat different than talking about an ACID database, as database consistency refers to transactions , while atomic consistency refers only to a property of a single request/response operation sequence. And it has a different meaning than the Atomic in ACID, as it subsumes\uff08\u5305\u62ec\uff09 the database notions of both Atomic and Consistent .\"[ 2] NOTE: \u5176\u5b9e\u8fd9\u7bc7\u6587\u7ae0\u7684\u5185\u5bb9\u662f\u6bd4\u8f83\u4e0d\u597d\u7684\uff0c\u5b83\u5728\u8fd9\u4e00\u6bb5\u5f3a\u8c03\u4e86\u5728consistency\u5728 database consistency \u548c CAP theorem \u4e2d\u7684\u5dee\u5f02\u6240\u5728\u3002","title":"As a CAP trade-off"},{"location":"Theory/Database-transaction/ACID/Isolation/","text":"Isolation # wikipedia Isolation # Concurrency control # NOTE: isolation\u662f\u548cconcurrency control\u5bc6\u5207\u76f8\u5173\u7684 wikipedia Multiversion concurrency control # Isolation is the property that provides guarantees in the concurrent accesses to data. Isolation is implemented by means of a concurrency control protocol. The simplest way is to make all readers wait until the writer is done, which is known as a read-write lock . Locks are known to create contention especially between long read transactions and update transactions. Isolation and concurrency control # Isolation\u662f\u548cconcurrency control\u5bc6\u5207\u76f8\u5173\u7684\uff0c\u5728\u4e0b\u9762\u6587\u7ae0\u4e2d\uff0c\u8c08\u53ca\u4e86\u8fd9\u4e2a\u8bdd\u9898: 1\u3001wikipedia Multiversion concurrency control","title":"Isolation"},{"location":"Theory/Database-transaction/ACID/Isolation/#isolation","text":"","title":"Isolation"},{"location":"Theory/Database-transaction/ACID/Isolation/#wikipedia-isolation","text":"","title":"wikipedia Isolation"},{"location":"Theory/Database-transaction/ACID/Isolation/#concurrency-control","text":"NOTE: isolation\u662f\u548cconcurrency control\u5bc6\u5207\u76f8\u5173\u7684","title":"Concurrency control"},{"location":"Theory/Database-transaction/ACID/Isolation/#wikipedia-multiversion-concurrency-control","text":"Isolation is the property that provides guarantees in the concurrent accesses to data. Isolation is implemented by means of a concurrency control protocol. The simplest way is to make all readers wait until the writer is done, which is known as a read-write lock . Locks are known to create contention especially between long read transactions and update transactions.","title":"wikipedia Multiversion concurrency control"},{"location":"Theory/Database-transaction/ACID/Isolation/#isolation-and-concurrency-control","text":"Isolation\u662f\u548cconcurrency control\u5bc6\u5207\u76f8\u5173\u7684\uff0c\u5728\u4e0b\u9762\u6587\u7ae0\u4e2d\uff0c\u8c08\u53ca\u4e86\u8fd9\u4e2a\u8bdd\u9898: 1\u3001wikipedia Multiversion concurrency control","title":"Isolation and concurrency control"},{"location":"Theory/Database-transaction/ACID/Isolation/Isolation-level/","text":"Transaction Isolation Levels in DBMS # geeksforgeeks Transaction Isolation Levels in DBMS # Prerequisite \u2013 Concurrency control in DBMS , ACID Properties in DBMS Isolation levels define the degree to which a transaction must be isolated from the data modifications made by any other transaction in the database system. A transaction isolation level is defined by the following phenomena \u2013 1\u3001 Dirty Read \u2013 A Dirty read is the situation when a transaction reads a data that has not yet been committed. For example, Let\u2019s say transaction 1 updates a row and leaves it uncommitted, meanwhile, Transaction 2 reads the updated row. If transaction 1 rolls back the change, transaction 2 will have read data that is considered never to have existed. 2\u3001 Non Repeatable read \u2013 Non Repeatable read occurs when a transaction reads same row twice, and get a different value each time. For example, suppose transaction T1 reads data. Due to concurrency, another transaction T2 updates the same data and commit, Now if transaction T1 rereads the same data, it will retrieve a different value. 3\u3001 Phantom Read \u2013 Phantom Read occurs when two same queries are executed, but the rows retrieved by the two, are different. For example, suppose transaction T1 retrieves a set of rows that satisfy some search criteria. Now, Transaction T2 generates some new rows that match the search criteria for transaction T1. If transaction T1 re-executes the statement that reads the rows, it gets a different set of rows this time. Based on these phenomena, The SQL standard defines four isolation levels : 1\u3001 Read Uncommitted \u2013 Read Uncommitted is the lowest isolation level. In this level, one transaction may read not yet committed changes made by other transaction, thereby allowing dirty reads. In this level, transactions are not isolated from each other. 2\u3001 Read Committed \u2013 This isolation level guarantees that any data read is committed at the moment it is read. Thus it does not allows dirty read. The transaction holds a read or write lock on the current row, and thus prevent other transactions from reading, updating or deleting it. 3\u3001 Repeatable Read \u2013 This is the most restrictive isolation level. The transaction holds read locks on all rows it references and writes locks on all rows it inserts, updates, or deletes. Since other transaction cannot read, update or delete these rows, consequently it avoids non-repeatable read. 4\u3001 Serializable \u2013 This is the Highest isolation level. A serializable execution is guaranteed to be serializable. Serializable execution is defined to be an execution of operations in which concurrently executing transactions appears to be serially executing. The Table is given below clearly depicts the relationship between isolation levels, read phenomena and locks : Anomaly Serializable is not the same as Serializable. That is, it is necessary, but not sufficient that a Serializable schedule should be free of all three phenomena types. References \u2013 Isolation \u2013 Wikipedia Transaction Isolation Levels \u2013 docs.microsoft Attention reader! Don\u2019t stop learning now. Get hold of all the important CS Theory concepts for SDE interviews with the CS Theory Course at a student-friendly price and become industry ready. sqlshack Dirty Reads and the Read Uncommitted Isolation Level #","title":"Transaction Isolation Levels in DBMS"},{"location":"Theory/Database-transaction/ACID/Isolation/Isolation-level/#transaction-isolation-levels-in-dbms","text":"","title":"Transaction Isolation Levels in DBMS"},{"location":"Theory/Database-transaction/ACID/Isolation/Isolation-level/#geeksforgeeks-transaction-isolation-levels-in-dbms","text":"Prerequisite \u2013 Concurrency control in DBMS , ACID Properties in DBMS Isolation levels define the degree to which a transaction must be isolated from the data modifications made by any other transaction in the database system. A transaction isolation level is defined by the following phenomena \u2013 1\u3001 Dirty Read \u2013 A Dirty read is the situation when a transaction reads a data that has not yet been committed. For example, Let\u2019s say transaction 1 updates a row and leaves it uncommitted, meanwhile, Transaction 2 reads the updated row. If transaction 1 rolls back the change, transaction 2 will have read data that is considered never to have existed. 2\u3001 Non Repeatable read \u2013 Non Repeatable read occurs when a transaction reads same row twice, and get a different value each time. For example, suppose transaction T1 reads data. Due to concurrency, another transaction T2 updates the same data and commit, Now if transaction T1 rereads the same data, it will retrieve a different value. 3\u3001 Phantom Read \u2013 Phantom Read occurs when two same queries are executed, but the rows retrieved by the two, are different. For example, suppose transaction T1 retrieves a set of rows that satisfy some search criteria. Now, Transaction T2 generates some new rows that match the search criteria for transaction T1. If transaction T1 re-executes the statement that reads the rows, it gets a different set of rows this time. Based on these phenomena, The SQL standard defines four isolation levels : 1\u3001 Read Uncommitted \u2013 Read Uncommitted is the lowest isolation level. In this level, one transaction may read not yet committed changes made by other transaction, thereby allowing dirty reads. In this level, transactions are not isolated from each other. 2\u3001 Read Committed \u2013 This isolation level guarantees that any data read is committed at the moment it is read. Thus it does not allows dirty read. The transaction holds a read or write lock on the current row, and thus prevent other transactions from reading, updating or deleting it. 3\u3001 Repeatable Read \u2013 This is the most restrictive isolation level. The transaction holds read locks on all rows it references and writes locks on all rows it inserts, updates, or deletes. Since other transaction cannot read, update or delete these rows, consequently it avoids non-repeatable read. 4\u3001 Serializable \u2013 This is the Highest isolation level. A serializable execution is guaranteed to be serializable. Serializable execution is defined to be an execution of operations in which concurrently executing transactions appears to be serially executing. The Table is given below clearly depicts the relationship between isolation levels, read phenomena and locks : Anomaly Serializable is not the same as Serializable. That is, it is necessary, but not sufficient that a Serializable schedule should be free of all three phenomena types. References \u2013 Isolation \u2013 Wikipedia Transaction Isolation Levels \u2013 docs.microsoft Attention reader! Don\u2019t stop learning now. Get hold of all the important CS Theory concepts for SDE interviews with the CS Theory Course at a student-friendly price and become industry ready.","title":"geeksforgeeks Transaction Isolation Levels in DBMS"},{"location":"Theory/Database-transaction/ACID/Isolation/Isolation-level/#sqlshack-dirty-reads-and-the-read-uncommitted-isolation-level","text":"","title":"sqlshack Dirty Reads and the Read Uncommitted Isolation Level"},{"location":"Theory/Database-transaction/Implementation/Atomic-commit/","text":"Atomic commit # wikipedia Atomic commit # In the field of computer science , an atomic commit is an operation that applies a set of distinct changes as a single operation. If the changes are applied then the atomic commit is said to have succeeded. If there is a failure before the atomic commit can be completed then all of the changes completed in the atomic commit are reversed. This ensures that the system is always left in a consistent state. The other key property of isolation comes from their nature as atomic operations. Isolation ensures that only one atomic commit is processed at a time. The most common uses of atomic commits are in database systems and version control systems . The problem with atomic commits is that they require coordination between multiple systems.[ 1] As computer networks are unreliable services this means no algorithm can coordinate with all systems as proven in the Two Generals Problem . As databases become more and more distributed this coordination will increase the difficulty of making truly atomic commits.[ 2] Database systems # Atomic commits in database systems fulfil two of the key properties of ACID ,[ 4] atomicity and consistency . Consistency is only achieved if each change in the atomic commit is consistent.","title":"Atomic commit"},{"location":"Theory/Database-transaction/Implementation/Atomic-commit/#atomic-commit","text":"","title":"Atomic commit"},{"location":"Theory/Database-transaction/Implementation/Atomic-commit/#wikipedia-atomic-commit","text":"In the field of computer science , an atomic commit is an operation that applies a set of distinct changes as a single operation. If the changes are applied then the atomic commit is said to have succeeded. If there is a failure before the atomic commit can be completed then all of the changes completed in the atomic commit are reversed. This ensures that the system is always left in a consistent state. The other key property of isolation comes from their nature as atomic operations. Isolation ensures that only one atomic commit is processed at a time. The most common uses of atomic commits are in database systems and version control systems . The problem with atomic commits is that they require coordination between multiple systems.[ 1] As computer networks are unreliable services this means no algorithm can coordinate with all systems as proven in the Two Generals Problem . As databases become more and more distributed this coordination will increase the difficulty of making truly atomic commits.[ 2]","title":"wikipedia Atomic commit"},{"location":"Theory/Database-transaction/Implementation/Atomic-commit/#database-systems","text":"Atomic commits in database systems fulfil two of the key properties of ACID ,[ 4] atomicity and consistency . Consistency is only achieved if each change in the atomic commit is consistent.","title":"Database systems"},{"location":"Theory/Database-transaction/Implementation/Serializability/","text":"Serializability # \"serializability\"\u7684\u542b\u4e49\u662f \"\u53ef\u4e32\u884c\u6027\"\uff0c\u672c\u6587\u4ecb\u7ecd\u7684\"serializability\"\u662fDB\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5\u3002 wikipedia Serializability # In concurrency control of databases ,[ 1] [ 2] transaction processing (transaction management), and various transactional applications (e.g., transactional memory [ 3] and software transactional memory ), both centralized and distributed , a transaction schedule is serializable if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially(\u4e32\u884c\u7684), i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions[ citation needed ]. It is considered the highest level of isolation between transactions , and plays an essential role in concurrency control . As such it is supported in all general purpose database systems. Strong strict two-phase locking (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s. Serializability theory provides the formal framework to reason about and analyze serializability and its techniques. Though it is mathematical in nature, its fundamentals are informally (without mathematics notation) introduced below. Linearizability and serializability # \u5728 wikipedia Serializability \u7684\"See also\"\u6bb5\u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0: Linearizability , a more general concept in concurrent computing","title":"Serializability"},{"location":"Theory/Database-transaction/Implementation/Serializability/#serializability","text":"\"serializability\"\u7684\u542b\u4e49\u662f \"\u53ef\u4e32\u884c\u6027\"\uff0c\u672c\u6587\u4ecb\u7ecd\u7684\"serializability\"\u662fDB\u4e2d\u7684\u4e00\u4e2a\u6982\u5ff5\u3002","title":"Serializability"},{"location":"Theory/Database-transaction/Implementation/Serializability/#wikipedia-serializability","text":"In concurrency control of databases ,[ 1] [ 2] transaction processing (transaction management), and various transactional applications (e.g., transactional memory [ 3] and software transactional memory ), both centralized and distributed , a transaction schedule is serializable if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially(\u4e32\u884c\u7684), i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions[ citation needed ]. It is considered the highest level of isolation between transactions , and plays an essential role in concurrency control . As such it is supported in all general purpose database systems. Strong strict two-phase locking (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s. Serializability theory provides the formal framework to reason about and analyze serializability and its techniques. Though it is mathematical in nature, its fundamentals are informally (without mathematics notation) introduced below.","title":"wikipedia Serializability"},{"location":"Theory/Database-transaction/Implementation/Serializability/#linearizability-and-serializability","text":"\u5728 wikipedia Serializability \u7684\"See also\"\u6bb5\u4e2d\uff0c\u6709\u8fd9\u6837\u7684\u63cf\u8ff0: Linearizability , a more general concept in concurrent computing","title":"Linearizability and serializability"},{"location":"Theory/Database-transaction/Implementation/Three-phase-commit-protocol/","text":"Three-phase commit protocol # wikipedia Three-phase commit protocol #","title":"Three-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Three-phase-commit-protocol/#three-phase-commit-protocol","text":"","title":"Three-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Three-phase-commit-protocol/#wikipedia-three-phase-commit-protocol","text":"","title":"wikipedia Three-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/","text":"Two-phase commit protocol # wikipedia Two-phase commit protocol # csdn \u4e24\u9636\u6bb5\u63d0\u4ea4\u534f\u8bae\uff08two phase commit protocol\uff0c2PC\uff09 # Example # sqlite # \u7531\u4e8e\u8981\u57fa\u4e8esqlite\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8evirtual table\u7684extension\uff0c\u5728\u9605\u8bfbsqlite The Virtual Table Mechanism Of SQLite#2.16. The xSync Method \u65f6\uff0c\u5176\u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0: This method signals the start of a two-phase commit on a virtual table. \u663e\u7136\uff0c\u8fd9\u662f\u4e3a\u4e86\u652f\u6301transaction\u7684\uff0c\u8fd9\u8ba9\u6211\u60f3\u8d77\u6765\u4e4b\u524d\u5728\u5b66\u4e60Redis\u7684\u65f6\u5019\uff0c\u5176\u4e2d\u4e5f\u6709\u63cf\u8ff0two-phase commit protocol\uff0c\u6240\u4ee5\u6709\u5fc5\u8981\u5bf9Two-phase commit \u8fdb\u884c\u603b\u7ed3\u3002 sqlite implementation of Two-phase commit # \u5982\u4e0b\u91cd\u8981\u65b9\u6cd5: xBegin xSync xCommit xRollback \u53c2\u89c1: sqlite The Virtual Table Mechanism Of SQLite#2.16. The xSync Method C++ # Generic: Change the Way You Write Exception-Safe Code \u2014 Forever # AddFriend now has two distinct parts: the activity phase, in which the operations occur, and the commitment phase, which doesn't throw \u2014 it only stops the undo from happening.","title":"Two-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#two-phase-commit-protocol","text":"","title":"Two-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#wikipedia-two-phase-commit-protocol","text":"","title":"wikipedia Two-phase commit protocol"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#csdn-two-phase-commit-protocol2pc","text":"","title":"csdn \u4e24\u9636\u6bb5\u63d0\u4ea4\u534f\u8bae\uff08two phase commit protocol\uff0c2PC\uff09"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#example","text":"","title":"Example"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#sqlite","text":"\u7531\u4e8e\u8981\u57fa\u4e8esqlite\u5f00\u53d1\u4e00\u4e2a\u57fa\u4e8evirtual table\u7684extension\uff0c\u5728\u9605\u8bfbsqlite The Virtual Table Mechanism Of SQLite#2.16. The xSync Method \u65f6\uff0c\u5176\u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0: This method signals the start of a two-phase commit on a virtual table. \u663e\u7136\uff0c\u8fd9\u662f\u4e3a\u4e86\u652f\u6301transaction\u7684\uff0c\u8fd9\u8ba9\u6211\u60f3\u8d77\u6765\u4e4b\u524d\u5728\u5b66\u4e60Redis\u7684\u65f6\u5019\uff0c\u5176\u4e2d\u4e5f\u6709\u63cf\u8ff0two-phase commit protocol\uff0c\u6240\u4ee5\u6709\u5fc5\u8981\u5bf9Two-phase commit \u8fdb\u884c\u603b\u7ed3\u3002","title":"sqlite"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#sqlite-implementation-of-two-phase-commit","text":"\u5982\u4e0b\u91cd\u8981\u65b9\u6cd5: xBegin xSync xCommit xRollback \u53c2\u89c1: sqlite The Virtual Table Mechanism Of SQLite#2.16. The xSync Method","title":"sqlite implementation of Two-phase commit"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#c","text":"","title":"C++"},{"location":"Theory/Database-transaction/Implementation/Two-phase-commit-protocol/#generic-change-the-way-you-write-exception-safe-code-forever","text":"AddFriend now has two distinct parts: the activity phase, in which the operations occur, and the commitment phase, which doesn't throw \u2014 it only stops the undo from happening.","title":"Generic: Change the Way You Write Exception-Safe Code \u2014 Forever"},{"location":"Theory/Database-transaction/Transaction/","text":"Database transaction # Transaction\u662fDBMS\u4e2d\u7684\u6838\u5fc3\u6982\u5ff5\uff0cDBMS\u4e2d\u7684\u5982\u4e0b\u5185\u5bb9\u7684\u57fa\u77f3: 1) unit of work 2) unit of concurrency control\uff0c\u5728 Theory\\Concurrency-Control-in-DBMS \u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0 stackoverflow How do ACID and database transactions work? # A ACID is a set of properties that you would like to apply when modifying a database. Atomicity Consistency Isolation Durability A transaction is a set of related changes which is used to achieve some of the ACID properties. Transactions are tools to achieve the ACID properties. Atomicity means that you can guarantee that all of a transaction happens, or none of it does; you can do complex operations as one single unit, all or nothing, and a crash, power failure, error, or anything else won't allow you to be in a state in which only some of the related changes have happened. Consistency means that you guarantee that your data will be consistent; none of the constraints you have on related data will ever be violated. Isolation means that one transaction cannot read data from another transaction that is not yet completed. If two transactions are executing concurrently, each one will see the world as if they were executing sequentially, and if one needs to read data that is written by another, it will have to wait until the other is finished. Durability means that once a transaction is complete, it is guaranteed that all of the changes have been recorded to a durable medium (such as a hard disk), and the fact that the transaction has been completed is likewise recorded. So, transactions are a mechanism for guaranteeing these properties; they are a way of grouping related actions together such that as a whole, a group of operations can be atomic, produce consistent results, be isolated from other operations, and be durably recorded. wikipedia Database transaction # A database transaction symbolizes(\u8c61\u5f81\u3001\u8868\u793a) a unit of work performed within a database management system (or similar system) against a database, and treated in a coherent(\u8fde\u8d2f\u7684\u3001\u4e00\u81f4\u7684) and reliable way independent of other transactions. A transaction generally represents any change in a database. NOTE: unit of work \u662f\u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u5173\u952e\u6240\u5728\uff0c\u9700\u8981\u4ee5\u6587\u7ae0\u300aUnit\u300b\u4e2d\u63cf\u8ff0\u7684\u601d\u60f3\u6765\u770b\u5f85transaction: 1\u3001transaction\u662fDB\u4e2dwork\u7684\u5355\u4f4d\uff0c\u5373\u5728DB\u4e2d\uff0c\u4ee5transaction\u4e3a\u5355\u4f4d\u6765\u5ea6\u91cfwork\uff0c\u663e\u7136\uff0c\u5b83\u662f\u6bd4SQL\u8bed\u53e5\u66f4\u5927\u7684\u4e00\u4e2a\u91cf\u7ea7 2\u3001\u663e\u7136transaction\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u62bd\u8c61\uff0c\u5b83\u62bd\u8c61\u5730\u8868\u793a\u4e86database work\uff0c\u7b26\u5408DB\u7684\u8bf8\u591a\u9700\u6c42\uff0c\u4e0b\u9762\u8fdb\u884c\u4e86\u63cf\u8ff0 Purpose # Transactions in a database environment have two main purposes: 1\u3001To provide reliable units of work that allow correct recovery from failures and keep a database consistent even in cases of system failure, when execution stops (completely or partially) and many operations upon a database remain uncompleted, with unclear status. 2\u3001To provide isolation between programs accessing a database concurrently. If this isolation is not provided, the programs' outcomes are possibly erroneous. NOTE: \u5982\u4f55\u5b9e\u73b0isolation\u5462\uff1f Property # A database transaction, by definition, must be atomic (it must either complete in its entirety or have no effect whatsoever), consistent (it must conform to existing constraints in the database), isolated (it must not affect other transactions) and durable (it must get written to persistent storage).[ 1] Database practitioners often refer to these properties of database transactions using the acronym ACID . NOTE: \u5728 Theory\\Database-transaction\\ACID \u4e2d\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u4ecb\u7ecd\u3002 Distributed transactions # NOTE: \u653e\u5230\u4e86distributed computing\u7ae0\u8282\u4e2d\u4e86 Transactional filesystems # NOTE: \u8fd9\u5176\u5b9e\u662f\u5c06transaction\u6982\u5ff5\u4f7f\u7528\u5230filesystem\u4e2d ucsd Lecture 8: Transactions, ACID, 2PC, 2PL, Serializability # ACID Transactions # Traditional database systems have relied upon bundling work into transactions that have the ACID properties. In so doing, they guarantee consistency at the expense of availability and/or partition tolerance. NOTE: CAP theory ACID is an acronym for: 1\u3001Atomicity 2\u3001Consistency (serializability) 3\u3001Isolation 4\u3001Durability 1\u3001Acid - \"All or nothing\" 2\u3001Consistency -- This implies two types of consistency. It implies that a single system is consistent and that there is consistency across systems. In other words, if $100 is moved from one bank account to another, not only is it subtracted from one and added to another on one host -- it appears this way everywhere. It is this property that allows one transaction to safely follow another. 3\u3001Isolation - Regardless of the level of concurrency, transactions must yields the same results as if they were executed one at a time (but any one of perhaps several orderings). 4\u3001Durability - permanance. Changes persist over crashes, &c. Transactions, Detail and Example # Transactions are sequences of actions such that all of the operations within the transaction succeed (on all recipients) and their effects are permanantly visible, or none of none of the operations suceed anywhere and they have no visible effects; this might be because of failure (unintentional) or an abort (intentional). NOTE: \u7b80\u800c\u8a00\u4e4b: \"All or nothing\" Mommit point # Characterisitically, transactions have a commit point . This is the point of no return. Before this point, we can undo a transaction. After this point, all changes are permanant. If problems occur after the commit point , we can take compensating(\u8865\u507f\uff1b\u4fee\u6b63\uff1b\u62b5\u6d88) or corrective action, but we can't wave a magic wand(\u9b54\u6cd5\u68d2) and undo it. NOTE: commit\u540e\u662f\u4e0d\u80fdredo\u7684 Distributed Transactions and Atomic Commit Protocols # NOTE: \u653e\u5230\u4e86distributed computing\u7ae0\u8282\u4e2d\u4e86","title":"Database transaction"},{"location":"Theory/Database-transaction/Transaction/#database-transaction","text":"Transaction\u662fDBMS\u4e2d\u7684\u6838\u5fc3\u6982\u5ff5\uff0cDBMS\u4e2d\u7684\u5982\u4e0b\u5185\u5bb9\u7684\u57fa\u77f3: 1) unit of work 2) unit of concurrency control\uff0c\u5728 Theory\\Concurrency-Control-in-DBMS \u4e2d\u8fdb\u884c\u4e86\u63cf\u8ff0","title":"Database transaction"},{"location":"Theory/Database-transaction/Transaction/#stackoverflow-how-do-acid-and-database-transactions-work","text":"A ACID is a set of properties that you would like to apply when modifying a database. Atomicity Consistency Isolation Durability A transaction is a set of related changes which is used to achieve some of the ACID properties. Transactions are tools to achieve the ACID properties. Atomicity means that you can guarantee that all of a transaction happens, or none of it does; you can do complex operations as one single unit, all or nothing, and a crash, power failure, error, or anything else won't allow you to be in a state in which only some of the related changes have happened. Consistency means that you guarantee that your data will be consistent; none of the constraints you have on related data will ever be violated. Isolation means that one transaction cannot read data from another transaction that is not yet completed. If two transactions are executing concurrently, each one will see the world as if they were executing sequentially, and if one needs to read data that is written by another, it will have to wait until the other is finished. Durability means that once a transaction is complete, it is guaranteed that all of the changes have been recorded to a durable medium (such as a hard disk), and the fact that the transaction has been completed is likewise recorded. So, transactions are a mechanism for guaranteeing these properties; they are a way of grouping related actions together such that as a whole, a group of operations can be atomic, produce consistent results, be isolated from other operations, and be durably recorded.","title":"stackoverflow How do ACID and database transactions work?"},{"location":"Theory/Database-transaction/Transaction/#wikipedia-database-transaction","text":"A database transaction symbolizes(\u8c61\u5f81\u3001\u8868\u793a) a unit of work performed within a database management system (or similar system) against a database, and treated in a coherent(\u8fde\u8d2f\u7684\u3001\u4e00\u81f4\u7684) and reliable way independent of other transactions. A transaction generally represents any change in a database. NOTE: unit of work \u662f\u7406\u89e3\u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u5173\u952e\u6240\u5728\uff0c\u9700\u8981\u4ee5\u6587\u7ae0\u300aUnit\u300b\u4e2d\u63cf\u8ff0\u7684\u601d\u60f3\u6765\u770b\u5f85transaction: 1\u3001transaction\u662fDB\u4e2dwork\u7684\u5355\u4f4d\uff0c\u5373\u5728DB\u4e2d\uff0c\u4ee5transaction\u4e3a\u5355\u4f4d\u6765\u5ea6\u91cfwork\uff0c\u663e\u7136\uff0c\u5b83\u662f\u6bd4SQL\u8bed\u53e5\u66f4\u5927\u7684\u4e00\u4e2a\u91cf\u7ea7 2\u3001\u663e\u7136transaction\u662f\u4e00\u4e2a\u975e\u5e38\u597d\u7684\u62bd\u8c61\uff0c\u5b83\u62bd\u8c61\u5730\u8868\u793a\u4e86database work\uff0c\u7b26\u5408DB\u7684\u8bf8\u591a\u9700\u6c42\uff0c\u4e0b\u9762\u8fdb\u884c\u4e86\u63cf\u8ff0","title":"wikipedia Database transaction"},{"location":"Theory/Database-transaction/Transaction/#purpose","text":"Transactions in a database environment have two main purposes: 1\u3001To provide reliable units of work that allow correct recovery from failures and keep a database consistent even in cases of system failure, when execution stops (completely or partially) and many operations upon a database remain uncompleted, with unclear status. 2\u3001To provide isolation between programs accessing a database concurrently. If this isolation is not provided, the programs' outcomes are possibly erroneous. NOTE: \u5982\u4f55\u5b9e\u73b0isolation\u5462\uff1f","title":"Purpose"},{"location":"Theory/Database-transaction/Transaction/#property","text":"A database transaction, by definition, must be atomic (it must either complete in its entirety or have no effect whatsoever), consistent (it must conform to existing constraints in the database), isolated (it must not affect other transactions) and durable (it must get written to persistent storage).[ 1] Database practitioners often refer to these properties of database transactions using the acronym ACID . NOTE: \u5728 Theory\\Database-transaction\\ACID \u4e2d\u8fdb\u884c\u4e86\u4e13\u95e8\u7684\u4ecb\u7ecd\u3002","title":"Property"},{"location":"Theory/Database-transaction/Transaction/#distributed-transactions","text":"NOTE: \u653e\u5230\u4e86distributed computing\u7ae0\u8282\u4e2d\u4e86","title":"Distributed transactions"},{"location":"Theory/Database-transaction/Transaction/#transactional-filesystems","text":"NOTE: \u8fd9\u5176\u5b9e\u662f\u5c06transaction\u6982\u5ff5\u4f7f\u7528\u5230filesystem\u4e2d","title":"Transactional filesystems"},{"location":"Theory/Database-transaction/Transaction/#ucsd-lecture-8-transactions-acid-2pc-2pl-serializability","text":"","title":"ucsd Lecture 8: Transactions, ACID, 2PC, 2PL, Serializability"},{"location":"Theory/Database-transaction/Transaction/#acid-transactions","text":"Traditional database systems have relied upon bundling work into transactions that have the ACID properties. In so doing, they guarantee consistency at the expense of availability and/or partition tolerance. NOTE: CAP theory ACID is an acronym for: 1\u3001Atomicity 2\u3001Consistency (serializability) 3\u3001Isolation 4\u3001Durability 1\u3001Acid - \"All or nothing\" 2\u3001Consistency -- This implies two types of consistency. It implies that a single system is consistent and that there is consistency across systems. In other words, if $100 is moved from one bank account to another, not only is it subtracted from one and added to another on one host -- it appears this way everywhere. It is this property that allows one transaction to safely follow another. 3\u3001Isolation - Regardless of the level of concurrency, transactions must yields the same results as if they were executed one at a time (but any one of perhaps several orderings). 4\u3001Durability - permanance. Changes persist over crashes, &c.","title":"ACID Transactions"},{"location":"Theory/Database-transaction/Transaction/#transactions-detail-and-example","text":"Transactions are sequences of actions such that all of the operations within the transaction succeed (on all recipients) and their effects are permanantly visible, or none of none of the operations suceed anywhere and they have no visible effects; this might be because of failure (unintentional) or an abort (intentional). NOTE: \u7b80\u800c\u8a00\u4e4b: \"All or nothing\"","title":"Transactions, Detail and Example"},{"location":"Theory/Database-transaction/Transaction/#mommit-point","text":"Characterisitically, transactions have a commit point . This is the point of no return. Before this point, we can undo a transaction. After this point, all changes are permanant. If problems occur after the commit point , we can take compensating(\u8865\u507f\uff1b\u4fee\u6b63\uff1b\u62b5\u6d88) or corrective action, but we can't wave a magic wand(\u9b54\u6cd5\u68d2) and undo it. NOTE: commit\u540e\u662f\u4e0d\u80fdredo\u7684","title":"Mommit point"},{"location":"Theory/Database-transaction/Transaction/#distributed-transactions-and-atomic-commit-protocols","text":"NOTE: \u653e\u5230\u4e86distributed computing\u7ae0\u8282\u4e2d\u4e86","title":"Distributed Transactions and Atomic Commit Protocols"}]}